{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ1JqAHisuEKjXbKzvE5Ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc133541cd924c1298ff925dee9d7372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e795a3629dcf450599f50752ec902a73",
              "IPY_MODEL_7e77ce3559c3495ab9405a72b38f2fea",
              "IPY_MODEL_287145738c1e4754bfbb1b1fe7406914"
            ],
            "layout": "IPY_MODEL_27aa96e840134db0b6689ddb2256df9b"
          }
        },
        "e795a3629dcf450599f50752ec902a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e931cfb52711465b8ea790fc47983fba",
            "placeholder": "​",
            "style": "IPY_MODEL_11850c52f4934f28ae25f998b824de49",
            "value": "svd_xt_1_1.safetensors: 100%"
          }
        },
        "7e77ce3559c3495ab9405a72b38f2fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da9a07ef23124d24af5263627d9a6413",
            "max": 4780030976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c6c79d595a4418a9f5219704ec8fdd5",
            "value": 4780030976
          }
        },
        "287145738c1e4754bfbb1b1fe7406914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e063b33126a4453793d04bfac8405f77",
            "placeholder": "​",
            "style": "IPY_MODEL_25fc791084d5448983f3c6dcab4c44c8",
            "value": " 4.78G/4.78G [00:49&lt;00:00, 135MB/s]"
          }
        },
        "27aa96e840134db0b6689ddb2256df9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e931cfb52711465b8ea790fc47983fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11850c52f4934f28ae25f998b824de49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da9a07ef23124d24af5263627d9a6413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6c79d595a4418a9f5219704ec8fdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e063b33126a4453793d04bfac8405f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fc791084d5448983f3c6dcab4c44c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d70c588ad7747be8670bff5dff76ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39d9248dad02476a933fc9d9935396d7",
              "IPY_MODEL_cd8614823a2949a2a09bff30d9892b33",
              "IPY_MODEL_f3bf918c33464a0e96097b4148e4daf7"
            ],
            "layout": "IPY_MODEL_570a93c1e421493f979bd9492a397807"
          }
        },
        "39d9248dad02476a933fc9d9935396d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b222edd5102a4aefb9ddc2e1f2b76697",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a21f0ad2824f82ba757b1756566aaa",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "cd8614823a2949a2a09bff30d9892b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37aa28c2b2fa4d0490e1da4f1d853539",
            "max": 3944517836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09ca4b284c70481fb7bdd5758cede411",
            "value": 3944517836
          }
        },
        "f3bf918c33464a0e96097b4148e4daf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913748a1e37f4664b137da9749055328",
            "placeholder": "​",
            "style": "IPY_MODEL_ca64ed380e834192bdf0f3ee1c28457a",
            "value": " 3.94G/3.94G [02:19&lt;00:00, 26.6MB/s]"
          }
        },
        "570a93c1e421493f979bd9492a397807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b222edd5102a4aefb9ddc2e1f2b76697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a21f0ad2824f82ba757b1756566aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37aa28c2b2fa4d0490e1da4f1d853539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ca4b284c70481fb7bdd5758cede411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "913748a1e37f4664b137da9749055328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca64ed380e834192bdf0f3ee1c28457a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicreativeexplorer/YT-Automation/blob/main/YT_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/YT-Automation/notebook_config.txt <<'EOF'\n",
        "UPLOADED_VIDEO=/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\n",
        "DRIVE_TOKEN_PATH=/content/drive/MyDrive/AI-Automation/hf_token.txt\n",
        "OUTPUT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/outputs/stitched\n",
        "CHECKPOINT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/checkpoints\n",
        "EOF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "koaeYlEFkIlj",
        "outputId": "c1fad3ac-47a9-4a97-abfd-685a86438360"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "bash: line 1: /content/YT-Automation/notebook_config.txt: No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b\"cat > /content/YT-Automation/notebook_config.txt <<'EOF'\\nUPLOADED_VIDEO=/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\\nDRIVE_TOKEN_PATH=/content/drive/MyDrive/AI-Automation/hf_token.txt\\nOUTPUT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/outputs/stitched\\nCHECKPOINT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/checkpoints\\nEOF\\n\"' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3577637377.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cat > /content/YT-Automation/notebook_config.txt <<'EOF'\\nUPLOADED_VIDEO=/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\\nDRIVE_TOKEN_PATH=/content/drive/MyDrive/AI-Automation/hf_token.txt\\nOUTPUT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/outputs/stitched\\nCHECKPOINT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/checkpoints\\nEOF\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b\"cat > /content/YT-Automation/notebook_config.txt <<'EOF'\\nUPLOADED_VIDEO=/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\\nDRIVE_TOKEN_PATH=/content/drive/MyDrive/AI-Automation/hf_token.txt\\nOUTPUT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/outputs/stitched\\nCHECKPOINT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/checkpoints\\nEOF\\n\"' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BOOTSTRAP: mount drive, load config, auto-login HF token\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "import os, sys, json\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# path inside the repo after you clone or open from GitHub\n",
        "REPO_CONFIG_PATH = '/content/YT-Automation/notebook_config.txt'  # if opened from GitHub this will be in /content/YT-Automation\n",
        "FALLBACK_CONFIG_PATH = '/content/notebook_config.txt'  # if you copied config into /content\n",
        "\n",
        "cfg_path = REPO_CONFIG_PATH if os.path.exists(REPO_CONFIG_PATH) else FALLBACK_CONFIG_PATH\n",
        "if not os.path.exists(cfg_path):\n",
        "    raise FileNotFoundError(f\"Config not found. Put notebook_config.txt at repo root or /content. Checked: {cfg_path}\")\n",
        "\n",
        "cfg = {}\n",
        "with open(cfg_path, 'r') as f:\n",
        "    for ln in f:\n",
        "        if '=' in ln:\n",
        "            k,v = ln.strip().split('=',1)\n",
        "            cfg[k]=v\n",
        "\n",
        "print(\"CONFIG:\", cfg)\n",
        "\n",
        "# HF login if token present\n",
        "if os.path.exists(cfg.get('DRIVE_TOKEN_PATH','')):\n",
        "    with open(cfg['DRIVE_TOKEN_PATH'],'r') as fh:\n",
        "        token = fh.read().strip()\n",
        "    login(token=token)\n",
        "    print(\"HuggingFace logged in from Drive token\")\n",
        "else:\n",
        "    print(\"No HF token found at\", cfg.get('DRIVE_TOKEN_PATH'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "hx4IGOYEjqkR",
        "outputId": "fbf62537-e202-45b2-ea1e-fcce93a7be8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Config not found. Put notebook_config.txt at repo root or /content. Checked: /content/notebook_config.txt",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1461214882.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcfg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREPO_CONFIG_PATH\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREPO_CONFIG_PATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mFALLBACK_CONFIG_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Config not found. Put notebook_config.txt at repo root or /content. Checked: {cfg_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Config not found. Put notebook_config.txt at repo root or /content. Checked: /content/notebook_config.txt"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) set your git identity (run once in this runtime)\n",
        "!git config --global user.email \"aicreativeexplorer@gmail.com\"\n",
        "!git config --global user.name \"aicreativeexplorer\"\n"
      ],
      "metadata": {
        "id": "e-JcwvC0VcF3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prints current notebook path that Colab can save to /content if needed\n",
        "import os\n",
        "from google.colab import drive\n",
        "print(\"NOTE: If you downloaded manually, put the .ipynb file into /content before running the push steps.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9I7unJnV1Oq",
        "outputId": "a320d16a-75e0-437c-8766-c3ad667497ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: If you downloaded manually, put the .ipynb file into /content before running the push steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Drive (run in Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# make folders in Drive\n",
        "!mkdir -p \"/content/drive/MyDrive/AI-Automation/inputs\"\n",
        "!mkdir -p \"/content/drive/MyDrive/AI-Automation/outputs/stitched\"\n",
        "!mkdir -p \"/content/drive/MyDrive/AI-Automation/checkpoints\"\n",
        "!mkdir -p \"/content/drive/MyDrive/AI-Automation/scripts\"\n",
        "!mkdir -p \"/content/drive/MyDrive/AI-Automation/configs\"\n",
        "\n",
        "# quick list to confirm\n",
        "!ls -la \"/content/drive/MyDrive/AI-Automation\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHdLnU7ngbl1",
        "outputId": "e474968d-ea6e-4dab-c7a5-b1b03507a0c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "total 20\n",
            "drwx------ 2 root root 4096 Nov 20 09:04 checkpoints\n",
            "drwx------ 2 root root 4096 Nov 20 09:04 configs\n",
            "drwx------ 2 root root 4096 Nov 20 09:04 inputs\n",
            "drwx------ 3 root root 4096 Nov 20 09:04 outputs\n",
            "drwx------ 2 root root 4096 Nov 20 09:04 scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat > /content/notebook_config.txt <<'CFG'\n",
        "UPLOADED_VIDEO=/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\n",
        "DRIVE_TOKEN_PATH=/content/drive/MyDrive/AI-Automation/hf_token.txt\n",
        "OUTPUT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/outputs/stitched\n",
        "CHECKPOINT_DRIVE_FOLDER=/content/drive/MyDrive/AI-Automation/checkpoints\n",
        "CFG\n",
        "\n",
        "# check\n",
        "cat /content/notebook_config.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UNCbN4L3gqUP",
        "outputId": "a9e3c65c-017f-48d0-db7b-bfb36ef2daa7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-856834468.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-856834468.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cat > /content/notebook_config.txt <<'CFG'\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRqbTAydgweR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) clone repo (fresh)\n",
        "!rm -rf /content/YT-Automation\n",
        "!git clone https://github.com/aicreativeexplorer/YT-Automation.git /content/YT-Automation\n",
        "%cd /content/YT-Automation\n",
        "\n",
        "# copy the notebook from /content (adjust filename if different)\n",
        "# if you saved it to /content/YT-Automation.ipynb or downloaded from Drive first, change source path\n",
        "!cp /content/YT-Automation.ipynb ./YT-Automation.ipynb || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD0pTUvnWAC5",
        "outputId": "e179b974-341d-4066-f300-120c857209b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/YT-Automation'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), 8.98 KiB | 8.98 MiB/s, done.\n",
            "/content/YT-Automation\n",
            "cp: cannot stat '/content/YT-Automation.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo (or create dir if clone fails)\n",
        "rm -rf /content/YT-Automation\n",
        "git clone https://github.com/aicreativeexplorer/YT-Automation.git /content/YT-Automation || mkdir -p /content/YT-Automation\n",
        "cd /content/YT-Automation\n",
        "\n",
        "# Create content files\n",
        "cat > svd_pipeline/requirements.txt <<'REQ'\n",
        "kornia\n",
        "open_clip_torch\n",
        "timm\n",
        "transformers\n",
        "safetensors\n",
        "accelerate\n",
        "pytorch-lightning\n",
        "gradio==3.34.0\n",
        "omegaconf\n",
        "einops\n",
        "imageio-ffmpeg\n",
        "imwatermark\n",
        "REQ\n",
        "\n",
        "mkdir -p scripts\n",
        "\n",
        "cat > scripts/clone_generative_models.sh <<'SH'\n",
        "#!/usr/bin/env bash\n",
        "set -e\n",
        "if [ ! -d /content/generative-models ]; then\n",
        "  git clone https://github.com/Stability-AI/generative-models.git /content/generative-models\n",
        "fi\n",
        "pip install -q -e /content/generative-models || true\n",
        "SH\n",
        "chmod +x scripts/clone_generative_models.sh\n",
        "\n",
        "cat > README.md <<'MD'\n",
        "YT-Automation / svd_pipeline scaffold\n",
        "- notebook_config.txt controls UPLOADED_VIDEO and Drive paths.\n",
        "- colab_notebooks/YT-Automation.ipynb is the main notebook.\n",
        "- scripts/clone_generative_models.sh clones the SVD repo.\n",
        "MD\n",
        "\n",
        "# copy the config into the repo so it persists in version control\n",
        "cp /content/notebook_config.txt ./notebook_config.txt\n",
        "\n",
        "# if you have the notebook /content/YT-Automation.ipynb, copy it into repo\n",
        "# if not, create a placeholder that you will replace with your actual full notebook\n",
        "if [ -f /content/YT-Automation.ipynb ]; then\n",
        "  cp /content/YT-Automation.ipynb ./YT-Automation.ipynb\n",
        "else\n",
        "  cat > ./YT-Automation.ipynb <<'JSON'\n",
        "{\n",
        " \"cells\": [\n",
        "  {\"cell_type\":\"markdown\",\"metadata\":{},\"source\":[\"# YT-Automation notebook\\nThis is a placeholder. Replace with full notebook.\"]}\n",
        " ],\n",
        " \"metadata\": {\"kernelspec\": {\"display_name\": \"Python 3\",\"name\": \"python3\"}},\n",
        " \"nbformat\":4,\"nbformat_minor\":5\n",
        "}\n",
        "JSON\n",
        "fi\n",
        "\n",
        "# stage files\n",
        "git add README.md svd_pipeline scripts/notebook_config.txt notebook_config.txt YT-Automation.ipynb || true\n",
        "git commit -m \"Add svd pipeline scaffold and notebook config\" || echo \"No changes to commit\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "AcboJEzPg5jR",
        "outputId": "eeb78fcd-84f7-4266-f921-e2a9b2c5f24f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3548272078.py, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3548272078.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    git clone https://github.com/aicreativeexplorer/YT-Automation.git /content/YT-Automation || mkdir -p /content/YT-Automation\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7CY4U4QJehf",
        "outputId": "5336c173-8f80-46fd-af2d-699d233e6233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG loaded\n"
          ]
        }
      ],
      "source": [
        "# CONFIG — edit only if you moved files\n",
        "DRIVE_TOKEN_PATH = \"/content/drive/MyDrive/ai_shorts_pipeline/hf_token.txt\"\n",
        "SVD_VERSION = \"svd-xt-1-1\"   # use \"svd\" if you want the lighter open model\n",
        "UPLOADED_VIDEO = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "OUTPUT_DRIVE_FOLDER = \"/content/drive/MyDrive/ai_shorts_pipeline/stitched\"\n",
        "CHECKPOINT_DIR = \"/content/checkpoints\"\n",
        "print(\"CONFIG loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "print('Mounting Drive...')\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "if os.path.exists(DRIVE_TOKEN_PATH):\n",
        "    with open(DRIVE_TOKEN_PATH, 'r') as f:\n",
        "        hf_token = f.read().strip()\n",
        "    login(token=hf_token)\n",
        "    print('🔥 HuggingFace logged in from Drive token')\n",
        "else:\n",
        "    print('⚠️ hf_token.txt not found at', DRIVE_TOKEN_PATH)\n",
        "    print('If you want, paste token interactively now:')\n",
        "    from huggingface_hub import login as hf_login\n",
        "    hf_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHqBGPPgKBP9",
        "outputId": "cae20f50-426d-449e-d620-116ccb997395"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Drive...\n",
            "Mounted at /content/drive\n",
            "🔥 HuggingFace logged in from Drive token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing key packages (fast)..\")\n",
        "!pip install -q kornia open_clip_torch timm transformers accelerate safetensors pytorch-lightning fire gradio==3.34.0 omegaconf einops imageio-ffmpeg imwatermark\n",
        "print(\"Install cell done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6pGPoX4KVgh",
        "outputId": "9eeffffb-6414-4d6c-b6e1-4dfaf4fedef8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing key packages (fast)..\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstall cell done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this in a code cell (keep the !)\n",
        "# idempotent: will skip clone if already present\n",
        "!if [ ! -d /content/generative-models ]; then git clone https://github.com/Stability-AI/generative-models.git /content/generative-models; else echo \"generative-models exists\"; fi\n",
        "!pip install -q -e /content/generative-models || true\n",
        "print(\"generative-models clone+install step finished\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhcFGcLgKlbk",
        "outputId": "44b182c5-40f9-492f-bfc4-821b95fc5094"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/generative-models'...\n",
            "remote: Enumerating objects: 1140, done.\u001b[K\n",
            "remote: Counting objects: 100% (562/562), done.\u001b[K\n",
            "remote: Compressing objects: 100% (177/177), done.\u001b[K\n",
            "remote: Total 1140 (delta 438), reused 390 (delta 385), pack-reused 578 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1140/1140), 86.66 MiB | 13.60 MiB/s, done.\n",
            "Resolving deltas: 100% (604/604), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building editable for sgm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "generative-models clone+install step finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "if \"/content/generative-models\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/generative-models\")\n",
        "print(\"sys.path updated\")\n",
        "\n",
        "try:\n",
        "    import sgm\n",
        "    print(\"✅ sgm import OK:\", sgm.__file__)\n",
        "except Exception as e:\n",
        "    print(\"❌ sgm import failed:\", e)\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dixu41sVKns0",
        "outputId": "5c910e3a-5fd2-4319-cd1c-9beeb92446d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.path updated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.diffusionmodules.model:no module 'xformers'. Processing without...\n",
            "WARNING:sgm.modules.attention:no module 'xformers'. Processing without...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ sgm import OK: /content/generative-models/sgm/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "TYPE2PATH = {\n",
        "    \"svd\": [\"stabilityai/stable-video-diffusion-img2vid\",\"svd.safetensors\"],\n",
        "    \"svd-xt\": [\"stabilityai/stable-video-diffusion-img2vid-xt\",\"svd_xt.safetensors\"],\n",
        "    \"svd-xt-1-1\": [\"stabilityai/stable-video-diffusion-img2vid-xt-1-1\",\"svd_xt_1_1.safetensors\"],\n",
        "}\n",
        "repo_id,fname = TYPE2PATH.get(SVD_VERSION)\n",
        "ckpt_path = os.path.join(CHECKPOINT_DIR, fname)\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(\"✔ Checkpoint exists:\", ckpt_path)\n",
        "else:\n",
        "    print(\"⬇ Downloading checkpoint (may be big)...\")\n",
        "    hf_hub_download(repo_id=repo_id, filename=fname, local_dir=CHECKPOINT_DIR)\n",
        "    print(\"✔ Downloaded:\", ckpt_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "fc133541cd924c1298ff925dee9d7372",
            "e795a3629dcf450599f50752ec902a73",
            "7e77ce3559c3495ab9405a72b38f2fea",
            "287145738c1e4754bfbb1b1fe7406914",
            "27aa96e840134db0b6689ddb2256df9b",
            "e931cfb52711465b8ea790fc47983fba",
            "11850c52f4934f28ae25f998b824de49",
            "da9a07ef23124d24af5263627d9a6413",
            "5c6c79d595a4418a9f5219704ec8fdd5",
            "e063b33126a4453793d04bfac8405f77",
            "25fc791084d5448983f3c6dcab4c44c8"
          ]
        },
        "id": "v91SqlsEKrl4",
        "outputId": "361db6ab-3af7-4b20-d788-5c249ff3b801"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇ Downloading checkpoint (may be big)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "svd_xt_1_1.safetensors:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc133541cd924c1298ff925dee9d7372"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Downloaded: /content/checkpoints/svd_xt_1_1.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "from sgm.util import instantiate_from_config\n",
        "\n",
        "def load_model_local(config_path, ckpt_path, device='cuda', num_frames=14, num_steps=25):\n",
        "    config = OmegaConf.load(config_path)\n",
        "    config.model.params.ckpt_path = ckpt_path\n",
        "    config.model.params.sampler_config.params.num_steps = num_steps\n",
        "    config.model.params.sampler_config.params.guider_config.params.num_frames = num_frames\n",
        "    with torch.device(device):\n",
        "        model = instantiate_from_config(config.model).to(device).eval().requires_grad_(False)\n",
        "    return model\n",
        "\n",
        "if \"xt\" in SVD_VERSION:\n",
        "    model_config = \"/content/generative-models/scripts/sampling/configs/svd_xt.yaml\"\n",
        "    num_frames = 25; num_steps = 30\n",
        "else:\n",
        "    model_config = \"/content/generative-models/scripts/sampling/configs/svd.yaml\"\n",
        "    num_frames = 14; num_steps = 25\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Loading model on\", device)\n",
        "model = load_model_local(model_config, ckpt_path, device=device, num_frames=num_frames, num_steps=num_steps)\n",
        "print(\"🔥 Model loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743,
          "referenced_widgets": [
            "6d70c588ad7747be8670bff5dff76ed4",
            "39d9248dad02476a933fc9d9935396d7",
            "cd8614823a2949a2a09bff30d9892b33",
            "f3bf918c33464a0e96097b4148e4daf7",
            "570a93c1e421493f979bd9492a397807",
            "b222edd5102a4aefb9ddc2e1f2b76697",
            "c9a21f0ad2824f82ba757b1756566aaa",
            "37aa28c2b2fa4d0490e1da4f1d853539",
            "09ca4b284c70481fb7bdd5758cede411",
            "913748a1e37f4664b137da9749055328",
            "ca64ed380e834192bdf0f3ee1c28457a"
          ]
        },
        "id": "sIm_THuvKvjt",
        "outputId": "00e212d1-f3a6-4189-d1de-ed10b4a2aa50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model on cpu\n",
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n",
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n",
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n",
            "WARNING:sgm.modules.attention:Attention mode 'softmax-xformers' is not available. Falling back to native attention. This is not a problem in Pytorch >= 2.0. FYI, you are running with PyTorch version 2.8.0+cu126.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoTransformerBlock is using checkpointing\n",
            "VideoTransformerBlock is using checkpointing\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/3.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d70c588ad7747be8670bff5dff76ed4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False\n",
            "Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False\n",
            "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
            "Restored from /content/checkpoints/svd_xt_1_1.safetensors with 0 missing and 0 unexpected keys\n",
            "🔥 Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract a frame at 1s from your uploaded video\n",
        "!ffmpeg -ss 00:00:01 -i \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\" -frames:v 1 /content/frame_for_svd.png -y\n",
        "print(\"Frame saved to /content/frame_for_svd.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIUNAHBdKy1D",
        "outputId": "4c6db425-88d2-4b26-88cd-321fa965694c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[1;31m/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4: No such file or directory\n",
            "\u001b[0mFrame saved to /content/frame_for_svd.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Define infer() wrapper that calls the notebook's sample() if available ===\n",
        "import random, os, traceback\n",
        "\n",
        "def infer(input_path: str,\n",
        "          resize_image: bool = True,\n",
        "          n_frames: int = 14,\n",
        "          n_steps: int = 25,\n",
        "          seed: str = \"random\",\n",
        "          decoding_t: int = 1,\n",
        "          fps_id: int = 6,\n",
        "          motion_bucket_id: int = 127,\n",
        "          cond_aug: float = 0.02,\n",
        "          skip_filter: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Wrapper to call the notebook's sample(...) function and return the created video path.\n",
        "    Requires the original notebook's sample(...) implementation to be present in the session.\n",
        "    \"\"\"\n",
        "    if seed == \"random\":\n",
        "        seed = random.randint(0, 2**31-1)\n",
        "    try:\n",
        "        # Try to call the existing sample() function used by the original notebook\n",
        "        out_paths = sample(\n",
        "            input_path=input_path,\n",
        "            resize_image=resize_image,\n",
        "            num_frames=int(n_frames),\n",
        "            num_steps=int(n_steps),\n",
        "            fps_id=int(fps_id),\n",
        "            motion_bucket_id=int(motion_bucket_id),\n",
        "            cond_aug=float(cond_aug),\n",
        "            seed=int(seed),\n",
        "            decoding_t=int(decoding_t),\n",
        "            device=device,        # depends on the notebook Load Model cell setting\n",
        "            skip_filter=skip_filter\n",
        "        )\n",
        "        # sample() usually returns a list of output paths\n",
        "        if isinstance(out_paths, (list, tuple)) and len(out_paths)>0:\n",
        "            return out_paths[0]\n",
        "        elif isinstance(out_paths, str):\n",
        "            return out_paths\n",
        "        else:\n",
        "            raise RuntimeError(f\"sample() returned unexpected value: {out_paths}\")\n",
        "    except NameError as e:\n",
        "        # sample() not defined — helpful guidance\n",
        "        raise NameError(\n",
        "            \"sample() or model sampling functions are not defined in this session. \"\n",
        "            \"Please run the notebook cells named 'Sampling function' or 'Do the Run!' that define sample()/infer().\\n\"\n",
        "            \"If you want, paste the original sample() implementation into a cell and re-run this cell.\"\n",
        "        ) from e\n",
        "    except Exception as e:\n",
        "        # bubble up other errors with traceback for debugging\n",
        "        traceback.print_exc()\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "bYZLfKKuNSZ1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try calling infer() if your notebook defines it. If NameError, run the Sampling / Do the Run! cells from the original notebook.\n",
        "try:\n",
        "    out_path = infer(\"/content/frame_for_svd.png\", True, num_frames, num_steps, \"random\", 1, 6, 127, 0.02, skip_filter=True)\n",
        "    print(\"Generated video at:\", out_path)\n",
        "    # show it\n",
        "    from IPython.display import Video, display\n",
        "    display(Video(out_path, embed=True, width=360))\n",
        "except NameError:\n",
        "    print(\"infer() is not defined in this session. Scroll up and run the original notebook's 'Sampling function' / 'Do the Run!' cells, or paste the sample()/infer() code into a cell.\")\n",
        "except Exception as e:\n",
        "    print(\"infer() failed:\", e)\n",
        "    raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qSnkOEfK08Q",
        "outputId": "76ac207f-9097-401c-bea4-8fbcdf9c23a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "infer() is not defined in this session. Scroll up and run the original notebook's 'Sampling function' / 'Do the Run!' cells, or paste the sample()/infer() code into a cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "os.makedirs(OUTPUT_DRIVE_FOLDER, exist_ok=True)\n",
        "if 'out_path' in globals() and out_path:\n",
        "    dst = os.path.join(OUTPUT_DRIVE_FOLDER, \"demo_output.mp4\")\n",
        "    shutil.copy(out_path, dst)\n",
        "    print(\"Saved output to Drive:\", dst)\n",
        "else:\n",
        "    print(\"No out_path found. Run infer() first or check previous cells.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wylydMLAK3IE",
        "outputId": "51bb880c-417f-4186-f3b3-8ac94c2c93b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No out_path found. Run infer() first or check previous cells.\n"
          ]
        }
      ]
    }
  ]
}