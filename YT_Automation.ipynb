{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp6YvcGS2Vkq9QFYvh7qGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicreativeexplorer/YT-Automation/blob/main/YT_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === AUTO-RUN HEARTBEAT (every 60 minutes) ===\n",
        "import threading, time, IPython\n",
        "\n",
        "HEARTBEAT_INTERVAL = 60 * 60   # 60 minutes\n",
        "\n",
        "def heartbeat_loop():\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"\\n‚ù§Ô∏è  Heartbeat triggered ‚Äî auto-running keepalive cell...\")\n",
        "            IPython.display.display(IPython.display.Javascript(\n",
        "                'google.colab.kernel.invokeFunction(\"keepalive\", [], {});'\n",
        "            ))\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Heartbeat error:\", e)\n",
        "        time.sleep(HEARTBEAT_INTERVAL)\n",
        "\n",
        "def start_heartbeat():\n",
        "    t = threading.Thread(target=heartbeat_loop, daemon=True)\n",
        "    t.start()\n",
        "    print(\"üî• Auto-run heartbeat started (interval = 60 min).\")\n",
        "\n",
        "# Register a hidden keepalive callback\n",
        "from google.colab import output\n",
        "def _keepalive():\n",
        "    print(\"‚è≥ Notebook auto-ran keepalive at\", time.ctime())\n",
        "output.register_callback(\"keepalive\", _keepalive)\n",
        "\n",
        "start_heartbeat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "tIwvr7z92m-0",
        "outputId": "dd5937b9-5fbb-4a26-c671-d7b09ab99892"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ù§Ô∏è  Heartbeat triggered ‚Äî auto-running keepalive cell...\n",
            "üî• Auto-run heartbeat started (interval = 60 min).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.kernel.invokeFunction(\"keepalive\", [], {});"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Notebook auto-ran keepalive at Fri Nov 21 14:09:42 2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_autosave(interval_sec=300)  # every 5 minutes snapshot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "uHF0ehFj3va1",
        "outputId": "67a241eb-db63-41ce-e224-4bd9712eb226"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'start_autosave' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15505181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_autosave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# every 5 minutes snapshot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'start_autosave' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTO-PERSIST STARTUP CELL ‚Äî paste & run at top of notebook (one cell)\n",
        "# - mounts Drive\n",
        "# - auto-restores uploaded sample from /mnt/data (if present) into /content and Drive\n",
        "# - provides save(file) and start_autosave(interval_sec) helpers\n",
        "# - optional: simple GitHub push helper for small files (needs GITHUB_TOKEN env)\n",
        "\n",
        "import os, shutil, time, threading\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "# change these if you want a different Drive folder\n",
        "DRIVE_BASE = Path(\"/content/drive/MyDrive/AI-Automation\")\n",
        "DRIVE_SAMPLE = DRIVE_BASE / \"sample.mp4\"\n",
        "DRIVE_CHECKPOINTS = DRIVE_BASE / \"checkpoints\"\n",
        "DRIVE_OUTPUTS = DRIVE_BASE / \"outputs\"\n",
        "LOCAL_CONTENT_DIR = Path(\"/content\")\n",
        "LOCAL_SAMPLE_TARGET = LOCAL_CONTENT_DIR / \"sample_from_upload.mp4\"\n",
        "\n",
        "# known uploaded path from this session (auto-detect fallback)\n",
        "POSSIBLE_UPLOAD_PATHS = [\n",
        "    Path(\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"),\n",
        "    Path(\"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"),\n",
        "]\n",
        "\n",
        "# ---------- Mount Drive ----------\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_BASE.mkdir(parents=True, exist_ok=True)\n",
        "DRIVE_OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
        "DRIVE_CHECKPOINTS.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Drive mounted at /content/drive\")\n",
        "\n",
        "# ---------- Auto-detect uploaded mp4 and copy to Drive + /content ----------\n",
        "def find_uploaded():\n",
        "    # check known locations first\n",
        "    for p in POSSIBLE_UPLOAD_PATHS:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    # fallback: search /content and /mnt for any mp4\n",
        "    for root in [Path(\"/content\"), Path(\"/mnt\")]:\n",
        "        if root.exists():\n",
        "            mp4s = list(root.rglob(\"*.mp4\"))\n",
        "            if mp4s:\n",
        "                return mp4s[0]\n",
        "    return None\n",
        "\n",
        "uploaded = find_uploaded()\n",
        "if uploaded:\n",
        "    print(\"Found uploaded file:\", uploaded)\n",
        "    # copy into /content (so pipeline expects it there)\n",
        "    try:\n",
        "        shutil.copy2(str(uploaded), str(LOCAL_SAMPLE_TARGET))\n",
        "        print(\"Copied uploaded file ->\", LOCAL_SAMPLE_TARGET)\n",
        "    except Exception as e:\n",
        "        print(\"Warn: failed to copy to /content:\", e)\n",
        "    # copy into Drive sample path if not already present or newer\n",
        "    try:\n",
        "        if (not DRIVE_SAMPLE.exists()) or (uploaded.stat().st_mtime > DRIVE_SAMPLE.stat().st_mtime):\n",
        "            shutil.copy2(str(uploaded), str(DRIVE_SAMPLE))\n",
        "            print(\"Copied uploaded file -> Drive:\", DRIVE_SAMPLE)\n",
        "        else:\n",
        "            print(\"Drive sample already exists and is newer. Skipping Drive copy.\")\n",
        "    except Exception as e:\n",
        "        print(\"Warn: failed to copy to Drive:\", e)\n",
        "else:\n",
        "    print(\"No uploaded mp4 found in standard locations. If you have a sample in Drive, it will be used when needed.\")\n",
        "\n",
        "# ---------- Helper: save(file) -> copies file to Drive outputs with timestamp ----------\n",
        "def save_to_drive(local_path, dest_name=None):\n",
        "    local_path = Path(local_path)\n",
        "    if not local_path.exists():\n",
        "        raise FileNotFoundError(f\"Local file not found: {local_path}\")\n",
        "    ts = int(time.time())\n",
        "    dest = DRIVE_OUTPUTS / (dest_name or f\"{local_path.stem}_{ts}{local_path.suffix}\")\n",
        "    shutil.copy2(str(local_path), str(dest))\n",
        "    print(\"Saved to Drive:\", dest)\n",
        "    return dest\n",
        "\n",
        "# ---------- Optional: GitHub push helper for small files (100MB limit) ----------\n",
        "def git_push_small(file_path, repo=\"aicreativeexplorer/YT-Automation\", branch=\"main\"):\n",
        "    \"\"\"\n",
        "    Push a small file to your GitHub repo. Requires env var GITHUB_TOKEN set in session.\n",
        "    Use: import os; os.environ['GITHUB_TOKEN']=\"ghp_xxx\" in a private cell before calling.\n",
        "    \"\"\"\n",
        "    token = os.environ.get(\"GITHUB_TOKEN\")\n",
        "    if not token:\n",
        "        raise EnvironmentError(\"Set GITHUB_TOKEN env var (repo push).\")\n",
        "    tmp = Path(\"/tmp/git_push_repo\")\n",
        "    if tmp.exists():\n",
        "        shutil.rmtree(tmp)\n",
        "    tmp.mkdir()\n",
        "    # clone and copy, commit\n",
        "    os.system(f\"git clone https://{token}@github.com/{repo}.git {tmp}\")\n",
        "    shutil.copy2(str(file_path), str(tmp / Path(file_path).name))\n",
        "    cur = os.getcwd()\n",
        "    os.chdir(tmp)\n",
        "    os.system('git config user.email \"colab@local\"')\n",
        "    os.system('git config user.name \"ColabAuto\"')\n",
        "    os.system(f'git add {Path(file_path).name} && git commit -m \"Add {Path(file_path).name}\" || echo \"nothing to commit\"')\n",
        "    os.system(f'git push origin {branch} || echo \"push failed\"')\n",
        "    os.chdir(cur)\n",
        "    print(\"Attempted push to GitHub (check repo).\")\n",
        "\n",
        "# ---------- Autosave thread: sync /content -> Drive every N seconds ----------\n",
        "_autosave_thread = None\n",
        "_autosave_stop = threading.Event()\n",
        "\n",
        "def _autosave_loop(interval_sec=60, paths_to_sync=None):\n",
        "    paths_to_sync = paths_to_sync or [\"/content\"]\n",
        "    while not _autosave_stop.is_set():\n",
        "        try:\n",
        "            ts = int(time.time())\n",
        "            backup_dir = DRIVE_BASE / \"session_backups\" / f\"backup_{ts}\"\n",
        "            backup_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for p in paths_to_sync:\n",
        "                src = Path(p)\n",
        "                if not src.exists():\n",
        "                    continue\n",
        "                # copy only top-level files (fast) and small dirs; avoid huge copy every loop\n",
        "                for f in src.glob(\"*\"):\n",
        "                    # skip Drive mount itself to avoid recursion\n",
        "                    if \"/content/drive\" in str(f):\n",
        "                        continue\n",
        "                    # only copy files under 200MB by default (safe)\n",
        "                    try:\n",
        "                        if f.is_file() and f.stat().st_size < 200 * 1024 * 1024:\n",
        "                            shutil.copy2(str(f), str(backup_dir / f.name))\n",
        "                        # small dir handling: copy single-level files\n",
        "                        elif f.is_dir():\n",
        "                            for sf in f.glob(\"*\"):\n",
        "                                if sf.is_file() and sf.stat().st_size < 200 * 1024 * 1024:\n",
        "                                    destd = backup_dir / f.name\n",
        "                                    destd.mkdir(parents=True, exist_ok=True)\n",
        "                                    shutil.copy2(str(sf), str(destd / sf.name))\n",
        "                    except Exception as e:\n",
        "                        print(\"Autosave copy warning for\", f, e)\n",
        "            print(f\"[autosave] synced snapshot to {backup_dir}\")\n",
        "        except Exception as e:\n",
        "            print(\"Autosave loop error:\", e)\n",
        "        _autosave_stop.wait(interval_sec)\n",
        "\n",
        "def start_autosave(interval_sec=120, paths_to_sync=None):\n",
        "    global _autosave_thread, _autosave_stop\n",
        "    if _autosave_thread and _autosave_thread.is_alive():\n",
        "        print(\"Autosave already running.\")\n",
        "        return\n",
        "    _autosave_stop.clear()\n",
        "    _autosave_thread = threading.Thread(target=_autosave_loop, args=(interval_sec, paths_to_sync), daemon=True)\n",
        "    _autosave_thread.start()\n",
        "    print(\"Started autosave thread: interval\", interval_sec, \"sec\")\n",
        "\n",
        "def stop_autosave():\n",
        "    global _autosave_thread, _autosave_stop\n",
        "    if _autosave_thread and _autosave_thread.is_alive():\n",
        "        _autosave_stop.set()\n",
        "        _autosave_thread.join(timeout=5)\n",
        "        print(\"Stopped autosave thread.\")\n",
        "    else:\n",
        "        print(\"No autosave running.\")\n",
        "\n",
        "# ---------- Quick usage hints printed ----------\n",
        "print(\"\\nREADY ‚Äî auto-persistence enabled.\")\n",
        "print(\"Detected sample (if any):\", uploaded or \"NONE\")\n",
        "print(\"Local sample target:\", LOCAL_SAMPLE_TARGET)\n",
        "print(\"Drive sample path  :\", DRIVE_SAMPLE)\n",
        "print(\"Drive outputs path :\", DRIVE_OUTPUTS)\n",
        "print(\"\\nFunctions you can call:\")\n",
        "print(\"  save_to_drive(local_path)   # copy file to Drive outputs\")\n",
        "print(\"  start_autosave(interval_sec=120)  # begin background autosave of /content -> Drive\")\n",
        "print(\"  stop_autosave()             # stop background autosave\")\n",
        "print(\"  git_push_small(local_file)  # optional small-file push (requires GITHUB_TOKEN env)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywIm0Eny2IFT",
        "outputId": "3f41f86c-fedb-4525-bbd5-f9441aec5867"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Drive mounted at /content/drive\n",
            "Found uploaded file: /content/sample_from_upload.mp4\n",
            "Warn: failed to copy to /content: '/content/sample_from_upload.mp4' and '/content/sample_from_upload.mp4' are the same file\n",
            "Copied uploaded file -> Drive: /content/drive/MyDrive/AI-Automation/sample.mp4\n",
            "\n",
            "READY ‚Äî auto-persistence enabled.\n",
            "Detected sample (if any): /content/sample_from_upload.mp4\n",
            "Local sample target: /content/sample_from_upload.mp4\n",
            "Drive sample path  : /content/drive/MyDrive/AI-Automation/sample.mp4\n",
            "Drive outputs path : /content/drive/MyDrive/AI-Automation/outputs\n",
            "\n",
            "Functions you can call:\n",
            "  save_to_drive(local_path)   # copy file to Drive outputs\n",
            "  start_autosave(interval_sec=120)  # begin background autosave of /content -> Drive\n",
            "  stop_autosave()             # stop background autosave\n",
            "  git_push_small(local_file)  # optional small-file push (requires GITHUB_TOKEN env)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhGVcsjW4nbQ",
        "outputId": "aaa623b3-2692-4b93-d9e6-643578888971"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 1) Inspect what's currently in /content/drive\n",
        "echo \"Contents of /content/drive BEFORE fix:\"\n",
        "ls -la /content/drive || true\n",
        "echo \"----\"\n",
        "\n",
        "# 2) If non-empty, move it to a safe backup folder instead of deleting\n",
        "mkdir -p /content/drive_backup || true\n",
        "if [ \"$(ls -A /content/drive 2>/dev/null)\" ]; then\n",
        "  echo \"Moving existing /content/drive/* -> /content/drive_backup/\"\n",
        "  mv /content/drive/* /content/drive_backup/ 2>/dev/null || true\n",
        "  echo \"Moved. Backup dir: /content/drive_backup/\"\n",
        "else\n",
        "  echo \"/content/drive is already empty.\"\n",
        "fi\n",
        "echo \"----\"\n",
        "\n",
        "# 3) Ensure mountpoint dir exists and is empty\n",
        "rm -rf /content/drive\n",
        "mkdir -p /content/drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJlgXIlX3heX",
        "outputId": "21170c36-ce1d-45a1-f0d5-3ab03db88587"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive BEFORE fix:\n",
            "total 16\n",
            "dr-x------ 4 root root 4096 Nov 21 14:10 .Encrypted\n",
            "drwx------ 2 root root 4096 Nov 21 14:10 MyDrive\n",
            "dr-x------ 2 root root 4096 Nov 21 14:10 .shortcut-targets-by-id\n",
            "drwx------ 5 root root 4096 Nov 21 14:10 .Trash-0\n",
            "----\n",
            "Moving existing /content/drive/* -> /content/drive_backup/\n",
            "Moved. Backup dir: /content/drive_backup/\n",
            "----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive': Operation canceled\n",
            "rm: cannot remove '/content/drive/.shortcut-targets-by-id': Operation canceled\n",
            "rm: cannot remove '/content/drive/.Trash-0': Directory not empty\n",
            "rm: cannot remove '/content/drive/.Encrypted/MyDrive': Operation canceled\n",
            "rm: cannot remove '/content/drive/.Encrypted/.shortcut-targets-by-id': Operation canceled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "SRC=\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "if [ -f \"$SRC\" ]; then\n",
        "  mkdir -p /content/drive/MyDrive/AI-Automation\n",
        "  cp \"$SRC\" /content/drive/MyDrive/AI-Automation/sample.mp4\n",
        "  cp \"$SRC\" \"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "  echo \"Copied uploaded file to Drive and /content.\"\n",
        "else\n",
        "  echo \"WARNING: Uploaded file missing at $SRC\"\n",
        "fi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Y8T7ZI4xxm",
        "outputId": "6f25fe71-587d-45fc-cdfa-ec34482556dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Uploaded file missing at /mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiafjBDXAm5J",
        "outputId": "673f288e-3ea4-4142-e84e-0ae83a308416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG OK\n"
          ]
        }
      ],
      "source": [
        "# CONFIG ‚Äî edit only if you moved paths\n",
        "REPO_DIR = \"/content/YT-Automation\"\n",
        "NOTEBOOK_NAME = \"YT-Automation.ipynb\"\n",
        "UPLOADED_VIDEO = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"  # your uploaded demo\n",
        "DRIVE_TOKEN_PATH = \"/content/drive/MyDrive/AI-Automation/hf_token.txt\"  # put HF token here\n",
        "OUTPUT_DRIVE_FOLDER = \"/content/drive/MyDrive/AI-Automation/outputs/stitched\"\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/AI-Automation/checkpoints\"\n",
        "SVD_VERSION = \"svd\"  # 'svd' (open) or 'svd-xt-1-1' (better but gated)\n",
        "USE_AUTO_PUSH = False  # no auto-push by default\n",
        "print(\"CONFIG OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Auto-login to HuggingFace if token present in Drive\n",
        "import os\n",
        "if os.path.exists(DRIVE_TOKEN_PATH):\n",
        "    from huggingface_hub import login\n",
        "    with open(DRIVE_TOKEN_PATH,'r') as f:\n",
        "        token = f.read().strip()\n",
        "    login(token=token)\n",
        "    print(\"Logged into HuggingFace from Drive token.\")\n",
        "else:\n",
        "    print(\"No HF token at\", DRIVE_TOKEN_PATH, \"- you'll be asked if downloading gated models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg2ZtRuIFxet",
        "outputId": "828dee97-eb16-4dcb-b69a-0765315fcf3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "No HF token at /content/drive/MyDrive/AI-Automation/hf_token.txt - you'll be asked if downloading gated models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# minimal set used by pipeline\n",
        "pip install -q kornia open_clip_torch timm transformers safetensors accelerate pytorch-lightning einops imageio-ffmpeg imwatermark opencv-python-headless==4.6.0.66 gradio==3.34.0\n",
        "# RIFE + Real-ESRGAN notebooks will install their deps inside their cells when needed.\n",
        "echo \"installed deps\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMkH4koVGfWG",
        "outputId": "d13a2a18-7552-4938-9022-285a6a10f68a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installed deps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# clone once per session\n",
        "if [ ! -d /content/generative-models ]; then\n",
        "  git clone https://github.com/Stability-AI/generative-models.git /content/generative-models\n",
        "fi\n",
        "# small helper scripts (won't break if run multiple times)\n",
        "mkdir -p /content/scripts\n",
        "cat > /content/scripts/ffmpeg_stitch.sh <<'SH'\n",
        "#!/usr/bin/env bash\n",
        "# Usage: ./ffmpeg_stitch.sh out.mp4 file1.mp4 file2.mp4 ...\n",
        "out=\"$1\"; shift\n",
        "# convert to ts and concat\n",
        "tsfiles=\"\"\n",
        "for f in \"$@\"; do\n",
        "  ts=\"/tmp/$(basename \"$f\").ts\"\n",
        "  ffmpeg -y -i \"$f\" -c copy -bsf:v h264_mp4toannexb -f mpegts \"$ts\"\n",
        "  tsfiles=\"${tsfiles}|${ts}\"\n",
        "done\n",
        "tsfiles=${tsfiles#|}\n",
        "ffmpeg -y -i \"concat:${tsfiles}\" -c copy -bsf:a aac_adtstoasc \"$out\"\n",
        "SH\n",
        "chmod +x /content/scripts/ffmpeg_stitch.sh\n",
        "echo \"cloned generative-models; helper scripts in /content/scripts\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WUgqUqpGi59",
        "outputId": "fe95acf9-e03e-4f4a-b77f-1ff3c09c4d4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloned generative-models; helper scripts in /content/scripts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/content/generative-models'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, uuid, json, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "def run_cmd(cmd, quiet=False):\n",
        "    print(\"RUN:\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if not quiet:\n",
        "        print(p.stdout)\n",
        "        if p.stderr:\n",
        "            print(\"ERR:\", p.stderr[:1000])\n",
        "    return p\n",
        "\n",
        "def ensure_folder(p):\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "ensure_folder(OUTPUT_DRIVE_FOLDER)\n",
        "ensure_folder(CHECKPOINT_DIR)\n",
        "\n",
        "# ---- SVD: wrapper (placeholder) ----\n",
        "def generate_svd_from_text(prompt, seed=None, num_frames=14, out_prefix=\"svd\"):\n",
        "    \"\"\"\n",
        "    Minimal wrapper to call SVD sampling. The heavy work is in the SVD notebook code.\n",
        "    Here we assume `sample()` exists in session OR we call a local script.\n",
        "    For now this function writes a JSON config file for the manual SVD notebook to pick up.\n",
        "    \"\"\"\n",
        "    jobid = f\"{out_prefix}_{int(time.time())}_{uuid.uuid4().hex[:6]}\"\n",
        "    jobdir = f\"/tmp/{jobid}\"\n",
        "    ensure_folder(jobdir)\n",
        "    cfg = {\n",
        "        \"prompt\": prompt,\n",
        "        \"seed\": seed or \"random\",\n",
        "        \"num_frames\": num_frames,\n",
        "        \"out\": f\"{jobdir}/{jobid}.mp4\"\n",
        "    }\n",
        "    cfg_path = f\"{jobdir}/cfg.json\"\n",
        "    with open(cfg_path,'w') as f: json.dump(cfg,f)\n",
        "    print(\"SVD job written:\", cfg_path)\n",
        "    # NOTE: actual execution will be in the notebook cell that imports the SVD sampling code\n",
        "    return cfg[\"out\"], jobdir\n",
        "\n",
        "# ---- RIFE: interpolation wrapper ----\n",
        "def interpolate_with_rife(infile, factor=4):\n",
        "    out = f\"{Path(infile).with_suffix('')}_rife.mp4\"\n",
        "    # Call public RIFE Colab? For now we use a simple ffmpeg fps trick as placeholder\n",
        "    run_cmd(f\"ffmpeg -y -i '{infile}' -filter:v 'minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1' -c:v libx264 -crf 18 '{out}'\")\n",
        "    return out\n",
        "\n",
        "# ---- Real-ESRGAN: upscale wrapper (placeholder) ----\n",
        "def upscale_realesrgan(infile, scale=2):\n",
        "    out = f\"{Path(infile).with_suffix('')}_up.mp4\"\n",
        "    # placeholder: re-encode at higher resolution (actual Real-ESRGAN model would process frames)\n",
        "    run_cmd(f\"ffmpeg -y -i '{infile}' -vf scale=iw*{scale}:ih*{scale} -c:v libx264 -crf 18 '{out}'\")\n",
        "    return out\n",
        "\n",
        "# ---- Stitch helper ----\n",
        "def stitch_files(inputs, out):\n",
        "    inputs = [str(i) for i in inputs]\n",
        "    run_cmd(f\"/content/scripts/ffmpeg_stitch.sh '{out}' \" + \" \".join([f\"'{i}'\" for i in inputs]))\n",
        "    return out\n",
        "\n",
        "# ---- TTS helper (ElevenLabs fallback) ----\n",
        "def tts_generate(text, outfile=\"/tmp/tts.wav\", provider=\"free\"):\n",
        "    \"\"\"\n",
        "    provider: 'elevenlabs' (needs key), 'gtts' (free).\n",
        "    This is a simple wrapper: I recommend hooking to ElevenLabs for quality or use gTTS for free.\n",
        "    \"\"\"\n",
        "    if provider==\"gtts\":\n",
        "        # install gTTS if needed\n",
        "        run_cmd(\"python -m pip install -q gTTS pydub\")\n",
        "        from gtts import gTTS\n",
        "        tts = gTTS(text=text, lang='en')\n",
        "        tts.save(outfile)\n",
        "        return outfile\n",
        "    else:\n",
        "        # try gTTS as default\n",
        "        run_cmd(\"python -m pip install -q gTTS pydub\")\n",
        "        from gtts import gTTS\n",
        "        tts = gTTS(text=text, lang='en')\n",
        "        tts.save(outfile)\n",
        "        return outfile\n",
        "\n",
        "# ---- Caption burn-in (ffmpeg) ----\n",
        "def burn_captions(video_in, text, out):\n",
        "    # naive single-line centered caption\n",
        "    cmd = (\n",
        "        f'ffmpeg -y -i \"{video_in}\" -vf '\n",
        "        f\"\\\"drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf: text='{text}':\"\n",
        "        \"fontcolor=white:fontsize=48:box=1:boxcolor=0x00000099:boxborderw=5:x=(w-text_w)/2:y=h-150\\\" \"\n",
        "        f'-c:a copy \"{out}\"'\n",
        "    )\n",
        "    run_cmd(cmd)\n",
        "    return out\n",
        "\n",
        "print(\"Helpers loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs0SlVlgGmJQ",
        "outputId": "8964b314-8c03-4603-c1d1-73370f14d83d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helpers loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEXT-ONLY MODE ‚Äî create config and call SVD job (sample wrapper)\n",
        "prompt = \"9:16 vertical, ultra-detailed close-up of a tiny mechanical fox exploring a sunlit garden, cinematic shallow depth-of-field, warm color grade, soft motion. No text or logos.\"\n",
        "out_mp4, jobdir = generate_svd_from_text(prompt, seed=1234, num_frames=25, out_prefix=\"tinyfox\")\n",
        "print(\"SVD job created. Local jobdir:\", jobdir)\n",
        "print(\"Once SVD sampling cell runs, output will be:\", out_mp4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU3GNFpAGsiY",
        "outputId": "9e90e0c8-761f-4bdd-f10c-9d01bad4cfd5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD job written: /tmp/tinyfox_1763734321_7d96f6/cfg.json\n",
            "SVD job created. Local jobdir: /tmp/tinyfox_1763734321_7d96f6\n",
            "Once SVD sampling cell runs, output will be: /tmp/tinyfox_1763734321_7d96f6/tinyfox_1763734321_7d96f6.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RylNAMd2xiS6",
        "outputId": "9281ca9f-0727-4133-c79b-0c3500a76ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7312bea-1795-4d7e-a4e8-787891f81a92\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7312bea-1795-4d7e-a4e8-787891f81a92\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "W1Alez_Ux_4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE-TO-VIDEO MODE\n",
        "# Use your uploaded file to extract a conditioning frame (change timestamp if you want)\n",
        "import os\n",
        "frame_path = \"/content/frame_for_svd.png\"\n",
        "run_cmd(f\"ffmpeg -y -ss 00:00:01 -i '{UPLOADED_VIDEO}' -frames:v 1 '{frame_path}'\")\n",
        "print(\"Extracted frame:\", frame_path)\n",
        "\n",
        "# Now create SVD job that uses this image\n",
        "prompt_image = \"9:16 vertical, mechanical fox exploring, use this frame as a style reference. No text.\"\n",
        "out_mp4_img, jobdir_img = generate_svd_from_text(prompt_image, seed=999, num_frames=25, out_prefix=\"img2vid\")\n",
        "# attach the frame info to jobdir so the sampling cell can pick it\n",
        "open(f\"{jobdir_img}/cond_frame.txt\",\"w\").write(frame_path)\n",
        "print(\"Image->video job created at\", jobdir_img, \"expected out:\", out_mp4_img)\n"
      ],
      "metadata": {
        "id": "5y_8wn01Gtgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-dejavu-core\n"
      ],
      "metadata": {
        "id": "ksm7tOZFQouV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -y -qq fonts-dejavu-core\n"
      ],
      "metadata": {
        "id": "37gVI4ukKbrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -version\n",
        "!ffmpeg -hide_banner -filters | grep -E 'drawtext|minterpolate' || true\n"
      ],
      "metadata": {
        "id": "8SfFZSKlbQPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "JOBDIR=\"/tmp/svd_job_fix_$(date +%s)\"\n",
        "mkdir -p \"$JOBDIR\"\n",
        "OUT=\"$JOBDIR/simulated_svd.mp4\"\n",
        "IN=\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "ffmpeg -y -i \"$IN\" -t 6 \\\n",
        "  -vf \"scale=720:1280:force_original_aspect_ratio=decrease,pad=720:1280:(ow-iw)/2:(oh-ih)/2,drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='SIMULATED SVD':fontsize=28:fontcolor=white:x=20:y=40\" \\\n",
        "  -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart \"$OUT\"\n",
        "\n",
        "echo \"DONE -> $OUT\"\n",
        "ls -lh \"$OUT\" || true\n"
      ],
      "metadata": {
        "id": "3xKnr51yKiHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, uuid, time\n",
        "from pathlib import Path\n",
        "\n",
        "# Your uploaded file\n",
        "IN = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "# Create job folder\n",
        "job_id = f\"svd_job_{int(time.time())}_{uuid.uuid4().hex[:6]}\"\n",
        "jobdir = Path(f\"/tmp/{job_id}\")\n",
        "jobdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "OUT = jobdir / f\"{job_id}.mp4\"\n",
        "\n",
        "print(\"Creating simulated SVD output WITHOUT lavfi source...\")\n",
        "print(\"Input:\", IN)\n",
        "print(\"Output:\", OUT)\n",
        "\n",
        "# 1) extract a single frame as PNG\n",
        "frame = jobdir / \"frame.png\"\n",
        "cmd1 = f\"ffmpeg -y -i '{IN}' -vframes 1 '{frame}'\"\n",
        "subprocess.run(cmd1, shell=True, check=False)\n",
        "\n",
        "# 2) make a 2-second video by looping the frame\n",
        "cmd2 = (\n",
        "    f\"ffmpeg -y -loop 1 -i '{frame}' -t 2 \"\n",
        "    f\"-c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast \"\n",
        "    f\"-movflags +faststart '{OUT}'\"\n",
        ")\n",
        "subprocess.run(cmd2, shell=True, check=False)\n",
        "\n",
        "print(\"\\nDONE ‚úî\")\n",
        "print(\"Simulated SVD output created at:\")\n",
        "print(str(OUT))\n"
      ],
      "metadata": {
        "id": "ORKBJ33pbvpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD sampling runner (paste into a cell and run after you confirm model & weights)\n",
        "# ONE-CELL: Robust fix for \"No SVD job config found in /tmp\"\n",
        "# - creates a /tmp/svd_* job with cfg.json if none exists\n",
        "# - tries to call sample() if available; otherwise produces simulated mp4\n",
        "# - safe, idempotent, prints everything you need\n",
        "import os, json, time, uuid, subprocess\n",
        "from pathlib import Path\n",
        "from shlex import quote\n",
        "\n",
        "# ---------- USER / ENV SETTINGS ----------\n",
        "# Use your uploaded file path (developer-provided)\n",
        "UPLOADED_FILE = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "# default prompt (edit inline if you want different)\n",
        "DEFAULT_PROMPT = (\n",
        "    \"9:16 vertical, ultra-detailed close-up of a tiny mechanical fox exploring a sunlit garden, \"\n",
        "    \"cinematic shallow depth-of-field, warm color grade, subtle camera push-in, photorealistic textures, no text or logos.\"\n",
        ")\n",
        "\n",
        "DEFAULT_SEED = 1234\n",
        "DEFAULT_NUM_FRAMES = 25\n",
        "\n",
        "# Where SVD checkpoints are expected (adjust if you use Drive)\n",
        "if \"CHECKPOINT_DIR\" not in globals():\n",
        "    CHECKPOINT_DIR = \"/content/checkpoints\"\n",
        "\n",
        "if \"SVD_VERSION\" not in globals():\n",
        "    # keep as 'svd' if you only have open weights; use 'svd-xt-1-1' only if you have access\n",
        "    SVD_VERSION = \"svd-xt-1-1\"\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run_cmd(cmd, fail_ok=False):\n",
        "    print(\"RUN:\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if p.stdout:\n",
        "        print(p.stdout.strip())\n",
        "    if p.stderr:\n",
        "        # only show trimmed error to avoid spamming\n",
        "        print(\"ERR:\", p.stderr.strip()[:1000])\n",
        "    if p.returncode != 0 and not fail_ok:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\nstderr: {p.stderr}\")\n",
        "    return p\n",
        "\n",
        "def find_latest_jobcfg(tmpdir=\"/tmp\"):\n",
        "    p = Path(tmpdir)\n",
        "    candidates = sorted(p.glob(\"svd_*\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    for d in candidates:\n",
        "        cfg = d / \"cfg.json\"\n",
        "        if cfg.exists():\n",
        "            return str(cfg)\n",
        "    return None\n",
        "\n",
        "# ---------- main logic ----------\n",
        "print(\"Looking for existing SVD job cfg in /tmp ...\")\n",
        "job_cfg = find_latest_jobcfg(\"/tmp\")\n",
        "\n",
        "if job_cfg:\n",
        "    print(\"Found job config:\", job_cfg)\n",
        "else:\n",
        "    # create a new job folder and cfg\n",
        "    jobid = f\"svd_job_{int(time.time())}_{uuid.uuid4().hex[:6]}\"\n",
        "    jobdir = Path(\"/tmp\") / jobid\n",
        "    jobdir.mkdir(parents=True, exist_ok=True)\n",
        "    out_mp4 = str(jobdir / f\"{jobid}.mp4\")\n",
        "    cfg = {\n",
        "        \"prompt\": DEFAULT_PROMPT,\n",
        "        \"seed\": DEFAULT_SEED,\n",
        "        \"num_frames\": DEFAULT_NUM_FRAMES,\n",
        "        \"out\": out_mp4,\n",
        "        \"conditioning_image\": UPLOADED_FILE  # if you want image->video\n",
        "    }\n",
        "    cfg_path = jobdir / \"cfg.json\"\n",
        "    with open(cfg_path, \"w\", encoding=\"utf8\") as f:\n",
        "        json.dump(cfg, f, indent=2)\n",
        "    job_cfg = str(cfg_path)\n",
        "    print(\"WROTE new SVD job config to:\", job_cfg)\n",
        "    print(\"EXPECTED OUTPUT ->\", out_mp4)\n",
        "    # create a short simulated MP4 so downstream pipeline can run\n",
        "    print(\"Creating simulated sample MP4 (2s) ‚Äî so RIFE/upscale/test can run immediately...\")\n",
        "    # safe ffmpeg drawtext value (escape single quotes)\n",
        "    txt = cfg[\"prompt\"][:80].replace(\"'\", \"\")\n",
        "    ffmpeg_cmd = (\n",
        "        f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 \"\n",
        "        f\"-t 2 -vf drawtext=text='{txt}':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "        f\"'{out_mp4}'\"\n",
        "    )\n",
        "    res = subprocess.run(ffmpeg_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if res.returncode == 0:\n",
        "        print(\"‚úÖ Simulated SVD output created at:\", out_mp4)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è ffmpeg failed to create simulated output. stderr:\")\n",
        "        print(res.stderr[:2000])\n",
        "        raise RuntimeError(\"ffmpeg simulation failed; check ffmpeg availability.\")\n",
        "\n",
        "# ---------- try to run real sample() if available ----------\n",
        "# Many SVD notebooks expose a `sample()` function in session. We'll attempt to call it safely.\n",
        "# If sample() isn't available or call fails, we keep the simulated mp4 created above.\n",
        "sample_called = False\n",
        "if 'sample' in globals() and callable(globals()['sample']):\n",
        "    print(\"Detected sample() in session ‚Äî attempting to call sample() with job config.\")\n",
        "    try:\n",
        "        # attempt a generic call signature. This may need adaptation depending on the notebook's sample() signature.\n",
        "        # We'll read the cfg and try common kwargs. Wrap in try/except to avoid killing the cell on mismatch.\n",
        "        cfg = json.load(open(job_cfg, 'r', encoding='utf8'))\n",
        "        # Common safe arguments ‚Äî you might need to adapt these for your sample()\n",
        "        kwargs = dict(\n",
        "            input_path=cfg.get(\"conditioning_image\", \"\"),\n",
        "            resize_image=True,\n",
        "            num_frames=cfg.get(\"num_frames\", 14),\n",
        "            num_steps=30,\n",
        "            seed=cfg.get(\"seed\", \"random\"),\n",
        "            decoding_t=2,\n",
        "            fps_id=6,\n",
        "            motion_bucket_id=127,\n",
        "            cond_aug=0.02,\n",
        "            device='cuda' if (torch.cuda.is_available() if 'torch' in globals() else False) else 'cpu',\n",
        "            skip_filter=True\n",
        "        )\n",
        "        print(\"Calling sample(...) with kwargs (trimmed):\", {k: kwargs[k] for k in ['num_frames','seed','device']})\n",
        "        out_paths = globals()['sample'](**kwargs)\n",
        "        print(\"sample() returned:\", out_paths)\n",
        "        sample_called = True\n",
        "    except Exception as e:\n",
        "        print(\"sample() call failed (ok) ‚Äî will use simulated output. Error:\", repr(e))\n",
        "\n",
        "else:\n",
        "    print(\"No sample() found in session ‚Äî simulated output will be used for now.\")\n",
        "\n",
        "# ---------- final reporting ----------\n",
        "print(\"\\n--- SUMMARY ---\")\n",
        "print(\"job_cfg used:\", job_cfg)\n",
        "cfg_obj = json.load(open(job_cfg, 'r', encoding='utf8'))\n",
        "print(\"cfg['out'] ->\", cfg_obj.get(\"out\"))\n",
        "if sample_called:\n",
        "    print(\"Real sample() executed. Check returned outputs above.\")\n",
        "else:\n",
        "    print(\"No real sample() executed. Simulated mp4 exists at cfg['out'] and downstream steps can proceed.\")\n",
        "print(\"If you want me to replace the simulation with an exact sample() call for your generative-models fork, say: 'Plug real sample()' and paste the notebook sampling function cell or give me the exact repo/branch you used.\")\n"
      ],
      "metadata": {
        "id": "1vNAwjlHGvKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced, robust MP4 repair + interpolation cell (Colab-ready)\n",
        "# Paste and run in a fresh Colab Python cell.\n",
        "\n",
        "import os, subprocess, sys, shutil, time, uuid\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- Config (edit only if you know what you're doing) ----------\n",
        "# fallback user-uploaded file (from your session)\n",
        "UPLOADED_SAMPLE = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "# output folder for processed files\n",
        "OUT_DIR = Path(\"/tmp/processed_svd_outputs\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run(cmd, capture=True):\n",
        "    \"\"\"Run shell command; return (rc, stdout, stderr).\"\"\"\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    return p.returncode, p.stdout or \"\", p.stderr or \"\"\n",
        "\n",
        "def safe_print_head(tag, txt, n=800):\n",
        "    print(f\"\\n[{tag}]\")\n",
        "    if not txt:\n",
        "        print(\" <empty>\")\n",
        "    else:\n",
        "        print(txt[:n] + (\"...\\n\" if len(txt) > n else \"\\n\"))\n",
        "\n",
        "# ensure fonts for drawtext exist (silently ignore errors)\n",
        "print(\"Ensuring fonts available for ffmpeg drawtext...\")\n",
        "rc, out, err = run(\"fc-list : file | grep -i dejavu || true\")\n",
        "if not out:\n",
        "    _ = run(\"apt-get update -qq && apt-get install -y -qq fonts-dejavu-core || true\")\n",
        "    rc, out, err = run(\"fc-list : file | grep -i dejavu || true\")\n",
        "print(\"Fonts check done.\")\n",
        "\n",
        "# ---------- find candidate input mp4 ----------\n",
        "print(\"\\nSearching for candidate SVD outputs in /tmp ...\")\n",
        "candidates = sorted(Path(\"/tmp\").glob(\"svd_*/*.mp4\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "input_path = None\n",
        "if candidates:\n",
        "    input_path = candidates[0]\n",
        "    print(\"Found candidate:\", str(input_path))\n",
        "else:\n",
        "    # fallback to the known uploaded sample file\n",
        "    if Path(UPLOADED_SAMPLE).exists():\n",
        "        print(\"No /tmp svd outputs found. Falling back to uploaded sample:\", UPLOADED_SAMPLE)\n",
        "        # copy it into a job-like location so downstream code expects /tmp/svd_*/file.mp4\n",
        "        jobdir = Path(\"/tmp/svd_fallback_\" + uuid.uuid4().hex[:6])\n",
        "        jobdir.mkdir(parents=True, exist_ok=True)\n",
        "        input_path = jobdir / \"fallback_input.mp4\"\n",
        "        shutil.copy2(UPLOADED_SAMPLE, input_path)\n",
        "        print(\"Copied uploaded sample to:\", str(input_path))\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No SVD outputs found in /tmp and uploaded sample missing at: \" + UPLOADED_SAMPLE)\n",
        "\n",
        "# convert to Path object\n",
        "input_path = Path(input_path)\n",
        "print(\"Using input:\", input_path)\n",
        "\n",
        "# ---------- validate file size ----------\n",
        "min_size_bytes = 1024  # tiny threshold\n",
        "if not input_path.exists() or input_path.stat().st_size < min_size_bytes:\n",
        "    print(\"Input missing or too small; creating a valid placeholder video at the input path.\")\n",
        "    # create placeholder valid mp4 with faststart\n",
        "    placeholder_cmd = (\n",
        "        f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 -t 2 \"\n",
        "        f\"-vf drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='SIMULATED SVD':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "        f\"-c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{input_path}'\"\n",
        "    )\n",
        "    rc, out, err = run(placeholder_cmd)\n",
        "    safe_print_head(\"ffmpeg-create-placeholder-stdout\", out)\n",
        "    safe_print_head(\"ffmpeg-create-placeholder-stderr\", err)\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(\"Failed to create placeholder mp4. See stderr above.\")\n",
        "\n",
        "# ---------- probe input with ffprobe ----------\n",
        "print(\"\\nProbing input with ffprobe...\")\n",
        "rc, out, err = run(f\"ffprobe -v error -show_format -show_streams '{input_path}'\")\n",
        "safe_print_head(\"ffprobe\", out + err, 1200)\n",
        "# detect 'moov' related errors heuristically\n",
        "if (\"moov\" in err.lower()) or (\"invalid data found\" in err.lower()) or rc != 0:\n",
        "    print(\"Detected container issues (moov/invalid). Attempting to remux/recreate clean mp4 with -movflags +faststart.\")\n",
        "    fixed = input_path.with_suffix(\".fixed.mp4\")\n",
        "    remux_cmd = f\"ffmpeg -y -i '{input_path}' -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{fixed}'\"\n",
        "    rc, out, err = run(remux_cmd)\n",
        "    safe_print_head(\"ffmpeg-remux-stdout\", out)\n",
        "    safe_print_head(\"ffmpeg-remux-stderr\", err)\n",
        "    if rc == 0 and fixed.exists():\n",
        "        # replace original safely (keep backup)\n",
        "        backup = input_path.with_suffix(\".bak.mp4\")\n",
        "        shutil.move(str(input_path), str(backup))\n",
        "        shutil.move(str(fixed), str(input_path))\n",
        "        print(\"Remux successful. Replaced input with fixed file. Backup at\", str(backup))\n",
        "    else:\n",
        "        print(\"Remux failed. We'll attempt to recreate a clean placeholder input instead.\")\n",
        "        recreate_cmd = (\n",
        "            f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 -t 2 \"\n",
        "            f\"-vf drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='SIM RECREATE':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "            f\"-c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{input_path}'\"\n",
        "        )\n",
        "        rc, out, err = run(recreate_cmd)\n",
        "        safe_print_head(\"ffmpeg-recreate-stderr\", err)\n",
        "        if rc != 0:\n",
        "            raise RuntimeError(\"Failed to remux or recreate a valid input mp4. Stderr above.\")\n",
        "\n",
        "# ---------- check ffmpeg supports minterpolate ----------\n",
        "print(\"\\nChecking ffmpeg filters for 'minterpolate' support...\")\n",
        "rc, out, err = run(\"ffmpeg -hide_banner -filters\")\n",
        "supports_minterp = \"minterpolate\" in out\n",
        "print(\"minterpolate supported?\" , supports_minterp)\n",
        "\n",
        "# ---------- attempt interpolation (minterpolate) with fallback to fps re-encode ----------\n",
        "base_name = input_path.stem\n",
        "rife_out = OUT_DIR / f\"{base_name}_rife.mp4\"\n",
        "fps_out = OUT_DIR / f\"{base_name}_fps30.mp4\"\n",
        "\n",
        "if supports_minterp:\n",
        "    print(\"Running minterpolate interpolation (this may be slow)...\")\n",
        "    # use quotes carefully\n",
        "    cmd_minterp = (\n",
        "        f\"ffmpeg -y -i '{input_path}' -filter:v \\\"minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\\\" \"\n",
        "        f\"-c:v libx264 -pix_fmt yuv420p -crf 18 '{rife_out}'\"\n",
        "    )\n",
        "    rc, out, err = run(cmd_minterp, )\n",
        "    safe_print_head(\"minterpolate-stdout\", out)\n",
        "    safe_print_head(\"minterpolate-stderr\", err, 4000)\n",
        "    if rc == 0 and rife_out.exists():\n",
        "        final_out = rife_out\n",
        "        print(\"minterpolate succeeded ->\", str(final_out))\n",
        "    else:\n",
        "        print(\"minterpolate failed ‚Äî falling back to fps re-encode.\")\n",
        "        rc, out, err = run(f\"ffmpeg -y -i '{input_path}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{fps_out}'\")\n",
        "        safe_print_head(\"fps-stdout\", out)\n",
        "        safe_print_head(\"fps-stderr\", err)\n",
        "        if rc == 0 and fps_out.exists():\n",
        "            final_out = fps_out\n",
        "        else:\n",
        "            raise RuntimeError(\"Both minterpolate and fps fallback failed. See stderr above.\")\n",
        "else:\n",
        "    print(\"minterpolate not supported in this ffmpeg build ‚Äî using fps re-encode fallback (safe).\")\n",
        "    rc, out, err = run(f\"ffmpeg -y -i '{input_path}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{fps_out}'\")\n",
        "    safe_print_head(\"fps-stdout\", out)\n",
        "    safe_print_head(\"fps-stderr\", err)\n",
        "    if rc == 0 and fps_out.exists():\n",
        "        final_out = fps_out\n",
        "    else:\n",
        "        raise RuntimeError(\"fps re-encode fallback failed. See stderr above.\")\n",
        "\n",
        "# ---------- final report ----------\n",
        "print(\"\\n--- DONE ---\")\n",
        "print(\"Input used:\", str(input_path))\n",
        "print(\"Final interpolation output:\", str(final_out))\n",
        "print(\"Filesize (bytes):\", final_out.stat().st_size if final_out.exists() else \"MISSING\")\n",
        "print(\"You can now use this file for RIFE/upscale/stitch steps.\")\n",
        "\n",
        "# show quick ls of output dir\n",
        "print(\"\\nOUT_DIR listing:\")\n",
        "for p in sorted(OUT_DIR.iterdir(), key=lambda x: x.stat().st_mtime):\n",
        "    print(p.name, \"-\", p.stat().st_size, \"bytes\")\n"
      ],
      "metadata": {
        "id": "uuOb6K-rGzjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def one_click(prompt_text):\n",
        "    # TEXT-ONLY ! generate SVD config\n",
        "    out, jobdir = generate_svd_from_text(prompt_text, seed=\"random\", num_frames=25, out_prefix=\"oneclick\")\n",
        "    # RUN sampling cell manually (or we can call sample() if present)\n",
        "    # For now we simulate generation (same logic as SVD sampling cell)\n",
        "    run_cmd(f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x331122 -t 3 -vf drawtext=\\\"text='ONECLICK {prompt_text[:30]}':fontsize=32:fontcolor=white:x=20:y=20\\\" {out}\")\n",
        "    # postprocess\n",
        "    rife = interpolate_with_rife(out)\n",
        "    up = upscale_realesrgan(rife, scale=1)\n",
        "    final = \"/content/oneclick_final.mp4\"\n",
        "    stitch_files([up], final)\n",
        "    voice = tts_generate(prompt_text, outfile=\"/content/oneclick_voice.wav\")\n",
        "    run_cmd(f\"ffmpeg -y -i '{final}' -i '{voice}' -c:v copy -c:a aac -shortest '/content/oneclick_final_audio.mp4'\")\n",
        "    dst = os.path.join(OUTPUT_DRIVE_FOLDER, \"oneclick_final.mp4\")\n",
        "    shutil.copy(\"/content/oneclick_final_audio.mp4\", dst)\n",
        "    return dst\n",
        "\n",
        "demo = gr.Interface(fn=one_click, inputs=gr.Textbox(lines=2, placeholder=\"Enter prompt...\"), outputs=gr.File())\n",
        "demo.launch(share=False)\n"
      ],
      "metadata": {
        "id": "3JwAGfFdG0L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REAL SVD SAMPLING runner (run only if you have checkpoints & optional HF token)\n",
        "import os, json, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# EDIT these if your checkpoints live in Drive\n",
        "CHECKPOINT_DIR = \"/content/checkpoints\"   # <-- change if your checkpoints are in Drive\n",
        "SVD_VERSION = \"svd\"  # \"svd\" or \"svd-xt-1-1\"\n",
        "\n",
        "# find latest job cfg\n",
        "jobcfg = None\n",
        "for d in sorted(Path(\"/tmp\").glob(\"svd_*\"), key=lambda x: x.stat().st_mtime, reverse=True):\n",
        "    c = d / \"cfg.json\"\n",
        "    if c.exists():\n",
        "        jobcfg = c\n",
        "        break\n",
        "if not jobcfg:\n",
        "    raise RuntimeError(\"No job cfg found in /tmp. Run TEXT-ONLY / IMAGE-TO-VIDEO cell first.\")\n",
        "\n",
        "cfg = json.load(open(jobcfg,\"r\"))\n",
        "print(\"Using job cfg:\", jobcfg)\n",
        "print(\"cfg:\", {k:cfg[k] for k in (\"prompt\",\"seed\",\"num_frames\",\"out\") if k in cfg})\n",
        "\n",
        "# sample() attempt\n",
        "if 'sample' in globals() and callable(globals()['sample']):\n",
        "    print(\"sample() found in session ‚Äî calling sample() now...\")\n",
        "    try:\n",
        "        out = sample(\n",
        "            input_path=cfg.get(\"conditioning_image\",\"\"),\n",
        "            resize_image=True,\n",
        "            num_frames=cfg.get(\"num_frames\",14),\n",
        "            num_steps=30,\n",
        "            seed=cfg.get(\"seed\",\"random\"),\n",
        "            decoding_t=2,\n",
        "            fps_id=6,\n",
        "            motion_bucket_id=127,\n",
        "            cond_aug=0.02,\n",
        "            device='cuda' if ((\"torch\" in globals()) and torch.cuda.is_available()) else 'cpu',\n",
        "            skip_filter=True\n",
        "        )\n",
        "        print(\"sample() returned:\", out)\n",
        "    except Exception as e:\n",
        "        print(\"sample() call failed. Error:\", e)\n",
        "        print(\"If it failed due to missing imports / checkpoints, ensure CHECKPOINT_DIR contains SVD weights and you loaded model cells.\")\n",
        "else:\n",
        "    print(\"No sample() defined in this session. If you want real SVD, either run a notebook cell that loads SVD 'sample' function or paste the sampling cell. Otherwise use the post-process cell (option 2).\")\n"
      ],
      "metadata": {
        "id": "41RQKVZ1jixF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-run, robust post-process cell ‚Äî no parentheses in shell filters (Colab-ready)\n",
        "import subprocess, shutil, json, time\n",
        "from pathlib import Path\n",
        "\n",
        "# Config (use your uploaded file)\n",
        "UPLOADED = Path(\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\")\n",
        "OUT_DIR = Path(\"/tmp/processed_svd_outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DRIVE_OUT = Path(\"/content/drive/MyDrive/AI-Automation/outputs\"); DRIVE_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def run(cmd, fail_ok=False):\n",
        "    print(\"RUN:\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if p.stdout: print(p.stdout[:1500])\n",
        "    if p.stderr: print(\"ERR:\", p.stderr[:1500])\n",
        "    if p.returncode != 0 and not fail_ok:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\nstderr snippet above\")\n",
        "    return p\n",
        "\n",
        "# 1) Find latest SVD output; fallback to uploaded\n",
        "cands = sorted(Path(\"/tmp\").glob(\"svd_*/*.mp4\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if cands:\n",
        "    input_mp4 = cands[0]\n",
        "else:\n",
        "    if UPLOADED.exists():\n",
        "        jobdir = Path(\"/tmp/svd_fallback_\"+str(int(time.time())))\n",
        "        jobdir.mkdir(parents=True, exist_ok=True)\n",
        "        input_mp4 = jobdir / \"fallback_input.mp4\"\n",
        "        shutil.copy2(str(UPLOADED), str(input_mp4))\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No SVD outputs in /tmp and uploaded sample missing.\")\n",
        "\n",
        "print(\"Using input:\", input_mp4)\n",
        "\n",
        "# 2) Ensure valid container (remux with movflags +faststart) -> remuxed\n",
        "remuxed = OUT_DIR / f\"{input_mp4.stem}_remux.mp4\"\n",
        "run(f\"ffmpeg -y -i '{input_mp4}' -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{remuxed}'\", fail_ok=True)\n",
        "if not remuxed.exists():\n",
        "    # try recreate using first frame (guaranteed compatible)\n",
        "    frame = OUT_DIR / f\"{input_mp4.stem}_frame.png\"\n",
        "    run(f\"ffmpeg -y -i '{input_mp4}' -vframes 1 '{frame}'\", fail_ok=True)\n",
        "    run(f\"ffmpeg -y -loop 1 -i '{frame}' -t 2 -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{remuxed}'\", fail_ok=False)\n",
        "\n",
        "# 3) Interpolate (minterpolate) with fallback to fps re-encode\n",
        "filters = subprocess.run(\"ffmpeg -hide_banner -filters\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout\n",
        "supports_minterp = \"minterpolate\" in (filters or \"\")\n",
        "interp_out = OUT_DIR / f\"{input_mp4.stem}_interp.mp4\"\n",
        "if supports_minterp:\n",
        "    try:\n",
        "        run(f\"ffmpeg -y -i '{remuxed}' -filter:v \\\"minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\\\" -c:v libx264 -pix_fmt yuv420p -crf 18 '{interp_out}'\", fail_ok=False)\n",
        "    except Exception as e:\n",
        "        print(\"minterpolate failed, falling back to fps re-encode. Error:\", e)\n",
        "        run(f\"ffmpeg -y -i '{remuxed}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{interp_out}'\")\n",
        "else:\n",
        "    run(f\"ffmpeg -y -i '{remuxed}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{interp_out}'\")\n",
        "\n",
        "if not interp_out.exists():\n",
        "    interp_out = remuxed\n",
        "\n",
        "# 4) Read width/height of interp_out using ffprobe (to compute numeric pad offsets)\n",
        "def probe_wh(path):\n",
        "    p = subprocess.run(f\"ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of json '{path}'\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    try:\n",
        "        info = json.loads(p.stdout)\n",
        "        st = info.get(\"streams\", [{}])[0]\n",
        "        return int(st.get(\"width\", 0)), int(st.get(\"height\", 0))\n",
        "    except Exception:\n",
        "        return 0, 0\n",
        "\n",
        "iw, ih = probe_wh(str(interp_out))\n",
        "print(\"Detected size:\", iw, \"x\", ih)\n",
        "target_w, target_h = 1080, 1920\n",
        "\n",
        "# If input is larger than target, we will scale-down preserving aspect ratio and then pad; compute scaled dimensions by ffmpeg scale math in Python\n",
        "# calculate scale factor to fit into target\n",
        "if iw == 0 or ih == 0:\n",
        "    # fallback: just re-encode to target size directly (safe)\n",
        "    up_out = OUT_DIR / f\"{interp_out.stem}_up.mp4\"\n",
        "    run(f\"ffmpeg -y -i '{interp_out}' -vf scale={target_w}:{target_h} -c:v libx264 -pix_fmt yuv420p -crf 18 '{up_out}'\")\n",
        "else:\n",
        "    # scale to fit target while preserving aspect\n",
        "    # compute scale factor\n",
        "    scale_w = target_w / iw\n",
        "    scale_h = target_h / ih\n",
        "    scale_factor = min(scale_w, scale_h)\n",
        "    new_w = int(iw * scale_factor)\n",
        "    new_h = int(ih * scale_factor)\n",
        "    pad_x = max((target_w - new_w) // 2, 0)\n",
        "    pad_y = max((target_h - new_h) // 2, 0)\n",
        "    up_out = OUT_DIR / f\"{interp_out.stem}_up.mp4\"\n",
        "    vf = f\"scale={new_w}:{new_h},pad={target_w}:{target_h}:{pad_x}:{pad_y}\"\n",
        "    # safe: no parentheses in vf string\n",
        "    run(f\"ffmpeg -y -i '{interp_out}' -vf \\\"{vf}\\\" -c:v libx264 -pix_fmt yuv420p -crf 18 '{up_out}'\")\n",
        "\n",
        "if not up_out.exists():\n",
        "    up_out = interp_out\n",
        "\n",
        "print(\"Upscaled output:\", up_out)\n",
        "\n",
        "# 5) Make ~15s by concat repetitions (use concat demuxer)\n",
        "def duration(path):\n",
        "    p = subprocess.run(f\"ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 '{path}'\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    try:\n",
        "        return float(p.stdout.strip())\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "cur_dur = duration(str(up_out))\n",
        "target = 15.0\n",
        "if cur_dur < target and cur_dur > 0:\n",
        "    reps = int((target // cur_dur) + 1)\n",
        "    listfile = OUT_DIR / \"concat_list.txt\"\n",
        "    with open(listfile, \"w\") as f:\n",
        "        for i in range(reps):\n",
        "            f.write(f\"file '{up_out}'\\n\")\n",
        "    stitched = OUT_DIR / f\"{up_out.stem}_stitched.mp4\"\n",
        "    run(f\"ffmpeg -y -f concat -safe 0 -i '{listfile}' -c copy '{stitched}'\")\n",
        "    final_video = stitched if stitched.exists() else up_out\n",
        "else:\n",
        "    final_video = up_out\n",
        "\n",
        "print(\"Final video (pre-audio):\", final_video)\n",
        "\n",
        "# 6) TTS (gTTS) and merge (safe)\n",
        "try:\n",
        "    run(\"python -m pip install -q gTTS pydub\", fail_ok=True)\n",
        "    from gtts import gTTS\n",
        "    tts_text = \"Tiny mechanical fox explores a sunlit garden.\"\n",
        "    tts_file = OUT_DIR / \"voice.mp3\"\n",
        "    gTTS(tts_text, lang='en').save(str(tts_file))\n",
        "    merged = OUT_DIR / f\"{final_video.stem}_final_audio.mp4\"\n",
        "    run(f\"ffmpeg -y -i '{final_video}' -i '{tts_file}' -c:v copy -c:a aac -shortest '{merged}'\")\n",
        "    final_with_audio = merged if merged.exists() else final_video\n",
        "except Exception as e:\n",
        "    print(\"TTS failed, continuing without audio. Error:\", e)\n",
        "    final_with_audio = final_video\n",
        "\n",
        "# 7) burn captions ‚Äî use numeric x,y to avoid parentheses\n",
        "caption_text = \"Tiny mechanical fox explores a sunlit garden.\"\n",
        "captioned = OUT_DIR / f\"{final_with_audio.stem}_captioned.mp4\"\n",
        "# choose numeric x (left indent) and numeric y from height\n",
        "y_pos = max(target_h - 150, 10)\n",
        "run(f\"ffmpeg -y -i '{final_with_audio}' -vf \\\"drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='{caption_text}':fontsize=40:fontcolor=white:box=1:boxcolor=0x00000099:x=40:y={y_pos}\\\" -c:a copy '{captioned}'\", fail_ok=True)\n",
        "if not captioned.exists():\n",
        "    captioned = final_with_audio\n",
        "\n",
        "# 8) copy result to Drive\n",
        "timestamp = int(time.time())\n",
        "dst = DRIVE_OUT / f\"final_short_{timestamp}.mp4\"\n",
        "shutil.copy2(str(captioned), str(dst))\n",
        "\n",
        "print(\"\\n--- DONE ---\")\n",
        "print(\"Final short saved to Drive:\", dst)\n",
        "print(\"Local file:\", captioned)\n"
      ],
      "metadata": {
        "id": "5KheAADbG2Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# 1) find your uploaded MP4 in /content\n",
        "mp4s = list(Path(\"/content\").glob(\"*.mp4\"))\n",
        "print(\"Found MP4s:\", mp4s)\n",
        "\n",
        "if not mp4s:\n",
        "    raise FileNotFoundError(\"‚ùå No MP4 found in /content. Upload again bro.\")\n",
        "\n",
        "UPLOADED_SAMPLE = mp4s[0]\n",
        "print(\"Using UPLOADED_SAMPLE =\", UPLOADED_SAMPLE)\n"
      ],
      "metadata": {
        "id": "OXgP-xSW6E7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKUP = Path(\"/content/drive/MyDrive/AI-Automation/last_uploaded_sample.mp4\")\n",
        "shutil.copy2(UPLOADED_SAMPLE, BACKUP)\n",
        "print(\"Backed up to:\", BACKUP)\n"
      ],
      "metadata": {
        "id": "B9XAcx6C6YyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "BACKUP = Path(\"/content/drive/MyDrive/AI-Automation/last_uploaded_sample.mp4\")\n",
        "RESTORE = Path(\"/content/last_uploaded_sample.mp4\")\n",
        "\n",
        "if BACKUP.exists():\n",
        "    shutil.copy2(BACKUP, RESTORE)\n",
        "    UPLOADED_SAMPLE = RESTORE\n",
        "else:\n",
        "    UPLOADED_SAMPLE = None\n",
        "\n",
        "print(\"Restored sample:\", UPLOADED_SAMPLE)\n"
      ],
      "metadata": {
        "id": "6ufq3znB6cKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTO-FIX uploaded-sample path (one cell) ‚Äî run now\n",
        "from pathlib import Path\n",
        "import shutil, os, time\n",
        "\n",
        "# Candidate paths (tries these in order)\n",
        "candidates = [\n",
        "    Path(\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"),\n",
        "    Path(\"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"),\n",
        "    Path(\"/content/drive/MyDrive/AI-Automation/sample.mp4\"),\n",
        "    Path(\"/content/last_uploaded_sample.mp4\"),\n",
        "]\n",
        "\n",
        "found = None\n",
        "for p in candidates:\n",
        "    try:\n",
        "        if p.exists():\n",
        "            found = p\n",
        "            break\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "# If not found, try scanning common folders for any mp4\n",
        "if not found:\n",
        "    for root in [Path(\"/content\"), Path(\"/mnt\"), Path(\"/content/drive/MyDrive/AI-Automation\")]:\n",
        "        if root.exists():\n",
        "            mp4s = list(root.rglob(\"*.mp4\"))\n",
        "            if mp4s:\n",
        "                found = mp4s[0]\n",
        "                break\n",
        "\n",
        "if not found:\n",
        "    raise FileNotFoundError(\"No MP4 found in known locations (/mnt/data, /content, Drive). Upload a sample or put it in Drive:/MyDrive/AI-Automation/sample.mp4\")\n",
        "\n",
        "# Ensure /content exists and copy into it (so pipeline uses /content path)\n",
        "content_target = Path(\"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\")\n",
        "try:\n",
        "    # Only copy if source != target or target missing\n",
        "    if found.resolve() != content_target.resolve():\n",
        "        shutil.copy2(str(found), str(content_target))\n",
        "except Exception as e:\n",
        "    print(\"Warning copying to /content:\", e)\n",
        "\n",
        "# Back up into Drive persistent location\n",
        "drive_path = Path(\"/content/drive/MyDrive/AI-Automation/last_uploaded_sample.mp4\")\n",
        "try:\n",
        "    # create Drive folder if missing\n",
        "    drive_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    shutil.copy2(str(content_target), str(drive_path))\n",
        "    print(\"Backed up sample to Drive:\", drive_path)\n",
        "except Exception as e:\n",
        "    print(\"Warning backing up to Drive (maybe Drive not mounted):\", e)\n",
        "\n",
        "# Final variable for rest of notebook\n",
        "UPLOADED_SAMPLE = content_target\n",
        "print(\"Final UPLOADED_SAMPLE set to:\", UPLOADED_SAMPLE)\n",
        "print(\"Exists:\", UPLOADED_SAMPLE.exists(), \" Size (MB):\", (UPLOADED_SAMPLE.stat().st_size/1024/1024) if UPLOADED_SAMPLE.exists() else \"N/A\")\n",
        "\n",
        "# quick sanity: if file missing after copy, show found path for debugging\n",
        "if not UPLOADED_SAMPLE.exists():\n",
        "    print(\"Debug - originally found at:\", found)\n",
        "    raise FileNotFoundError(f\"Failed to ensure uploaded sample at {UPLOADED_SAMPLE}. Found candidate: {found}\")\n",
        "\n",
        "# optional small wait to ensure FS flush\n",
        "time.sleep(0.5)\n"
      ],
      "metadata": {
        "id": "KmuxHN-Z7tv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD loader ‚Äî paste & run in Colab (must mount Drive first)\n",
        "import os, sys, subprocess, traceback\n",
        "from pathlib import Path\n",
        "print(\"Starting SVD loader...\")\n",
        "\n",
        "# 1) Config: where we expect checkpoints in Drive\n",
        "CKPT_DIR = Path(\"/content/drive/MyDrive/AI-Automation/checkpoints\")\n",
        "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "expected_names = [\n",
        "    \"svd.safetensors\",\n",
        "    \"svd_xt.safetensors\",\n",
        "    \"svd_xt_1_1.safetensors\",\n",
        "    \"open_clip_model.safetensors\",  # sometimes required\n",
        "]\n",
        "\n",
        "print(\"Checking Drive checkpoint folder:\", CKPT_DIR)\n",
        "found = {p.name: p for p in CKPT_DIR.glob(\"*.safetensors\")}\n",
        "print(\"Found checkpoint files in Drive:\", list(found.keys()))\n",
        "\n",
        "# 2) Install lightweight deps (best-effort, non-destructive)\n",
        "def run(cmd):\n",
        "    print(\">>\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    print(p.stdout[:1000])\n",
        "    if p.returncode != 0:\n",
        "        print(\"ERR:\", p.stderr[:1000])\n",
        "    return p.returncode == 0\n",
        "\n",
        "print(\"Installing minimal Python deps (this can take a minute)...\")\n",
        "# GPU/torch wheel selection may vary by Colab image; this is best-effort.\n",
        "run(\"python -m pip install -q -U pip\")\n",
        "run(\"python -m pip install -q omegaconf einops accelerate transformers timm open-clip-torch imwatermark\")\n",
        "\n",
        "# Optional: xformers increases speed but often fails to build; try lightly\n",
        "print(\"Attempting to install xformers (optional, may fail)...\")\n",
        "run(\"python -m pip install -q xformers --no-deps\",)  # ignore failures\n",
        "\n",
        "# 3) Clone repo if missing\n",
        "if not Path(\"generative-models\").exists():\n",
        "    print(\"Cloning generative-models repo (read-only)...\")\n",
        "    run(\"git clone https://github.com/Stability-AI/generative-models.git generative-models\")\n",
        "else:\n",
        "    print(\"generative-models already present locally.\")\n",
        "\n",
        "# 4) Add repo to sys.path\n",
        "if \"generative-models\" not in sys.path:\n",
        "    sys.path.append(str(Path.cwd() / \"generative-models\"))\n",
        "print(\"sys.path updated.\")\n",
        "\n",
        "# 5) Try to import a sampling wrapper\n",
        "MODEL_READY = False\n",
        "IMPORT_ERROR = None\n",
        "try:\n",
        "    # try multiple likely import paths (repo structure varies across forks)\n",
        "    try:\n",
        "        from sgm.sampling import sample as svd_sample\n",
        "        print(\"Imported sample() from sgm.sampling\")\n",
        "    except Exception as e1:\n",
        "        try:\n",
        "            # older path fallback\n",
        "            from scripts.sampling import sample as svd_sample\n",
        "            print(\"Imported sample() from scripts.sampling\")\n",
        "        except Exception as e2:\n",
        "            # last attempt: generic search\n",
        "            import importlib, pkgutil\n",
        "            svd_sample = None\n",
        "            for finder, name, ispkg in pkgutil.iter_modules(['generative-models']):\n",
        "                pass\n",
        "            raise RuntimeError(\"Could not find sample() in known locations: \" + repr((e1, e2)))\n",
        "    # expose to globals for your UI\n",
        "    globals()['sample'] = svd_sample\n",
        "    MODEL_READY = True\n",
        "    print(\"sample() exposed to notebook globals. Model loader SUCCESS (function available).\")\n",
        "except Exception as e:\n",
        "    IMPORT_ERROR = traceback.format_exc()\n",
        "    print(\"Import failed. Full traceback:\\n\", IMPORT_ERROR)\n",
        "    MODEL_READY = False\n",
        "\n",
        "# 6) Check that weights exist and warn if missing/gated\n",
        "has_expected_ckpt = any(name in found for name in expected_names)\n",
        "if not has_expected_ckpt:\n",
        "    print(\"\\n‚ö†Ô∏è No expected checkpoint found in Drive:/AI-Automation/checkpoints.\")\n",
        "    print(\"Please place the required safetensors in that folder with one of these names:\", expected_names)\n",
        "    print(\"If a checkpoint is gated on Hugging Face, you must request access on the model page and then upload the safetensors to Drive manually.\")\n",
        "else:\n",
        "    print(\"Checkpoint exists in Drive:\", [k for k in found.keys() if k in expected_names])\n",
        "\n",
        "# 7) Final status summary\n",
        "print(\"\\n=== SVD LOAD SUMMARY ===\")\n",
        "print(\"MODEL_READY (function present):\", MODEL_READY)\n",
        "if not MODEL_READY:\n",
        "    print(\"Import error snippet (first 500 chars):\")\n",
        "    print((IMPORT_ERROR or \"none\")[:500])\n",
        "print(\"If MODEL_READY==True and you still get fallback, ensure the checkpoint file (.safetensors) is placed at:\")\n",
        "print(\"  /content/drive/MyDrive/AI-Automation/checkpoints/\")\n",
        "print(\"Expected filenames: svd.safetensors OR svd_xt.safetensors OR svd_xt_1_1.safetensors\")\n",
        "print(\"If the repo import fails repeatedly, paste the full traceback here and I'll tailor the fix.\")\n"
      ],
      "metadata": {
        "id": "CCgMpn9yGDGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KlingAI compact Gradio UI ‚Äî 3 previews, Load Model, Generate 3, compact styling\n",
        "# Paste & run in Colab after mounting Drive (drive.mount('/content/drive', force_remount=True))\n",
        "import os, subprocess, shutil, time, uuid, json\n",
        "from pathlib import Path\n",
        "import gradio as gr\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "DRIVE_OUT = Path(\"/content/drive/MyDrive/AI-Automation/outputs\")\n",
        "DRIVE_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# IMPORTANT: your uploaded sample (session path). Use this path in tools.\n",
        "FALLBACK_SAMPLE_PATH = \"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "FALLBACK_SAMPLE = Path(FALLBACK_SAMPLE_PATH)\n",
        "\n",
        "TMP_BASE = Path(\"/tmp/kling_ui\"); TMP_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- helper to run shell cmds ----------\n",
        "def run(cmd, fail_ok=False):\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    stdout = p.stdout.strip()\n",
        "    stderr = p.stderr.strip()\n",
        "    if stdout:\n",
        "        print(stdout[:2000])\n",
        "    if stderr:\n",
        "        print(\"ERR:\", stderr[:3000])\n",
        "    if p.returncode != 0 and not fail_ok:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\n{stderr[:2000]}\")\n",
        "    return p\n",
        "\n",
        "# ---------- Model loader (attempts safe non-blocking install) ----------\n",
        "MODEL_READY = {\"ok\": False, \"msg\": \"Model not loaded.\"}\n",
        "def load_svd_model():\n",
        "    \"\"\"\n",
        "    Try to prepare environment & load stable-video-diffusion code.\n",
        "    This will:\n",
        "     - clone generative-models (if missing)\n",
        "     - pip install common deps (light)\n",
        "     - check Drive for checkpoints at /content/drive/MyDrive/AI-Automation/checkpoints\n",
        "     - attempt to import sample() from generative-models (best-effort)\n",
        "    NOTE: Gated weights need manual placement in Drive.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1) clone if missing\n",
        "        if not Path(\"generative-models\").exists():\n",
        "            run(\"git clone https://github.com/Stability-AI/generative-models.git generative-models\", fail_ok=True)\n",
        "        # 2) install minimal deps to make imports work (non-exhaustive)\n",
        "        run(\"python -m pip install -q -U torch torchvision --index-url https://download.pytorch.org/whl/cu118\", fail_ok=True)\n",
        "        run(\"python -m pip install -q omegaconf einops accelerate transformers timm open-clip-torch imwatermark\", fail_ok=True)\n",
        "        # 3) try to import sample() from the repo (in-process)\n",
        "        import sys\n",
        "        if \"generative-models\" not in sys.path:\n",
        "            sys.path.append(\"generative-models\")\n",
        "        # best-effort import (may still fail if many deps missing)\n",
        "        try:\n",
        "            from sgm.sampling import sample as svd_sample  # path depends on fork; try canonical\n",
        "            globals()['sample'] = svd_sample\n",
        "            MODEL_READY['ok'] = True\n",
        "            MODEL_READY['msg'] = \"Loaded sample() from generative-models (best-effort).\"\n",
        "            return (\"SVD model function loaded (best-effort). If you plan to run large gen, ensure weights are in Drive:/AI-Automation/checkpoints and restart runtime.\", True)\n",
        "        except Exception as e:\n",
        "            # If import fail, still return instructive message\n",
        "            MODEL_READY['ok'] = False\n",
        "            MODEL_READY['msg'] = f\"Could not import sample(): {e}\"\n",
        "            return (f\"Partial setup done. sample() not importable: {e}\\nPlace SVD checkpoints in Drive:/AI-Automation/checkpoints and follow SVD notebook instructions, or ask me to fully script weight download.\", False)\n",
        "    except Exception as e:\n",
        "        return (f\"Load failed: {e}\", False)\n",
        "\n",
        "# ---------- Post-process (compact, same robust pipeline with duration) ----------\n",
        "def post_process(input_mp4_path, prompt_text, duration_sec:int):\n",
        "    OUT_DIR = TMP_BASE / \"processed\"; shutil.rmtree(OUT_DIR, ignore_errors=True); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    input_mp4 = Path(input_mp4_path)\n",
        "    # remux / ensure valid container\n",
        "    remuxed = OUT_DIR / (input_mp4.stem + \"_remux.mp4\")\n",
        "    run(f\"ffmpeg -y -i '{input_mp4}' -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{remuxed}'\", fail_ok=True)\n",
        "    if not remuxed.exists():\n",
        "        # fallback from frame\n",
        "        frame = OUT_DIR / \"fallback_frame.png\"\n",
        "        run(f\"ffmpeg -y -i '{input_mp4}' -vframes 1 '{frame}'\", fail_ok=True)\n",
        "        run(f\"ffmpeg -y -loop 1 -i '{frame}' -t 2 -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{remuxed}'\", fail_ok=False)\n",
        "\n",
        "    # simple upsampling/fps -> use fps 30\n",
        "    interp_out = OUT_DIR / (input_mp4.stem + \"_interp.mp4\")\n",
        "    run(f\"ffmpeg -y -i '{remuxed}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{interp_out}'\", fail_ok=True)\n",
        "    if not interp_out.exists():\n",
        "        interp_out = remuxed\n",
        "\n",
        "    # scale/pad to 1080x1920 numerically\n",
        "    def probe_wh(path):\n",
        "        p = subprocess.run(f\"ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of json '{path}'\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        try:\n",
        "            info = json.loads(p.stdout); st = info.get(\"streams\", [{}])[0]; return int(st.get(\"width\",0)), int(st.get(\"height\",0))\n",
        "        except:\n",
        "            return 0,0\n",
        "    iw, ih = probe_wh(str(interp_out)); target_w, target_h = 1080,1920\n",
        "    up_out = OUT_DIR / (interp_out.stem + \"_up.mp4\")\n",
        "    if iw==0 or ih==0:\n",
        "        run(f\"ffmpeg -y -i '{interp_out}' -vf scale={target_w}:{target_h} -c:v libx264 -pix_fmt yuv420p -crf 18 '{up_out}'\", fail_ok=True)\n",
        "    else:\n",
        "        scale_w = target_w/iw; scale_h=target_h/ih; sf=min(scale_w,scale_h)\n",
        "        new_w = max(1,int(iw*sf)); new_h=max(1,int(ih*sf))\n",
        "        pad_x = max((target_w-new_w)//2,0); pad_y = max((target_h-new_h)//2,0)\n",
        "        vf = f\"scale={new_w}:{new_h},pad={target_w}:{target_h}:{pad_x}:{pad_y}\"\n",
        "        run(f\"ffmpeg -y -i '{interp_out}' -vf \\\"{vf}\\\" -c:v libx264 -pix_fmt yuv420p -crf 18 '{up_out}'\", fail_ok=True)\n",
        "    if not up_out.exists(): up_out = interp_out\n",
        "\n",
        "    # ensure exact duration: repeat/trim\n",
        "    def get_dur(path):\n",
        "        p = subprocess.run(f\"ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 '{path}'\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        try: return float(p.stdout.strip())\n",
        "        except: return 0.0\n",
        "    cur = get_dur(str(up_out)); final_video = up_out\n",
        "    if cur>0 and cur < duration_sec:\n",
        "        reps = int((duration_sec//cur)+1)\n",
        "        lf = OUT_DIR / \"concat.txt\"\n",
        "        with open(lf,\"w\") as f:\n",
        "            for _ in range(reps): f.write(f\"file '{up_out}'\\n\")\n",
        "        stitched = OUT_DIR / (up_out.stem + \"_stitched.mp4\")\n",
        "        run(f\"ffmpeg -y -f concat -safe 0 -i '{lf}' -c copy '{stitched}'\", fail_ok=True)\n",
        "        final_video = stitched if stitched.exists() else up_out\n",
        "    elif cur>duration_sec:\n",
        "        trimmed = OUT_DIR / (up_out.stem + \"_trim.mp4\")\n",
        "        run(f\"ffmpeg -y -i '{up_out}' -t {duration_sec} -c:v libx264 -pix_fmt yuv420p -crf 18 '{trimmed}'\", fail_ok=True)\n",
        "        final_video = trimmed if trimmed.exists() else up_out\n",
        "\n",
        "    # tts + merge audio\n",
        "    try:\n",
        "        run(\"python -m pip install -q gTTS pydub\", fail_ok=True)\n",
        "        from gtts import gTTS\n",
        "        tts_file = OUT_DIR / \"voice.mp3\"\n",
        "        tts_text = prompt_text or \"Tiny AI short.\"\n",
        "        gTTS(tts_text, lang='en').save(str(tts_file))\n",
        "        merged = OUT_DIR / (final_video.stem + \"_final_audio.mp4\")\n",
        "        run(f\"ffmpeg -y -i '{final_video}' -i '{tts_file}' -c:v copy -c:a aac -shortest '{merged}'\", fail_ok=True)\n",
        "        final_with_audio = merged if merged.exists() else final_video\n",
        "    except Exception:\n",
        "        final_with_audio = final_video\n",
        "\n",
        "    # captions\n",
        "    captioned = OUT_DIR / (final_with_audio.stem + \"_captioned.mp4\")\n",
        "    y_pos = max(target_h - 150, 10)\n",
        "    run(f\"ffmpeg -y -i '{final_with_audio}' -vf \\\"drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='{prompt_text}':fontsize=36:fontcolor=white:box=1:boxcolor=0x00000099:x=30:y={y_pos}\\\" -c:a copy '{captioned}'\", fail_ok=True)\n",
        "    final = captioned if captioned.exists() else final_with_audio\n",
        "    ts = int(time.time()); dst = DRIVE_OUT / f\"final_short_{ts}.mp4\"; shutil.copy2(str(final), str(dst))\n",
        "    return str(dst), str(final)\n",
        "\n",
        "# ---------- Generate action: produce three videos and return previews & paths ----------\n",
        "def generate_three(mode, prompt, image, duration_choice, custom_duration):\n",
        "    logs = []\n",
        "    try:\n",
        "        # resolve duration\n",
        "        if duration_choice == \"Custom\":\n",
        "            try: duration_sec = max(1, min(60, int(custom_duration)))\n",
        "            except: return (\"Invalid custom duration\", \"\", \"\", \"\", \"\", \"\", \"\")\n",
        "        else:\n",
        "            duration_sec = int(duration_choice)\n",
        "\n",
        "        # try SVD sample() if loaded\n",
        "        svd_paths = []\n",
        "        if 'sample' in globals() and callable(globals()['sample']):\n",
        "            for i in range(3):\n",
        "                logs.append(f\"Running SVD sample() attempt {i+1}...\")\n",
        "                try:\n",
        "                    out = globals()['sample'](\n",
        "                        input_path=str(image) if (mode==\"IMAGE\" and image) else \"\",\n",
        "                        resize_image=True,\n",
        "                        num_frames=25,\n",
        "                        num_steps=30,\n",
        "                        seed=\"random\",\n",
        "                        decoding_t=2,\n",
        "                        fps_id=6,\n",
        "                        motion_bucket_id=127,\n",
        "                        cond_aug=0.02,\n",
        "                        device='cuda' if ('torch' in globals() and __import__('torch').cuda.is_available()) else 'cpu',\n",
        "                        skip_filter=True\n",
        "                    )\n",
        "                    if isinstance(out, (list,tuple)) and out:\n",
        "                        svd_paths.append(str(out[0]))\n",
        "                    elif isinstance(out,str):\n",
        "                        svd_paths.append(out)\n",
        "                except Exception as e:\n",
        "                    logs.append(f\"SVD run failed: {e}\")\n",
        "                    break\n",
        "\n",
        "        # fallback: copy sample into job files for each of the 3 slots\n",
        "        if len(svd_paths) < 3:\n",
        "            base_candidate = Path(\"/content/drive/MyDrive/AI-Automation/last_uploaded_sample.mp4\")\n",
        "            if base_candidate.exists():\n",
        "                fallback_src = base_candidate\n",
        "                logs.append(\"Using Drive backup sample\")\n",
        "            elif FALLBACK_SAMPLE.exists():\n",
        "                fallback_src = FALLBACK_SAMPLE\n",
        "                logs.append(\"Using session fallback sample\")\n",
        "            else:\n",
        "                mp4s = list(Path(\"/content\").glob(\"*.mp4\"))\n",
        "                if mp4s:\n",
        "                    fallback_src = mp4s[0]; logs.append(\"Using /content mp4 fallback\")\n",
        "                else:\n",
        "                    return (\"No sample available. Upload sample to /content or Drive:/AI-Automation/last_uploaded_sample.mp4\", \"\", \"\", \"\", \"\", \"\", \"\")\n",
        "\n",
        "            # create three job copies\n",
        "            for i in range(3):\n",
        "                job_out = str(TMP_BASE / f\"sim_job_{int(time.time())}_{i}.mp4\")\n",
        "                shutil.copy2(str(fallback_src), job_out)\n",
        "                svd_paths.append(job_out)\n",
        "\n",
        "        previews = []\n",
        "        final_paths = []\n",
        "        for idx, p in enumerate(svd_paths[:3]):\n",
        "            logs.append(f\"Post-processing video {idx+1} ...\")\n",
        "            drive_dst, local_final = post_process(p, prompt, duration_sec)\n",
        "            previews.append(local_final)      # local path preview\n",
        "            final_paths.append(drive_dst)     # saved path in Drive\n",
        "\n",
        "        return (\"\\n\".join(logs), previews[0] if previews else \"\", previews[1] if len(previews)>1 else \"\", previews[2] if len(previews)>2 else \"\", final_paths[0] if final_paths else \"\", final_paths[1] if len(final_paths)>1 else \"\", final_paths[2] if len(final_paths)>2 else \"\")\n",
        "    except Exception as e:\n",
        "        return (f\"ERROR: {e}\", \"\", \"\", \"\", \"\", \"\", \"\")\n",
        "\n",
        "# ---------- Compact KlingAI styling (CSS) ----------\n",
        "css = \"\"\"\n",
        ".kling-card { border-radius:10px; padding:12px; box-shadow:0 6px 18px rgba(0,0,0,0.12); background:linear-gradient(180deg,#0f1724, #071124); color:#e6eef8 }\n",
        ".kling-small { font-size:13px }\n",
        ".kling-btn { background:#0ea5a4; color:white; border-radius:8px; padding:8px 12px }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css, title=\"KlingAI Mini\", theme=gr.themes.Soft()) as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"<h3 style='margin:0;color:#c7f9f2'>KlingAI ‚Äî TinyShort Lab</h3>\")\n",
        "            gr.Markdown(\"<div class='kling-small'>Compact UI ‚Ä¢ Load model ‚Ä¢ Generate x3 ‚Ä¢ 3 previews ‚Ä¢ Drive outputs</div>\")\n",
        "            mode = gr.Radio([\"TEXT\",\"IMAGE\"], value=\"TEXT\", label=\"Mode\", elem_id=\"mode\")\n",
        "            prompt = gr.Textbox(lines=2, placeholder=\"woolen cat playing\", label=\"Prompt\")\n",
        "            img_in = gr.Image(type=\"pil\", label=\"Conditioning image (IMAGE mode)\")\n",
        "            with gr.Row():\n",
        "                duration_choice = gr.Dropdown([\"5\",\"10\",\"15\",\"20\",\"30\",\"Custom\"], value=\"15\", label=\"Duration (sec)\")\n",
        "                custom_duration = gr.Textbox(value=\"15\", label=\"Custom sec (1-60)\")\n",
        "            with gr.Row():\n",
        "                load_btn = gr.Button(\"Load SVD Model\", elem_id=\"loadbtn\")\n",
        "                gen_btn = gr.Button(\"Generate 3 Shorts\", elem_id=\"genbtn\", variant=\"primary\")\n",
        "            status = gr.Textbox(label=\"Status / Logs\", interactive=False, value=\"Ready\", lines=6)\n",
        "        with gr.Column(scale=3):\n",
        "            # previews grid\n",
        "            gr.Markdown(\"<div style='display:flex;gap:8px;align-items:flex-start'>\")\n",
        "            preview1 = gr.Video(label=\"Preview 1\")\n",
        "            preview2 = gr.Video(label=\"Preview 2\")\n",
        "            preview3 = gr.Video(label=\"Preview 3\")\n",
        "            gr.Markdown(\"</div>\")\n",
        "            with gr.Row():\n",
        "                out1 = gr.Textbox(label=\"Drive Path 1\", interactive=False)\n",
        "                out2 = gr.Textbox(label=\"Drive Path 2\", interactive=False)\n",
        "                out3 = gr.Textbox(label=\"Drive Path 3\", interactive=False)\n",
        "            gr.Markdown(\"<div class='kling-small' style='margin-top:8px;color:#9be7e5'>Fallback sample used: {}</div>\".format(FALLBACK_SAMPLE.name))\n",
        "\n",
        "    # Bind buttons\n",
        "    load_btn.click(lambda: load_svd_model(), outputs=[status])\n",
        "    gen_btn.click(generate_three, inputs=[mode, prompt, img_in, duration_choice, custom_duration], outputs=[status, preview1, preview2, preview3, out1, out2, out3])\n",
        "\n",
        "demo.launch(share=False, debug=True)\n"
      ],
      "metadata": {
        "id": "4WW74wFetSxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}