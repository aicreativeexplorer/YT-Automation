{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnGUFaVmLK3/j8TyeAAId7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicreativeexplorer/YT-Automation/blob/main/YT_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === AUTO-RUN HEARTBEAT (every 60 minutes) ===\n",
        "import threading, time, IPython\n",
        "\n",
        "HEARTBEAT_INTERVAL = 60 * 60   # 60 minutes\n",
        "\n",
        "def heartbeat_loop():\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"\\n‚ù§Ô∏è  Heartbeat triggered ‚Äî auto-running keepalive cell...\")\n",
        "            IPython.display.display(IPython.display.Javascript(\n",
        "                'google.colab.kernel.invokeFunction(\"keepalive\", [], {});'\n",
        "            ))\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Heartbeat error:\", e)\n",
        "        time.sleep(HEARTBEAT_INTERVAL)\n",
        "\n",
        "def start_heartbeat():\n",
        "    t = threading.Thread(target=heartbeat_loop, daemon=True)\n",
        "    t.start()\n",
        "    print(\"üî• Auto-run heartbeat started (interval = 60 min).\")\n",
        "\n",
        "# Register a hidden keepalive callback\n",
        "from google.colab import output\n",
        "def _keepalive():\n",
        "    print(\"‚è≥ Notebook auto-ran keepalive at\", time.ctime())\n",
        "output.register_callback(\"keepalive\", _keepalive)\n",
        "\n",
        "start_heartbeat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "tIwvr7z92m-0",
        "outputId": "d4a96c6b-83ec-4098-8b52-e950aa3dfb42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ù§Ô∏è  Heartbeat triggered ‚Äî auto-running keepalive cell...\n",
            "üî• Auto-run heartbeat started (interval = 60 min).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.kernel.invokeFunction(\"keepalive\", [], {});"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Notebook auto-ran keepalive at Mon Nov 24 08:05:05 2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "def start_autosave(interval_sec=300, source_path=\"/content/drive/MyDrive/AI-Automation\", backup_root=\"/content/drive/MyDrive/YT_Backups\"):\n",
        "    def autosave_loop():\n",
        "        while True:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            backup_path = f\"{backup_root}/backup_{timestamp}\"\n",
        "\n",
        "            try:\n",
        "                shutil.copytree(source_path, backup_path)\n",
        "                print(f\"[AUTOSAVE] Backup created at {backup_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[AUTOSAVE ERROR] {e}\")\n",
        "\n",
        "            time.sleep(interval_sec)\n",
        "\n",
        "    thread = threading.Thread(target=autosave_loop, daemon=True)\n",
        "    thread.start()\n",
        "    print(f\"[AUTOSAVE] Started autosave every {interval_sec} seconds.\")\n"
      ],
      "metadata": {
        "id": "uHF0ehFj3va1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_autosave(interval_sec=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14fzmXW78cpC",
        "outputId": "e4c1021a-74c6-4fca-abb7-5ce6fd9a16c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTOSAVE] Started autosave every 300 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FULLY-ROBUST AUTO-PERSIST STARTUP CELL (advanced, single cell)\n",
        "# - mounts Drive (safe)\n",
        "# - finds a working Drive root (handles strange mountpoints)\n",
        "# - restores uploaded sample if found (uses /content/sample_from_upload.mp4 hint)\n",
        "# - provides: save_to_drive(), start_autosave(), stop_autosave(), git_push_small()\n",
        "# - autosave fallback to /content/drive_backup if Drive is not writable\n",
        "# - safe defaults, rotation, size checks, and clear logging\n",
        "\n",
        "import os, shutil, time, threading, tempfile, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "UPLOADED_HINT = Path(\"/content/sample_from_upload.mp4\")   # <-- your session-uploaded file (use as file URL)\n",
        "PREFERRED_DRIVE_SUBPATH = \"AI-Automation\"                  # top-level folder in MyDrive to use\n",
        "MAX_COPY_BYTES = 200 * 1024 * 1024                        # 200 MB\n",
        "AUTOSAVE_INTERVAL_SEC = 300                               # 5 minutes\n",
        "BACKUP_ROTATE_KEEP = 12\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def _log(*a, **k): print(\"[AUTO-PERSIST]\", *a, **k)\n",
        "\n",
        "# Standard Colab mount attempt (safe)\n",
        "def try_mount_drive():\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "    except Exception:\n",
        "        _log(\"Not running in Colab (no google.colab). Skipping Drive mount.\")\n",
        "        return False, None\n",
        "    try:\n",
        "        # mount to standard location; if already mounted this is idempotent\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        _log(\"drive.mount called.\")\n",
        "    except Exception as e:\n",
        "        _log(\"drive.mount raised:\", e)\n",
        "\n",
        "    # detect proper drive root (MyDrive)\n",
        "    candidates = [\n",
        "        Path(\"/content/drive/MyDrive\"),\n",
        "        Path(\"/content/drive\"),   # fallback\n",
        "        Path(\"/content/drive_google/MyDrive\"),  # some environments\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c.exists() and any(c.iterdir()):  # non-empty\n",
        "            _log(\"Detected Drive root:\", c)\n",
        "            return True, c\n",
        "    # if none found, still return mountpoint if exists\n",
        "    if Path(\"/content/drive\").exists():\n",
        "        _log(\"Drive present at /content/drive (but MyDrive not found). Using /content/drive.\")\n",
        "        return True, Path(\"/content/drive\")\n",
        "    _log(\"Drive not detected after mount attempt.\")\n",
        "    return False, None\n",
        "\n",
        "def ensure_drive_paths(drive_root: Path, subpath=PREFERRED_DRIVE_SUBPATH):\n",
        "    try:\n",
        "        target = drive_root / subpath\n",
        "        target.mkdir(parents=True, exist_ok=True)\n",
        "        (target / \"outputs\").mkdir(parents=True, exist_ok=True)\n",
        "        (target / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
        "        (target / \"session_backups\").mkdir(parents=True, exist_ok=True)\n",
        "        return target\n",
        "    except Exception as e:\n",
        "        _log(\"Could not create Drive subpaths:\", e)\n",
        "        return None\n",
        "\n",
        "def _safe_copy(src: Path, dst: Path, max_bytes=MAX_COPY_BYTES):\n",
        "    try:\n",
        "        if not src.exists():\n",
        "            _log(\"Source missing:\", src)\n",
        "            return False\n",
        "        # avoid copying to same file\n",
        "        try:\n",
        "            if src.resolve() == dst.resolve():\n",
        "                _log(\"Source and destination are identical; skipping copy:\", src)\n",
        "                return True\n",
        "        except Exception:\n",
        "            pass\n",
        "        size = src.stat().st_size\n",
        "        if size > max_bytes:\n",
        "            _log(\"Skipping copy (too large):\", src, size)\n",
        "            return False\n",
        "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy2(str(src), str(dst))\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        _log(\"Copy failed:\", src, dst, e)\n",
        "        return False\n",
        "\n",
        "# ---------- main init ----------\n",
        "_drive_mounted, drive_root = try_mount_drive()\n",
        "DRIVE_OK = False\n",
        "DRIVE_BASE = None\n",
        "if _drive_mounted and drive_root:\n",
        "    DRIVE_BASE = ensure_drive_paths(drive_root)\n",
        "    if DRIVE_BASE:\n",
        "        DRIVE_OK = True\n",
        "        _log(\"Drive workspace ready at:\", DRIVE_BASE)\n",
        "    else:\n",
        "        _log(\"Drive present but cannot create workspace subpaths (permission/op error). Will fallback.\")\n",
        "else:\n",
        "    _log(\"Drive not usable; will fallback to local drive_backup.\")\n",
        "\n",
        "# fallback local backup path\n",
        "LOCAL_BACKUP_BASE = Path(\"/content/drive_backup/MyDrive\") / PREFERRED_DRIVE_SUBPATH\n",
        "if not DRIVE_OK:\n",
        "    LOCAL_BACKUP_BASE.mkdir(parents=True, exist_ok=True)\n",
        "    (LOCAL_BACKUP_BASE / \"outputs\").mkdir(parents=True, exist_ok=True)\n",
        "    (LOCAL_BACKUP_BASE / \"session_backups\").mkdir(parents=True, exist_ok=True)\n",
        "    _log(\"Using local backup base:\", LOCAL_BACKUP_BASE)\n",
        "\n",
        "# ---------- restore uploaded sample (if exists) ----------\n",
        "_local_sample = None\n",
        "_drive_sample = None\n",
        "if UPLOADED_HINT.exists():\n",
        "    _log(\"Found uploaded sample hint:\", UPLOADED_HINT)\n",
        "    # copy into /content (if not already there)\n",
        "    if UPLOADED_HINT.parent != Path(\"/content\"):\n",
        "        try:\n",
        "            dst = Path(\"/content\") / UPLOADED_HINT.name\n",
        "            if _safe_copy(UPLOADED_HINT, dst):\n",
        "                _local_sample = dst\n",
        "                _log(\"Copied uploaded ->\", dst)\n",
        "        except Exception as e:\n",
        "            _log(\"Warn: failed to copy into /content:\", e)\n",
        "    else:\n",
        "        _local_sample = UPLOADED_HINT\n",
        "        _log(\"Uploaded already in /content:\", _local_sample)\n",
        "    # also try copy into Drive outputs if available\n",
        "    if DRIVE_OK:\n",
        "        drive_sample_path = DRIVE_BASE / \"sample.mp4\"\n",
        "        if _safe_copy(UPLOADED_HINT, drive_sample_path):\n",
        "            _drive_sample = drive_sample_path\n",
        "            _log(\"Copied uploaded -> Drive sample:\", drive_sample_path)\n",
        "        else:\n",
        "            _log(\"Drive copy failed or skipped for sample.\")\n",
        "    else:\n",
        "        # fallback: copy to local backup outputs\n",
        "        local_out = LOCAL_BACKUP_BASE / \"outputs\" / UPLOADED_HINT.name\n",
        "        if _safe_copy(UPLOADED_HINT, local_out):\n",
        "            _log(\"Copied uploaded -> local backup outputs:\", local_out)\n",
        "else:\n",
        "    _log(\"No uploaded sample found at hint path:\", UPLOADED_HINT)\n",
        "\n",
        "# ---------- API: save_to_drive (smart) ----------\n",
        "def save_to_drive(local_path, dest_name=None):\n",
        "    local_path = Path(local_path)\n",
        "    if not local_path.exists():\n",
        "        raise FileNotFoundError(local_path)\n",
        "    if local_path.stat().st_size > MAX_COPY_BYTES:\n",
        "        raise ValueError(\"File too large to save via helper.\")\n",
        "    ts = int(time.time())\n",
        "    name = dest_name or f\"{local_path.stem}_{ts}{local_path.suffix}\"\n",
        "    if DRIVE_OK:\n",
        "        dst = DRIVE_BASE / \"outputs\" / name\n",
        "        ok = _safe_copy(local_path, dst)\n",
        "        if ok:\n",
        "            _log(\"Saved to Drive:\", dst)\n",
        "            return dst\n",
        "        else:\n",
        "            _log(\"Failed to save to Drive; saving to local backup instead.\")\n",
        "    # fallback\n",
        "    dst2 = LOCAL_BACKUP_BASE / \"outputs\" / name\n",
        "    _safe_copy(local_path, dst2)\n",
        "    _log(\"Saved to local backup:\", dst2)\n",
        "    return dst2\n",
        "\n",
        "# ---------- small git push helper (optional) ----------\n",
        "def git_push_small(file_path, repo=\"aicreativeexplorer/YT-Automation\", branch=\"main\"):\n",
        "    token = os.environ.get(\"GITHUB_TOKEN\")\n",
        "    if not token:\n",
        "        raise EnvironmentError(\"Set GITHUB_TOKEN env var in Colab before calling git_push_small().\")\n",
        "    file_path = Path(file_path)\n",
        "    if not file_path.exists():\n",
        "        raise FileNotFoundError(file_path)\n",
        "    if file_path.stat().st_size > 100*1024*1024:\n",
        "        raise ValueError(\"File too large for git_push_small.\")\n",
        "    tmp = Path(tempfile.mkdtemp(prefix=\"kling_git_\"))\n",
        "    clone_url = f\"https://{token}@github.com/{repo}.git\"\n",
        "    try:\n",
        "        _log(\"Cloning repo to temp...\")\n",
        "        res = subprocess.run([\"git\",\"clone\",\"--depth\",\"1\",\"--branch\",branch,clone_url,str(tmp)], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        if res.returncode != 0:\n",
        "            _log(\"Git clone failed:\", res.stderr.strip()[:1000])\n",
        "            return False\n",
        "        shutil.copy2(str(file_path), str(tmp/file_path.name))\n",
        "        subprocess.run([\"git\",\"config\",\"user.email\",\"colab@local\"], cwd=str(tmp))\n",
        "        subprocess.run([\"git\",\"config\",\"user.name\",\"ColabAuto\"], cwd=str(tmp))\n",
        "        subprocess.run([\"git\",\"add\",file_path.name], cwd=str(tmp))\n",
        "        subprocess.run([\"git\",\"commit\",\"-m\",f\"Add {file_path.name} via Colab autosave\"], cwd=str(tmp))\n",
        "        push = subprocess.run([\"git\",\"push\",\"origin\",branch], cwd=str(tmp), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        if push.returncode != 0:\n",
        "            _log(\"Git push failed:\", push.stderr[:2000])\n",
        "            return False\n",
        "        _log(\"Pushed to GitHub:\", repo)\n",
        "        return True\n",
        "    finally:\n",
        "        _log(\"Git temp dir:\", tmp)\n",
        "\n",
        "# ---------- autosave loop ----------\n",
        "_autosave_thread = None\n",
        "_autosave_stop = threading.Event()\n",
        "\n",
        "def _rotate(base, keep=BACKUP_ROTATE_KEEP):\n",
        "    try:\n",
        "        base = Path(base) / \"session_backups\"\n",
        "        if not base.exists(): return\n",
        "        items = sorted([p for p in base.iterdir() if p.is_dir()], key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "        for old in items[keep:]:\n",
        "            try:\n",
        "                shutil.rmtree(old)\n",
        "                _log(\"Removed old backup:\", old)\n",
        "            except Exception as e:\n",
        "                _log(\"Failed to remove old backup:\", old, e)\n",
        "    except Exception as e:\n",
        "        _log(\"Rotate error:\", e)\n",
        "\n",
        "def _autosave_loop(interval_sec=AUTOSAVE_INTERVAL_SEC, paths_to_sync=None, max_bytes=MAX_COPY_BYTES):\n",
        "    paths_to_sync = paths_to_sync or [\"/content\"]\n",
        "    target_base = DRIVE_BASE if DRIVE_OK else LOCAL_BACKUP_BASE\n",
        "    _log(\"[autosave] starting. interval=\", interval_sec, \"target=\", target_base)\n",
        "    while not _autosave_stop.is_set():\n",
        "        try:\n",
        "            ts = int(time.time())\n",
        "            backup_dir = target_base / \"session_backups\" / f\"snapshot_{ts}\"\n",
        "            backup_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for p in paths_to_sync:\n",
        "                src = Path(p)\n",
        "                if not src.exists(): continue\n",
        "                for f in src.glob(\"*\"):\n",
        "                    # skip copy of Drive itself\n",
        "                    if \"/content/drive\" in str(f): continue\n",
        "                    try:\n",
        "                        if f.is_file():\n",
        "                            _safe_copy(f, backup_dir / f.name, max_bytes)\n",
        "                        elif f.is_dir():\n",
        "                            dtarget = backup_dir / f.name\n",
        "                            dtarget.mkdir(parents=True, exist_ok=True)\n",
        "                            for sf in f.glob(\"*\"):\n",
        "                                if sf.is_file():\n",
        "                                    _safe_copy(sf, dtarget / sf.name, max_bytes)\n",
        "                    except Exception as e:\n",
        "                        _log(\"Autosave copy warning:\", f, e)\n",
        "            _log(\"[autosave] snapshot ->\", backup_dir)\n",
        "            _rotate(target_base)\n",
        "        except Exception as e:\n",
        "            _log(\"[autosave] loop error:\", e)\n",
        "        _autosave_stop.wait(interval_sec)\n",
        "    _log(\"Autosave loop stopped\")\n",
        "\n",
        "def start_autosave(interval_sec=AUTOSAVE_INTERVAL_SEC, paths_to_sync=None):\n",
        "    global _autosave_thread, _autosave_stop\n",
        "    if _autosave_thread and _autosave_thread.is_alive():\n",
        "        _log(\"Autosave already running.\")\n",
        "        return False\n",
        "    _autosave_stop.clear()\n",
        "    _autosave_thread = threading.Thread(target=_autosave_loop, args=(interval_sec, paths_to_sync, MAX_COPY_BYTES), daemon=True)\n",
        "    _autosave_thread.start()\n",
        "    _log(\"[AUTOSAVE] Started every\", interval_sec, \"seconds. Target:\", DRIVE_BASE if DRIVE_OK else LOCAL_BACKUP_BASE)\n",
        "    return True\n",
        "\n",
        "def stop_autosave(timeout=5):\n",
        "    global _autosave_thread, _autosave_stop\n",
        "    if _autosave_thread and _autosave_thread.is_alive():\n",
        "        _autosave_stop.set()\n",
        "        _autosave_thread.join(timeout=timeout)\n",
        "        _log(\"Stopped autosave.\")\n",
        "        return True\n",
        "    _log(\"No autosave running.\")\n",
        "    return False\n",
        "\n",
        "# ---------- finish init ----------\n",
        "_log(\"INIT COMPLETE.\")\n",
        "_log(\"Detected sample (local):\", str(_local_sample) if _local_sample else \"NONE\")\n",
        "_log(\"Detected sample (drive):\", str(_drive_sample) if _drive_sample else \"NONE\")\n",
        "_log(\"Drive usable:\", DRIVE_OK, \"Drive base:\", DRIVE_BASE if DRIVE_OK else LOCAL_BACKUP_BASE)\n",
        "_log(\"Uploaded sample path to use as URL:\", UPLOADED_HINT)\n",
        "\n",
        "# start autosave automatically but only if we have a target\n",
        "start_autosave()\n",
        "\n",
        "# Expose variables for interactive use\n",
        "__AUTO_PERSIST_META__ = dict(\n",
        "    DRIVE_OK=DRIVE_OK,\n",
        "    DRIVE_BASE=str(DRIVE_BASE if DRIVE_OK else LOCAL_BACKUP_BASE),\n",
        "    LOCAL_SAMPLE=str(_local_sample) if _local_sample else \"\",\n",
        "    DRIVE_SAMPLE=str(_drive_sample) if _drive_sample else \"\",\n",
        "    UPLOADED_HINT=str(UPLOADED_HINT)\n",
        ")\n",
        "\n",
        "_log(\"Done. Use save_to_drive(path), git_push_small(path) (with GITHUB_TOKEN), stop_autosave() if needed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywIm0Eny2IFT",
        "outputId": "67730b13-62b3-4fb2-c7b3-3c875b65d316"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTO-PERSIST] drive.mount raised: Mountpoint must not already contain files\n",
            "[AUTO-PERSIST] Detected Drive root: /content/drive\n",
            "[AUTO-PERSIST] Drive workspace ready at: /content/drive/AI-Automation\n",
            "[AUTO-PERSIST] Found uploaded sample hint: /content/sample_from_upload.mp4\n",
            "[AUTO-PERSIST] Uploaded already in /content: /content/sample_from_upload.mp4\n",
            "[AUTO-PERSIST] Copied uploaded -> Drive sample: /content/drive/AI-Automation/sample.mp4\n",
            "[AUTO-PERSIST] INIT COMPLETE.\n",
            "[AUTO-PERSIST] Detected sample (local): /content/sample_from_upload.mp4\n",
            "[AUTO-PERSIST] Detected sample (drive): /content/drive/AI-Automation/sample.mp4\n",
            "[AUTO-PERSIST] Drive usable: True Drive base: /content/drive/AI-Automation\n",
            "[AUTO-PERSIST] Uploaded sample path to use as URL: /content/sample_from_upload.mp4\n",
            "[AUTO-PERSIST] [autosave] starting. interval= 300 target= /content/drive/AI-Automation\n",
            "[AUTO-PERSIST] [AUTOSAVE] Started every 300 seconds. Target: /content/drive/AI-Automation\n",
            "[AUTO-PERSIST] Done. Use save_to_drive(path), git_push_small(path) (with GITHUB_TOKEN), stop_autosave() if needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhGVcsjW4nbQ",
        "outputId": "8a681fb1-e52a-464d-82a8-e0308238c0e3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# 1) Inspect what's currently in /content/drive\n",
        "echo \"Contents of /content/drive BEFORE fix:\"\n",
        "ls -la /content/drive || true\n",
        "echo \"----\"\n",
        "\n",
        "# 2) If non-empty, move it to a safe backup folder instead of deleting\n",
        "mkdir -p /content/drive_backup || true\n",
        "if [ \"$(ls -A /content/drive 2>/dev/null)\" ]; then\n",
        "  echo \"Moving existing /content/drive/* -> /content/drive_backup/\"\n",
        "  mv /content/drive/* /content/drive_backup/ 2>/dev/null || true\n",
        "  echo \"Moved. Backup dir: /content/drive_backup/\"\n",
        "else\n",
        "  echo \"/content/drive is already empty.\"\n",
        "fi\n",
        "echo \"----\"\n",
        "\n",
        "# 3) Ensure mountpoint dir exists and is empty\n",
        "rm -rf /content/drive\n",
        "mkdir -p /content/drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJlgXIlX3heX",
        "outputId": "de13bd18-baa7-4a28-ee07-fca786499eac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/drive BEFORE fix:\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Nov 24 09:35 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 24 09:35 ..\n",
            "----\n",
            "/content/drive is already empty.\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "SRC=\"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "if [ -f \"$SRC\" ]; then\n",
        "  mkdir -p /content/drive/MyDrive/AI-Automation\n",
        "  cp \"$SRC\" /content/drive/MyDrive/AI-Automation/sample.mp4\n",
        "  cp \"$SRC\" \"/content/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "  echo \"Copied uploaded file to Drive and /content.\"\n",
        "else\n",
        "  echo \"WARNING: Uploaded file missing at $SRC\"\n",
        "fi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Y8T7ZI4xxm",
        "outputId": "2407aa50-68ed-44c0-f32e-f35273ea7ae6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Uploaded file missing at /mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiafjBDXAm5J",
        "outputId": "3e7119a3-f9c0-43d1-b921-78ba6cfae13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG OK\n"
          ]
        }
      ],
      "source": [
        "# CONFIG ‚Äî edit only if you moved paths\n",
        "REPO_DIR = \"/content/YT-Automation\"\n",
        "NOTEBOOK_NAME = \"YT-Automation.ipynb\"\n",
        "UPLOADED_VIDEO = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"  # your uploaded demo\n",
        "DRIVE_TOKEN_PATH = \"/content/drive/MyDrive/AI-Automation/hf_token.txt\"  # put HF token here\n",
        "OUTPUT_DRIVE_FOLDER = \"/content/drive/MyDrive/AI-Automation/outputs/stitched\"\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/AI-Automation/checkpoints\"\n",
        "SVD_VERSION = \"svd\"  # 'svd' (open) or 'svd-xt-1-1' (better but gated)\n",
        "USE_AUTO_PUSH = False  # no auto-push by default\n",
        "print(\"CONFIG OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Auto-login to HuggingFace if token present in Drive\n",
        "import os\n",
        "if os.path.exists(DRIVE_TOKEN_PATH):\n",
        "    from huggingface_hub import login\n",
        "    with open(DRIVE_TOKEN_PATH,'r') as f:\n",
        "        token = f.read().strip()\n",
        "    login(token=token)\n",
        "    print(\"Logged into HuggingFace from Drive token.\")\n",
        "else:\n",
        "    print(\"No HF token at\", DRIVE_TOKEN_PATH, \"- you'll be asked if downloading gated models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg2ZtRuIFxet",
        "outputId": "43f2ec91-aa33-428a-eddb-27057b1a57a6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Logged into HuggingFace from Drive token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full backend replacement: write Flask app, start server in background\n",
        "# Paste & run this cell in Colab.\n",
        "\n",
        "import os, textwrap, subprocess, time, threading\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Ensure Flask is installed\n",
        "print(\"Installing Flask (if missing)...\")\n",
        "subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-q\", \"Flask\"], check=False)\n",
        "\n",
        "# 2) Write the Flask backend file\n",
        "backend_path = Path(\"/content/klingai_flask_backend.py\")\n",
        "backend_code = r'''\n",
        "import os, json, time, uuid, shutil, threading, subprocess\n",
        "from pathlib import Path\n",
        "from flask import Flask, request, jsonify, send_file, abort\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "UPLOAD_ROOT = Path(\"/content/uploads\")\n",
        "JOB_ROOT = Path(\"/tmp/klingai_jobs\")\n",
        "OUTPUT_LOCAL = Path(\"/content/outputs\")\n",
        "# try Drive output if mounted\n",
        "DRIVE_OUTPUTS = Path(\"/content/drive/MyDrive/AI-Automation/outputs\")\n",
        "if DRIVE_OUTPUTS.exists():\n",
        "    OUTPUT_ROOT = DRIVE_OUTPUTS\n",
        "else:\n",
        "    OUTPUT_ROOT = OUTPUT_LOCAL\n",
        "\n",
        "UPLOAD_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "JOB_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_LOCAL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Developer-provided uploaded path (session upload hint)\n",
        "UPLOADED_HINT = Path(r\"/mnt/data/YT_Automation (1).ipynb\")\n",
        "\n",
        "# Job store\n",
        "_jobs = {}\n",
        "_jobs_lock = threading.Lock()\n",
        "\n",
        "# Worker thread pool (just spawn per job for simplicity)\n",
        "def _create_simulated_mp4(out_path: Path, text=\"Simulated output\", duration=2):\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    txt = str(text).replace(\"'\", \"\").replace(\"\\n\",\" \")[:200]\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\"-y\",\n",
        "        \"-f\",\"lavfi\",\"-i\",f\"color=size=720x1280:rate=6:color=0x101018\",\n",
        "        \"-t\", str(max(1,int(duration))),\n",
        "        \"-vf\", f\"drawtext=text='{txt}':fontsize=28:fontcolor=white:x=20:y=40\",\n",
        "        str(out_path)\n",
        "    ]\n",
        "    try:\n",
        "        p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
        "        return True, \"\"\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "def _try_call_sample(cfg, out_path:Path):\n",
        "    \"\"\"\n",
        "    Attempt to call a sample() function available in the global session.\n",
        "    This works only if the notebook/session has defined sample() and necessary libs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if 'sample' in globals() and callable(globals()['sample']):\n",
        "            kwargs = dict(\n",
        "                input_path=cfg.get(\"conditioning_image\",\"\"),\n",
        "                resize_image=True,\n",
        "                num_frames=cfg.get(\"num_frames\", 14),\n",
        "                num_steps=cfg.get(\"num_steps\", 30),\n",
        "                seed=cfg.get(\"seed\", \"random\"),\n",
        "                decoding_t=2,\n",
        "                fps_id=6,\n",
        "                motion_bucket_id=127,\n",
        "                cond_aug=0.02,\n",
        "                device='cuda' if ('torch' in globals() and __import__('torch').cuda.is_available()) else 'cpu',\n",
        "                skip_filter=True\n",
        "            )\n",
        "            out = globals()['sample'](**kwargs)\n",
        "            # If sample returned a path or list, try to use it\n",
        "            if isinstance(out, (list, tuple)) and out:\n",
        "                candidate = Path(out[0])\n",
        "                if candidate.exists():\n",
        "                    shutil.copy2(str(candidate), str(out_path))\n",
        "                    return True, \"sample() produced output\"\n",
        "            elif isinstance(out, str):\n",
        "                candidate = Path(out)\n",
        "                if candidate.exists():\n",
        "                    shutil.copy2(str(candidate), str(out_path))\n",
        "                    return True, \"sample() produced output\"\n",
        "    except Exception as e:\n",
        "        return False, f\"sample() call failed: {e}\"\n",
        "    return False, \"no sample() available\"\n",
        "\n",
        "def _process_job(jobid):\n",
        "    with _jobs_lock:\n",
        "        job = _jobs.get(jobid)\n",
        "        if not job:\n",
        "            return\n",
        "        job['status'] = 'running'\n",
        "        job['logs'].append('Job started')\n",
        "    jobdir = Path(job['jobdir'])\n",
        "    out_path = jobdir / f\"{jobid}.mp4\"\n",
        "    cfg = job.get('cfg', {})\n",
        "    # 1) if user uploaded a file for this job, use it as conditioning / copy to output (fast path)\n",
        "    user_file = job.get('uploaded_file')\n",
        "    used_sample = False\n",
        "    if user_file:\n",
        "        upath = Path(user_file)\n",
        "        if upath.exists():\n",
        "            # attempt to remux or copy to out_path\n",
        "            try:\n",
        "                # remux to mp4 with libx264 to ensure compatibility\n",
        "                cmd = [\"ffmpeg\",\"-y\",\"-i\", str(upath), \"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-crf\",\"18\", str(out_path)]\n",
        "                subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True, text=True)\n",
        "                used_sample = True\n",
        "                _msg = \"Used uploaded file as output\"\n",
        "                with _jobs_lock:\n",
        "                    job['status'] = 'done'\n",
        "                    job['progress'] = 100\n",
        "                    job['logs'].append(_msg)\n",
        "                    job['output'] = str(out_path)\n",
        "                # copy to OUTPUT_ROOT\n",
        "                try:\n",
        "                    dst = OUTPUT_ROOT / out_path.name\n",
        "                    shutil.copy2(str(out_path), str(dst))\n",
        "                except Exception:\n",
        "                    pass\n",
        "                return\n",
        "            except Exception as e:\n",
        "                with _jobs_lock:\n",
        "                    job['logs'].append(\"Failed to remux uploaded file: \" + str(e))\n",
        "    # 2) attempt to call sample() if present\n",
        "    try:\n",
        "        ok, info = _try_call_sample(cfg, out_path)\n",
        "        if ok:\n",
        "            with _jobs_lock:\n",
        "                job['status'] = 'done'\n",
        "                job['progress'] = 100\n",
        "                job['logs'].append(str(info))\n",
        "                job['output'] = str(out_path)\n",
        "            try:\n",
        "                dst = OUTPUT_ROOT / out_path.name\n",
        "                shutil.copy2(str(out_path), str(dst))\n",
        "            except Exception:\n",
        "                pass\n",
        "            return\n",
        "        else:\n",
        "            with _jobs_lock:\n",
        "                job['logs'].append(\"sample() not used: \" + str(info))\n",
        "    except Exception as e:\n",
        "        with _jobs_lock:\n",
        "            job['logs'].append(\"sample() call error: \" + str(e))\n",
        "\n",
        "    # 3) if we have an explicit conditioning image/video path in cfg, and it exists, try simple transform (remux -> ensure mp4)\n",
        "    cond = cfg.get('conditioning_image') or cfg.get('input_path') or cfg.get('conditioning_video')\n",
        "    if cond:\n",
        "        condp = Path(cond)\n",
        "        if condp.exists():\n",
        "            try:\n",
        "                cmd = [\"ffmpeg\",\"-y\",\"-i\", str(condp), \"-c:v\",\"libx264\",\"-pix_fmt\",\"yuv420p\",\"-crf\",\"18\", str(out_path)]\n",
        "                subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True, text=True)\n",
        "                with _jobs_lock:\n",
        "                    job['status'] = 'done'\n",
        "                    job['progress'] = 100\n",
        "                    job['logs'].append(\"Transcoded conditioning file to output\")\n",
        "                    job['output'] = str(out_path)\n",
        "                try:\n",
        "                    dst = OUTPUT_ROOT / out_path.name\n",
        "                    shutil.copy2(str(out_path), str(dst))\n",
        "                except Exception:\n",
        "                    pass\n",
        "                return\n",
        "            except Exception as e:\n",
        "                with _jobs_lock:\n",
        "                    job['logs'].append(\"Failed transcode of conditioning file: \" + str(e))\n",
        "\n",
        "    # 4) fallback: create a simulated MP4 with drawtext using the prompt\n",
        "    try:\n",
        "        prompt = cfg.get('prompt') or \"Tiny AI short.\"\n",
        "        duration = int(cfg.get('duration', 2))\n",
        "        ok, err = _create_simulated_mp4(out_path, prompt, duration)\n",
        "        if ok:\n",
        "            with _jobs_lock:\n",
        "                job['status'] = 'done'\n",
        "                job['progress'] = 100\n",
        "                job['logs'].append(\"Created simulated mp4\")\n",
        "                job['output'] = str(out_path)\n",
        "            try:\n",
        "                dst = OUTPUT_ROOT / out_path.name\n",
        "                shutil.copy2(str(out_path), str(dst))\n",
        "            except Exception:\n",
        "                pass\n",
        "            return\n",
        "        else:\n",
        "            with _jobs_lock:\n",
        "                job['status'] = 'error'\n",
        "                job['logs'].append(\"Simulated mp4 creation failed: \" + str(err))\n",
        "            return\n",
        "    except Exception as e:\n",
        "        with _jobs_lock:\n",
        "            job['status'] = 'error'\n",
        "            job['logs'].append(\"Unexpected processing error: \" + str(e))\n",
        "        return\n",
        "\n",
        "# Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def root():\n",
        "    return jsonify({\"ok\": True, \"msg\":\"KlingAI Flask backend alive\"}), 200\n",
        "\n",
        "@app.route(\"/api/generate\", methods=[\"POST\"])\n",
        "def api_generate():\n",
        "    try:\n",
        "        prompt = request.form.get(\"prompt\", \"\") or request.values.get(\"prompt\",\"\")\n",
        "        mode = request.form.get(\"mode\", \"TEXT\")\n",
        "        duration = request.form.get(\"duration\", request.form.get(\"dur\",\"2\"))\n",
        "        num_frames = int(request.form.get(\"num_frames\", request.form.get(\"frames\", 25)))\n",
        "        seed = request.form.get(\"seed\", \"random\")\n",
        "        # create job\n",
        "        jobid = \"job-\" + uuid.uuid4().hex[:12]\n",
        "        jobdir = JOB_ROOT / jobid\n",
        "        jobdir.mkdir(parents=True, exist_ok=True)\n",
        "        cfg = {\n",
        "            \"prompt\": prompt,\n",
        "            \"mode\": mode,\n",
        "            \"duration\": int(duration) if str(duration).isdigit() else 2,\n",
        "            \"num_frames\": num_frames,\n",
        "            \"seed\": seed,\n",
        "            \"created_at\": int(time.time())\n",
        "        }\n",
        "        # if file uploaded with request, save it\n",
        "        uploaded_file_path = None\n",
        "        if \"file\" in request.files:\n",
        "            f = request.files[\"file\"]\n",
        "            fname = f.filename or f\"{jobid}_upload\"\n",
        "            dst = jobdir / fname\n",
        "            f.save(str(dst))\n",
        "            uploaded_file_path = str(dst)\n",
        "            cfg['conditioning_image'] = str(dst)\n",
        "        else:\n",
        "            # fallback: if developer-provided hint exists and is a media file, use as conditioning\n",
        "            if UPLOADED_HINT.exists() and UPLOADED_HINT.is_file():\n",
        "                # only accept if extension looks like media\n",
        "                if UPLOADED_HINT.suffix.lower() in [\".mp4\",\".mov\",\".mkv\",\".avi\",\".webm\",\".gif\"]:\n",
        "                    cfg['conditioning_image'] = str(UPLOADED_HINT)\n",
        "                else:\n",
        "                    # we still store hint info for logs, but won't use as media\n",
        "                    cfg['hint_note'] = str(UPLOADED_HINT)\n",
        "\n",
        "        job_record = {\n",
        "            \"jobId\": jobid,\n",
        "            \"jobdir\": str(jobdir),\n",
        "            \"cfg\": cfg,\n",
        "            \"status\": \"queued\",\n",
        "            \"progress\": 0,\n",
        "            \"logs\": [\"Job queued\"],\n",
        "            \"uploaded_file\": uploaded_file_path,\n",
        "            \"output\": None\n",
        "        }\n",
        "        with _jobs_lock:\n",
        "            _jobs[jobid] = job_record\n",
        "\n",
        "        # start background processing thread for this job\n",
        "        t = threading.Thread(target=_process_job, args=(jobid,), daemon=True)\n",
        "        t.start()\n",
        "\n",
        "        return jsonify({\"jobId\": jobid}), 200\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route(\"/api/job/<jobid>\", methods=[\"GET\"])\n",
        "def api_job(jobid):\n",
        "    with _jobs_lock:\n",
        "        job = _jobs.get(jobid)\n",
        "        if not job:\n",
        "            return jsonify({\"error\":\"job not found\"}), 404\n",
        "        # return safe fields\n",
        "        return jsonify({\n",
        "            \"jobId\": job.get(\"jobId\"),\n",
        "            \"status\": job.get(\"status\"),\n",
        "            \"progress\": job.get(\"progress\"),\n",
        "            \"logs\": job.get(\"logs\")[-20:],\n",
        "            \"outputUrl\": f\"/api/output/{jobid}\" if job.get(\"output\") else None\n",
        "        }), 200\n",
        "\n",
        "@app.route(\"/api/output/<jobid>\", methods=[\"GET\"])\n",
        "def api_output(jobid):\n",
        "    with _jobs_lock:\n",
        "        job = _jobs.get(jobid)\n",
        "        if not job:\n",
        "            return jsonify({\"error\":\"job not found\"}), 404\n",
        "        out = job.get(\"output\")\n",
        "        if not out:\n",
        "            return jsonify({\"error\":\"no output yet\"}), 404\n",
        "        p = Path(out)\n",
        "        if not p.exists():\n",
        "            return jsonify({\"error\":\"output missing\"}), 404\n",
        "        # serve file\n",
        "        try:\n",
        "            return send_file(str(p), mimetype=\"video/mp4\", as_attachment=False)\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\":\"send_file failed: \"+str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # debug run\n",
        "    app.run(host=\"0.0.0.0\", port=7860, threaded=True)\n",
        "'''\n",
        "backend_path.write_text(backend_code)\n",
        "print(\"Wrote backend to\", backend_path)\n",
        "\n",
        "# 3) Start the backend in the background using nohup so it persists in Colab\n",
        "print(\"Starting backend in background (nohup). Output -> /content/klingai_backend.log\")\n",
        "cmd = f\"nohup python {str(backend_path)} > /content/klingai_backend.log 2>&1 & echo $!\"\n",
        "proc = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "pid = proc.stdout.strip()\n",
        "print(\"Backend launch command output (pid or blank):\", pid)\n",
        "time.sleep(1.2)\n",
        "# show last few lines of log to confirm\n",
        "if Path(\"/content/klingai_backend.log\").exists():\n",
        "    print(\"--- backend log (last 40 lines) ---\")\n",
        "    print(\"\\n\".join(Path(\"/content/klingai_backend.log\").read_text().splitlines()[-40:]))\n",
        "else:\n",
        "    print(\"No backend log yet. If process started, check /content/klingai_backend.log later.\")\n",
        "\n",
        "print(\"\\nBackend should be listening on 0.0.0.0:7860 in this Colab runtime.\")\n",
        "print(\"If using ngrok, open a tunnel to port 7860 and use the public URL for the React UI.\")\n",
        "print(\"Example to create an ngrok tunnel (if pyngrok installed and authtoken configured):\")\n",
        "print(\"  from pyngrok import ngrok; ngrok.connect(7860, 'http')\")\n",
        "print(\"API endpoints: /api/generate (POST), /api/job/<jobId> (GET), /api/output/<jobId> (GET)\")\n",
        "print(\"Developer hint path used as uploaded-file hint:\", \"/mnt/data/YT_Automation (1).ipynb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIgrHZFUSxP9",
        "outputId": "7b67ebb5-df2f-42c7-9563-e60dfd65d216"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Flask (if missing)...\n",
            "[AUTO-PERSIST] Autosave loop error: [Errno 95] Operation not supported: '/content/drive/AI-Automation'\n",
            "Wrote backend to /content/klingai_flask_backend.py\n",
            "Starting backend in background (nohup). Output -> /content/klingai_backend.log\n",
            "Backend launch command output (pid or blank): 39311\n",
            "--- backend log (last 40 lines) ---\n",
            " * Serving Flask app 'klingai_flask_backend'\n",
            " * Debug mode: off\n",
            "Address already in use\n",
            "Port 7860 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "\n",
            "Backend should be listening on 0.0.0.0:7860 in this Colab runtime.\n",
            "If using ngrok, open a tunnel to port 7860 and use the public URL for the React UI.\n",
            "Example to create an ngrok tunnel (if pyngrok installed and authtoken configured):\n",
            "  from pyngrok import ngrok; ngrok.connect(7860, 'http')\n",
            "API endpoints: /api/generate (POST), /api/job/<jobId> (GET), /api/output/<jobId> (GET)\n",
            "Developer hint path used as uploaded-file hint: /mnt/data/YT_Automation (1).ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import time, os\n",
        "\n",
        "token = \"35mgc5Udwe6mQ6G8HekXP3Rla9x_7zjHMiABfpRhE1j3aWAm5\"\n",
        "\n",
        "print(\"Setting ngrok authtoken...\")\n",
        "ngrok.set_auth_token(token)\n",
        "conf.get_default().auth_token = token\n",
        "print(\"Done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSCiu4KnczK_",
        "outputId": "352559a2-1dc9-4942-83aa-8b99f137171d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting ngrok authtoken...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step A: start pyngrok tunnel and print public URL\n",
        "# Run this in a Python cell in Colab.\n",
        "\n",
        "# install pyngrok if needed\n",
        "import os, time\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "except Exception:\n",
        "    print(\"Installing pyngrok...\")\n",
        "    os.system(\"python -m pip install -q pyngrok\")\n",
        "    time.sleep(0.5)\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "# create tunnel to port 7860 (your Flask backend)\n",
        "print(\"Opening ngrok tunnel to localhost:7860 ...\")\n",
        "tunnel = ngrok.connect(7860, \"http\")\n",
        "print(\"NGROK TUNNEL OPENED ->\", tunnel.public_url)\n",
        "print(\"If you get an auth error, run: from pyngrok import ngrok; ngrok.set_auth_token('YOUR_TOKEN')\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjlGFJf0V_zg",
        "outputId": "473c7f9c-c1cc-48dd-fc7e-7f8c01678564"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening ngrok tunnel to localhost:7860 ...\n",
            "NGROK TUNNEL OPENED -> https://advertizable-interpenetratively-abbie.ngrok-free.dev\n",
            "If you get an auth error, run: from pyngrok import ngrok; ngrok.set_auth_token('YOUR_TOKEN')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this in a Python cell (Colab). It opens ngrok -> 7860 and prints the public URL.\n",
        "import os, time\n",
        "from getpass import getpass\n",
        "\n",
        "# install pyngrok if missing\n",
        "try:\n",
        "    from pyngrok import ngrok, conf\n",
        "except Exception:\n",
        "    print(\"Installing pyngrok...\")\n",
        "    os.system(\"python -m pip install -q pyngrok\")\n",
        "    time.sleep(0.5)\n",
        "    from pyngrok import ngrok, conf\n",
        "\n",
        "# If there's no auth token configured, prompt safely (only if needed)\n",
        "current_token = conf.get_default().auth_token\n",
        "if not current_token:\n",
        "    print(\"No ngrok auth token found in config. If you have one paste it now; otherwise press Enter to abort.\")\n",
        "    token = getpass(\"ngrok authtoken (paste only the token string, NOT commands): \").strip()\n",
        "    if not token:\n",
        "        raise SystemExit(\"No token provided. Provide a valid ngrok auth token and re-run.\")\n",
        "    conf.get_default().auth_token = token\n",
        "    try:\n",
        "        ngrok.set_auth_token(token)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Close any existing tunnels (cleanup)\n",
        "try:\n",
        "    for t in ngrok.get_tunnels():\n",
        "        try:\n",
        "            ngrok.disconnect(t.public_url)\n",
        "        except Exception:\n",
        "            pass\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Try to open tunnel\n",
        "print(\"Opening ngrok tunnel to 7860 ...\")\n",
        "try:\n",
        "    t = ngrok.connect(7860, \"http\")\n",
        "    print(\"NGROK PUBLIC URL ->\", t.public_url)\n",
        "except Exception as e:\n",
        "    print(\"Failed to open ngrok tunnel:\", repr(e))\n",
        "    # show pyngrok logs if available\n",
        "    log_path = \"/tmp/pyngrok.log\"\n",
        "    if os.path.exists(log_path):\n",
        "        print(\"--- pyngrok log tail ---\")\n",
        "        print(open(log_path,\"r\",encoding=\"utf8\",errors=\"ignore\").read().splitlines()[-40:])\n",
        "    raise\n",
        "\n",
        "# show tunnels list & quick local sanity curl\n",
        "print(\"\\npyngrok.get_tunnels():\", ngrok.get_tunnels())\n",
        "print(\"\\nQuick backend root check (server must be running in this Colab):\")\n",
        "import subprocess\n",
        "subprocess.run([\"bash\",\"-lc\", \"curl -sS --max-time 5 {}/ || echo 'local public root failed'\".format(t.public_url)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWsFvOicfid6",
        "outputId": "928d0e03-6aad-4f0a-b4e5-6a44aa0a2b41"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening ngrok tunnel to 7860 ...\n",
            "NGROK PUBLIC URL -> https://advertizable-interpenetratively-abbie.ngrok-free.dev\n",
            "\n",
            "pyngrok.get_tunnels(): [<NgrokTunnel: \"https://advertizable-interpenetratively-abbie.ngrok-free.dev\" -> \"http://localhost:7860\">]\n",
            "\n",
            "Quick backend root check (server must be running in this Colab):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['bash', '-lc', \"curl -sS --max-time 5 https://advertizable-interpenetratively-abbie.ngrok-free.dev/ || echo 'local public root failed'\"], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "NGROK=\"https://advertizable-interpenetratively-abbie.ngrok-free.dev\"\n",
        "FILE=\"/content/sample_from_upload.mp4\"\n",
        "\n",
        "echo \"Using sample:\" $FILE\n",
        "if [ ! -f \"$FILE\" ]; then\n",
        "  echo \"ERROR: sample missing: $FILE\"\n",
        "  exit 1\n",
        "fi\n",
        "\n",
        "echo \"Posting to $NGROK/api/generate ...\"\n",
        "curl -s -X POST \"$NGROK/api/generate\" \\\n",
        "  -F \"prompt=9:16 tiny mechanical fox exploring a sunlit garden, cinematic\" \\\n",
        "  -F \"mode=IMAGE\" \\\n",
        "  -F \"duration=4\" \\\n",
        "  -F \"file=@${FILE}\" \\\n",
        "  -o /tmp/generate_resp.json\n",
        "\n",
        "echo \"=== generate response ===\"\n",
        "cat /tmp/generate_resp.json\n",
        "echo\n",
        "echo \"If you got a jobId (e.g. {\\\"jobId\\\":\\\"job-abc123\\\"}), paste it here.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBSweFzFW_nU",
        "outputId": "7e37c036-f42c-495d-d53b-5463edc0da67"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sample: /content/sample_from_upload.mp4\n",
            "Posting to https://advertizable-interpenetratively-abbie.ngrok-free.dev/api/generate ...\n",
            "=== generate response ===\n",
            "{\"jobId\":\"job-19c6c1f1f2a8\"}\n",
            "\n",
            "If you got a jobId (e.g. {\"jobId\":\"job-abc123\"}), paste it here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, requests, os\n",
        "NGROK = \"https://advertizable-interpenetratively-abbie.ngrok-free.dev\"\n",
        "JOB_ID = \"job-19c6c1f1f2a8\"\n",
        "\n",
        "poll_url = f\"{NGROK}/api/job/{JOB_ID}\"\n",
        "print(\"Polling:\", poll_url)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        r = requests.get(poll_url, timeout=10)\n",
        "        data = r.json()\n",
        "        print(\"STATUS:\", data.get(\"status\"), \"| PROGRESS:\", data.get(\"progress\"))\n",
        "        print(\"LOGS:\", data.get(\"logs\")[-3:])\n",
        "\n",
        "        if data.get(\"status\") == \"done\":\n",
        "            print(\"\\nüéâ Job finished!\")\n",
        "            output_url = f\"{NGROK}{data['outputUrl']}\"\n",
        "            print(\"Output URL:\", output_url)\n",
        "            break\n",
        "\n",
        "        if data.get(\"status\") == \"error\":\n",
        "            print(\"\\n‚ùå Error in job:\", data)\n",
        "            break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Poll error:\", e)\n",
        "\n",
        "    time.sleep(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmRN63uYglNN",
        "outputId": "8e2df6f8-a517-4232-d56c-6ef7388614fe"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polling: https://advertizable-interpenetratively-abbie.ngrok-free.dev/api/job/job-19c6c1f1f2a8\n",
            "STATUS: done | PROGRESS: 100\n",
            "LOGS: ['Job queued', 'Job started', 'Used uploaded file as output']\n",
            "\n",
            "üéâ Job finished!\n",
            "Output URL: https://advertizable-interpenetratively-abbie.ngrok-free.dev/api/output/job-19c6c1f1f2a8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "OUTPUT_URL = \"https://advertizable-interpenetratively-abbie.ngrok-free.dev/api/output/job-19c6c1f1f2a8\"\n",
        "OUTPUT_FILE = \"/content/generated_output.mp4\"\n",
        "\n",
        "r = requests.get(OUTPUT_URL, stream=True)\n",
        "with open(OUTPUT_FILE, \"wb\") as f:\n",
        "    for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "\n",
        "print(\"Saved video to:\", OUTPUT_FILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHTWd2Bbgs80",
        "outputId": "8874a976-844f-4f1e-ead4-2729a468d55e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved video to: /content/generated_output.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python -m pip install -q flask-cors"
      ],
      "metadata": {
        "id": "T-YzbiLZh0H9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2 ‚Äî Add CORS support to backend\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "backend_path = Path(\"/content/klingai_flask_backend.py\")\n",
        "code = backend_path.read_text()\n",
        "\n",
        "# Insert CORS import\n",
        "code = code.replace(\n",
        "    \"from flask import Flask, request, jsonify, send_file, abort\",\n",
        "    \"from flask import Flask, request, jsonify, send_file, abort\\nfrom flask_cors import CORS\"\n",
        ")\n",
        "\n",
        "# Enable CORS after app = Flask(__name__)\n",
        "code = code.replace(\n",
        "    \"app = Flask(__name__)\",\n",
        "    \"app = Flask(__name__)\\nCORS(app)\"\n",
        ")\n",
        "\n",
        "backend_path.write_text(code)\n",
        "print(\"CORS added successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fZCX0ssloqp",
        "outputId": "04a23c73-84e6-45bb-ccd9-5f2483168cad"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORS added successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flask-cors\n"
      ],
      "metadata": {
        "id": "BnnqFd8a_VUh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\n",
        "!sudo apt-get install -y nodejs\n",
        "!node -v\n",
        "!npm -v\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEOEowzE9WnI",
        "outputId": "e4493bb6-16ba-4c45-9dcf-e0127cf6f614"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;79m2025-11-24 13:16:19 - Installing pre-requisites\u001b[0m\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://deb.nodesource.com/node_18.x nodistro InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "44 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.21).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.4).\n",
            "apt-transport-https is already the newest version (2.4.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Get:4 https://deb.nodesource.com/node_20.x nodistro InRelease [12.1 kB]\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:10 https://deb.nodesource.com/node_20.x nodistro/main amd64 Packages [12.9 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 25.1 kB in 2s (12.4 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "\u001b[1;34m2025-11-24 13:16:40 - Repository configured successfully.\u001b[0m\n",
            "\u001b[38;5;79m2025-11-24 13:16:40 - To install Node.js, run: apt install nodejs -y\u001b[0m\n",
            "\u001b[38;5;79m2025-11-24 13:16:40 - You can use N|solid Runtime as a node.js alternative\u001b[0m\n",
            "\u001b[1;32m2025-11-24 13:16:40 - To install N|solid Runtime, run: apt install nsolid -y \n",
            "\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following packages will be upgraded:\n",
            "  nodejs\n",
            "1 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 32.0 MB of archives.\n",
            "After this operation, 9,394 kB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_20.x nodistro/main amd64 nodejs amd64 20.19.5-1nodesource1 [32.0 MB]\n",
            "Fetched 32.0 MB in 1s (56.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 127034 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_20.19.5-1nodesource1_amd64.deb ...\n",
            "Detected old npm client, removing...\n",
            "Unpacking nodejs (20.19.5-1nodesource1) over (18.20.8-1nodesource1) ...\n",
            "Setting up nodejs (20.19.5-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "v20.19.5\n",
            "10.8.2\n",
            "\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP A ‚Äî install backend dependencies (CORRECT SYNTAX)\n",
        "\n",
        "!pip install -q flask flask-cors gTTS\n",
        "\n",
        "# ensure ffmpeg is installed\n",
        "!ffmpeg -version || (sudo apt-get update -y && sudo apt-get install -y ffmpeg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P734wOF98O4m",
        "outputId": "962e1ab4-e1a0-4aae-d777-ec00ed9d2d5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls -l \"/content/drive/MyDrive/AI-Automation\" | sed -n '1,200p'\n"
      ],
      "metadata": {
        "id": "QMPNulCMJrAF",
        "outputId": "9ad360ee-bd38-47e0-d18f-b6a1875f9c86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "total 248\n",
            "drwx------ 2 root root   4096 Nov 24 08:29 checkpoints\n",
            "-rw------- 1 root root     37 Nov 19 17:34 hf_token.txt\n",
            "-rw------- 1 root root  14164 Nov 24 13:26 kling_ai_react_ui.jsx\n",
            "drwx------ 2 root root   4096 Nov 24 08:29 outputs\n",
            "-rw------- 1 root root 229926 Nov 21 11:42 sample.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "UI_SRC=\"/content/drive/MyDrive/AI-Automation/kling_ai_react_ui.jsx\"\n",
        "APP_DIR=\"/content/kling-ui\"\n",
        "\n",
        "echo \"=== STEP 0: check UI file exists ===\"\n",
        "if [ ! -f \"${UI_SRC}\" ]; then\n",
        "  echo \"ERROR: UI file not found at ${UI_SRC}\"\n",
        "  echo \"Files in the folder:\"\n",
        "  ls -l \"$(dirname \"${UI_SRC}\")\"\n",
        "  exit 2\n",
        "fi\n",
        "echo \"Found UI file: ${UI_SRC}\"\n",
        "echo\n",
        "\n",
        "# 1) create React app if missing (idempotent)\n",
        "if [ ! -d \"${APP_DIR}\" ]; then\n",
        "  echo \"Creating React app (may take ~2min)...\"\n",
        "  npx create-react-app \"${APP_DIR}\"\n",
        "else\n",
        "  echo \"React app already exists at ${APP_DIR}\"\n",
        "fi\n",
        "\n",
        "# 2) ensure src exists & copy UI from Drive into src\n",
        "mkdir -p \"${APP_DIR}/src\"\n",
        "cp \"${UI_SRC}\" \"${APP_DIR}/src/KlingAIUI.jsx\"\n",
        "echo \"Copied UI -> ${APP_DIR}/src/KlingAIUI.jsx\"\n",
        "\n",
        "# 3) ensure App.js mounts KlingAIUI\n",
        "cat > \"${APP_DIR}/src/App.js\" <<'EOF'\n",
        "import React from \"react\";\n",
        "import KlingAIUI from \"./KlingAIUI\";\n",
        "export default function App(){ return <KlingAIUI />; }\n",
        "EOF\n",
        "echo \"Wrote App.js to mount KlingAIUI\"\n",
        "\n",
        "# 4) clean formatting (remove CRLF/BOM if present)\n",
        "sed -i 's/\\r$//' \"${APP_DIR}/src/KlingAIUI.jsx\" || true\n",
        "sed -i '1s/^\\xEF\\xBB\\xBF//' \"${APP_DIR}/src/KlingAIUI.jsx\" || true\n",
        "echo \"Cleaned JSX formatting\"\n",
        "\n",
        "# 5) install deps (non-fatal if already installed)\n",
        "cd \"${APP_DIR}\"\n",
        "npm install framer-motion lucide-react --legacy-peer-deps || true\n",
        "\n",
        "# 6) start dev server in background and show recent log\n",
        "pkill -f \"react-scripts start\" || true\n",
        "nohup npm start > /content/react_dev.log 2>&1 & echo $! > /content/react_dev.pid\n",
        "sleep 6\n",
        "echo \"---- /content/react_dev.log (tail) ----\"\n",
        "tail -n 80 /content/react_dev.log || true\n",
        "echo\n",
        "echo \"If you see 'Local: http://localhost:3000' then the dev server is running inside Colab.\"\n",
        "echo \"If not, paste the exact tail above here and I will fix the error.\"\n"
      ],
      "metadata": {
        "id": "0AxzRj7-KDpa",
        "outputId": "ca8c0f00-a049-43a1-8024-f02bd8073501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STEP 0: check UI file exists ===\n",
            "Found UI file: /content/drive/MyDrive/AI-Automation/kling_ai_react_ui.jsx\n",
            "\n",
            "React app already exists at /content/kling-ui\n",
            "Copied UI -> /content/kling-ui/src/KlingAIUI.jsx\n",
            "Wrote App.js to mount KlingAIUI\n",
            "Cleaned JSX formatting\n",
            "\n",
            "up to date, audited 1324 packages in 6s\n",
            "\n",
            "264 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "9 vulnerabilities (3 moderate, 6 high)\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "---- /content/react_dev.log (tail) ----\n",
            "\n",
            "> kling-ui@0.1.0 start\n",
            "> react-scripts start\n",
            "\n",
            "(node:23580) [DEP_WEBPACK_DEV_SERVER_ON_AFTER_SETUP_MIDDLEWARE] DeprecationWarning: 'onAfterSetupMiddleware' option is deprecated. Please use the 'setupMiddlewares' option.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "(node:23580) [DEP_WEBPACK_DEV_SERVER_ON_BEFORE_SETUP_MIDDLEWARE] DeprecationWarning: 'onBeforeSetupMiddleware' option is deprecated. Please use the 'setupMiddlewares' option.\n",
            "Starting the development server...\n",
            "\n",
            "\n",
            "If you see 'Local: http://localhost:3000' then the dev server is running inside Colab.\n",
            "If not, paste the exact tail above here and I will fix the error.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/kling-ui\n",
        "pkill -f \"react-scripts start\" || true\n",
        "nohup npm start > /content/react_dev.log 2>&1 & echo $! > /content/react_dev.pid\n",
        "sleep 4\n",
        "tail -n 80 /content/react_dev.log\n"
      ],
      "metadata": {
        "id": "i4TbYgODQ7Md",
        "outputId": "47e9551d-968a-4878-eb33-78b4f139048f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> kling-ui@0.1.0 start\n",
            "> react-scripts start\n",
            "\n",
            "Something is already running on port 3000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# 1) show what's using port 3000\n",
        "echo \"=== WHAT'S USING PORT 3000 ===\"\n",
        "ss -ltnp | grep ':3000' || echo \"No process listening on :3000\"\n",
        "\n",
        "echo\n",
        "echo \"=== LIST REACT/Node PROCS ===\"\n",
        "ps aux | egrep 'node|react-scripts' | egrep -v 'grep' || true\n",
        "echo\n",
        "\n",
        "# 2) Kill any existing CRA dev server\n",
        "echo \"Attempting pkill -f react-scripts...\"\n",
        "pkill -f \"react-scripts start\" || true\n",
        "\n",
        "# 3) Kill anything still occupying port 3000\n",
        "PIDS=$(ss -ltnp | grep ':3000' | sed -E 's/.*pid=([0-9]+),.*/\\1/' | tr '\\n' ' ')\n",
        "if [ -n \"$PIDS\" ]; then\n",
        "  echo \"Killing PIDs on :3000 -> $PIDS\"\n",
        "  kill -9 $PIDS || true\n",
        "else\n",
        "  echo \"No PIDs found for :3000\"\n",
        "fi\n",
        "\n",
        "sleep 1\n",
        "\n",
        "# 4) confirm port is free\n",
        "echo\n",
        "echo \"=== VERIFY PORT 3000 FREED ===\"\n",
        "ss -ltnp | grep ':3000' || echo \"Port 3000 is free\"\n",
        "\n",
        "# 5) restart dev server\n",
        "cd /content/kling-ui || { echo \"ERROR: /content/kling-ui not found\"; exit 1; }\n",
        "\n",
        "echo \"Starting React dev server (background). Log -> /content/react_dev.log\"\n",
        "\n",
        "nohup bash -lc \"PORT=3000 npm start\" > /content/react_dev.log 2>&1 & echo $! > /content/react_dev.pid\n",
        "\n",
        "sleep 4\n",
        "\n",
        "echo\n",
        "echo \"=== react_dev.log (tail) ===\"\n",
        "tail -n 60 /content/react_dev.log || true\n"
      ],
      "metadata": {
        "id": "V948YVRTSndd",
        "outputId": "224adb17-5c9f-435a-baaf-c87f8a10e3ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== WHAT'S USING PORT 3000 ===\n",
            "LISTEN 0      511          0.0.0.0:3000       0.0.0.0:*    users:((\"node\",pid=23580,fd=18))       \n",
            "\n",
            "=== LIST REACT/Node PROCS ===\n",
            "root           7  0.0  0.5 1298336 67384 ?       Sl   12:56   0:05 /tools/node/bin/node /datalab/web/app.js\n",
            "root       11968  0.0  0.1 1275476 21448 ?       Sl   13:25   0:01 /usr/colab/bin/language_service --lsp_search_dirs=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages --language_services_request_root_url=http://172.28.0.1:8013/ --language_services_request_timeout=30s -- node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:62d097b2e53ab6c7ace155bd1e6fd91a403f339c09\n",
            "root       11975  1.7  2.1 1774516 280356 ?      Sl   13:25   1:22 node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:62d097b2e53ab6c7ace155bd1e6fd91a403f339c09\n",
            "root       23580  3.6  3.0 43575180 410768 ?     Sl   14:12   1:03 /usr/bin/node /content/kling-ui/node_modules/react-scripts/scripts/start.js\n",
            "\n",
            "Attempting pkill -f react-scripts...\n",
            "Killing PIDs on :3000 -> 23580 \n",
            "\n",
            "=== VERIFY PORT 3000 FREED ===\n",
            "Port 3000 is free\n",
            "Starting React dev server (background). Log -> /content/react_dev.log\n",
            "\n",
            "=== react_dev.log (tail) ===\n",
            "\n",
            "> kling-ui@0.1.0 start\n",
            "> react-scripts start\n",
            "\n",
            "(node:30837) [DEP_WEBPACK_DEV_SERVER_ON_AFTER_SETUP_MIDDLEWARE] DeprecationWarning: 'onAfterSetupMiddleware' option is deprecated. Please use the 'setupMiddlewares' option.\n",
            "(Use `node --trace-deprecation ...` to show where the warning was created)\n",
            "(node:30837) [DEP_WEBPACK_DEV_SERVER_ON_BEFORE_SETUP_MIDDLEWARE] DeprecationWarning: 'onBeforeSetupMiddleware' option is deprecated. Please use the 'setupMiddlewares' option.\n",
            "Starting the development server...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sS --max-time 5 https://advertizable-interpenetratively-abbie.ngrok-free.dev/ || echo \"root failed\"\n"
      ],
      "metadata": {
        "id": "OL6rDfy4dt9H",
        "outputId": "3db6b8ec-14b8-4e6f-8bc9-c5c8d5f2b23a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n",
            "  <head>\n",
            "    <meta charset=\"utf-8\">\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <link rel=\"preload\" href=\"https://assets.ngrok.com/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n",
            "    <meta name=\"author\" content=\"ngrok\">\n",
            "    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n",
            "    <link href=\"https://ngrok.com/assets/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
            "    <meta name=\"robots\" content=\"noindex, nofollow\">\n",
            "    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n",
            "    <noscript>The endpoint advertizable-interpenetratively-abbie.ngrok-free.dev is offline. (ERR_NGROK_3200)</noscript>\n",
            "    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n",
            "  </head>\n",
            "  <body class=\"h-full\" id=\"ngrok\">\n",
            "    <div id=\"root\" data-payload=\"eyJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiIzMjAwIiwibWVzc2FnZSI6IlRoZSBlbmRwb2ludCBhZHZlcnRpemFibGUtaW50ZXJwZW5ldHJhdGl2ZWx5LWFiYmllLm5ncm9rLWZyZWUuZGV2IGlzIG9mZmxpbmUuIiwidGl0bGUiOiJOb3QgRm91bmQifQ==\"></div>\n",
            "  </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k_PXSw7ZdyPk",
        "outputId": "b6a2b4c5-6492-4a55-b34c-db78455d0992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posting file -> https://advertizable-interpenetratively-abbie.ngrok-free.dev/api/generate\n",
            "=== generate response ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "cat: /tmp/generate_resp.json: No such file or directory\n"
          ]
        }
      ]
    }
  ]
}