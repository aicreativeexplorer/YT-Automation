{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6FkMJMmF0Yqp0XvKozZ7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicreativeexplorer/YT-Automation/blob/main/YT_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiafjBDXAm5J",
        "outputId": "2186753e-02c8-4697-f2e4-631f396fd2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG OK\n"
          ]
        }
      ],
      "source": [
        "# CONFIG — edit only if you moved paths\n",
        "REPO_DIR = \"/content/YT-Automation\"\n",
        "NOTEBOOK_NAME = \"YT-Automation.ipynb\"\n",
        "UPLOADED_VIDEO = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"  # your uploaded demo\n",
        "DRIVE_TOKEN_PATH = \"/content/drive/MyDrive/AI-Automation/hf_token.txt\"  # put HF token here\n",
        "OUTPUT_DRIVE_FOLDER = \"/content/drive/MyDrive/AI-Automation/outputs/stitched\"\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/AI-Automation/checkpoints\"\n",
        "SVD_VERSION = \"svd\"  # 'svd' (open) or 'svd-xt-1-1' (better but gated)\n",
        "USE_AUTO_PUSH = False  # no auto-push by default\n",
        "print(\"CONFIG OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Auto-login to HuggingFace if token present in Drive\n",
        "import os\n",
        "if os.path.exists(DRIVE_TOKEN_PATH):\n",
        "    from huggingface_hub import login\n",
        "    with open(DRIVE_TOKEN_PATH,'r') as f:\n",
        "        token = f.read().strip()\n",
        "    login(token=token)\n",
        "    print(\"Logged into HuggingFace from Drive token.\")\n",
        "else:\n",
        "    print(\"No HF token at\", DRIVE_TOKEN_PATH, \"- you'll be asked if downloading gated models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg2ZtRuIFxet",
        "outputId": "ab57e7e3-fb25-4991-cb0d-6a5c1780c8b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Logged into HuggingFace from Drive token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# minimal set used by pipeline\n",
        "pip install -q kornia open_clip_torch timm transformers safetensors accelerate pytorch-lightning einops imageio-ffmpeg imwatermark opencv-python-headless==4.6.0.66 gradio==3.34.0\n",
        "# RIFE + Real-ESRGAN notebooks will install their deps inside their cells when needed.\n",
        "echo \"installed deps\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMkH4koVGfWG",
        "outputId": "b05c8b07-3825-4dc3-a72e-215c33aa3888"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installed deps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# clone once per session\n",
        "if [ ! -d /content/generative-models ]; then\n",
        "  git clone https://github.com/Stability-AI/generative-models.git /content/generative-models\n",
        "fi\n",
        "# small helper scripts (won't break if run multiple times)\n",
        "mkdir -p /content/scripts\n",
        "cat > /content/scripts/ffmpeg_stitch.sh <<'SH'\n",
        "#!/usr/bin/env bash\n",
        "# Usage: ./ffmpeg_stitch.sh out.mp4 file1.mp4 file2.mp4 ...\n",
        "out=\"$1\"; shift\n",
        "# convert to ts and concat\n",
        "tsfiles=\"\"\n",
        "for f in \"$@\"; do\n",
        "  ts=\"/tmp/$(basename \"$f\").ts\"\n",
        "  ffmpeg -y -i \"$f\" -c copy -bsf:v h264_mp4toannexb -f mpegts \"$ts\"\n",
        "  tsfiles=\"${tsfiles}|${ts}\"\n",
        "done\n",
        "tsfiles=${tsfiles#|}\n",
        "ffmpeg -y -i \"concat:${tsfiles}\" -c copy -bsf:a aac_adtstoasc \"$out\"\n",
        "SH\n",
        "chmod +x /content/scripts/ffmpeg_stitch.sh\n",
        "echo \"cloned generative-models; helper scripts in /content/scripts\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WUgqUqpGi59",
        "outputId": "ce12c585-cf8f-44b4-d963-35f6b969ca99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloned generative-models; helper scripts in /content/scripts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/content/generative-models'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, uuid, json, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "def run_cmd(cmd, quiet=False):\n",
        "    print(\"RUN:\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if not quiet:\n",
        "        print(p.stdout)\n",
        "        if p.stderr:\n",
        "            print(\"ERR:\", p.stderr[:1000])\n",
        "    return p\n",
        "\n",
        "def ensure_folder(p):\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "ensure_folder(OUTPUT_DRIVE_FOLDER)\n",
        "ensure_folder(CHECKPOINT_DIR)\n",
        "\n",
        "# ---- SVD: wrapper (placeholder) ----\n",
        "def generate_svd_from_text(prompt, seed=None, num_frames=14, out_prefix=\"svd\"):\n",
        "    \"\"\"\n",
        "    Minimal wrapper to call SVD sampling. The heavy work is in the SVD notebook code.\n",
        "    Here we assume `sample()` exists in session OR we call a local script.\n",
        "    For now this function writes a JSON config file for the manual SVD notebook to pick up.\n",
        "    \"\"\"\n",
        "    jobid = f\"{out_prefix}_{int(time.time())}_{uuid.uuid4().hex[:6]}\"\n",
        "    jobdir = f\"/tmp/{jobid}\"\n",
        "    ensure_folder(jobdir)\n",
        "    cfg = {\n",
        "        \"prompt\": prompt,\n",
        "        \"seed\": seed or \"random\",\n",
        "        \"num_frames\": num_frames,\n",
        "        \"out\": f\"{jobdir}/{jobid}.mp4\"\n",
        "    }\n",
        "    cfg_path = f\"{jobdir}/cfg.json\"\n",
        "    with open(cfg_path,'w') as f: json.dump(cfg,f)\n",
        "    print(\"SVD job written:\", cfg_path)\n",
        "    # NOTE: actual execution will be in the notebook cell that imports the SVD sampling code\n",
        "    return cfg[\"out\"], jobdir\n",
        "\n",
        "# ---- RIFE: interpolation wrapper ----\n",
        "def interpolate_with_rife(infile, factor=4):\n",
        "    out = f\"{Path(infile).with_suffix('')}_rife.mp4\"\n",
        "    # Call public RIFE Colab? For now we use a simple ffmpeg fps trick as placeholder\n",
        "    run_cmd(f\"ffmpeg -y -i '{infile}' -filter:v 'minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1' -c:v libx264 -crf 18 '{out}'\")\n",
        "    return out\n",
        "\n",
        "# ---- Real-ESRGAN: upscale wrapper (placeholder) ----\n",
        "def upscale_realesrgan(infile, scale=2):\n",
        "    out = f\"{Path(infile).with_suffix('')}_up.mp4\"\n",
        "    # placeholder: re-encode at higher resolution (actual Real-ESRGAN model would process frames)\n",
        "    run_cmd(f\"ffmpeg -y -i '{infile}' -vf scale=iw*{scale}:ih*{scale} -c:v libx264 -crf 18 '{out}'\")\n",
        "    return out\n",
        "\n",
        "# ---- Stitch helper ----\n",
        "def stitch_files(inputs, out):\n",
        "    inputs = [str(i) for i in inputs]\n",
        "    run_cmd(f\"/content/scripts/ffmpeg_stitch.sh '{out}' \" + \" \".join([f\"'{i}'\" for i in inputs]))\n",
        "    return out\n",
        "\n",
        "# ---- TTS helper (ElevenLabs fallback) ----\n",
        "def tts_generate(text, outfile=\"/tmp/tts.wav\", provider=\"free\"):\n",
        "    \"\"\"\n",
        "    provider: 'elevenlabs' (needs key), 'gtts' (free).\n",
        "    This is a simple wrapper: I recommend hooking to ElevenLabs for quality or use gTTS for free.\n",
        "    \"\"\"\n",
        "    if provider==\"gtts\":\n",
        "        # install gTTS if needed\n",
        "        run_cmd(\"python -m pip install -q gTTS pydub\")\n",
        "        from gtts import gTTS\n",
        "        tts = gTTS(text=text, lang='en')\n",
        "        tts.save(outfile)\n",
        "        return outfile\n",
        "    else:\n",
        "        # try gTTS as default\n",
        "        run_cmd(\"python -m pip install -q gTTS pydub\")\n",
        "        from gtts import gTTS\n",
        "        tts = gTTS(text=text, lang='en')\n",
        "        tts.save(outfile)\n",
        "        return outfile\n",
        "\n",
        "# ---- Caption burn-in (ffmpeg) ----\n",
        "def burn_captions(video_in, text, out):\n",
        "    # naive single-line centered caption\n",
        "    cmd = (\n",
        "        f'ffmpeg -y -i \"{video_in}\" -vf '\n",
        "        f\"\\\"drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf: text='{text}':\"\n",
        "        \"fontcolor=white:fontsize=48:box=1:boxcolor=0x00000099:boxborderw=5:x=(w-text_w)/2:y=h-150\\\" \"\n",
        "        f'-c:a copy \"{out}\"'\n",
        "    )\n",
        "    run_cmd(cmd)\n",
        "    return out\n",
        "\n",
        "print(\"Helpers loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs0SlVlgGmJQ",
        "outputId": "1b75c037-743c-4163-ec56-08475f0318fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helpers loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEXT-ONLY MODE — create config and call SVD job (sample wrapper)\n",
        "prompt = \"9:16 vertical, ultra-detailed close-up of a tiny mechanical fox exploring a sunlit garden, cinematic shallow depth-of-field, warm color grade, soft motion. No text or logos.\"\n",
        "out_mp4, jobdir = generate_svd_from_text(prompt, seed=1234, num_frames=25, out_prefix=\"tinyfox\")\n",
        "print(\"SVD job created. Local jobdir:\", jobdir)\n",
        "print(\"Once SVD sampling cell runs, output will be:\", out_mp4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU3GNFpAGsiY",
        "outputId": "7973b1d9-59a3-45b3-9968-bb636f961b02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD job written: /tmp/tinyfox_1763639622_3c71ba/cfg.json\n",
            "SVD job created. Local jobdir: /tmp/tinyfox_1763639622_3c71ba\n",
            "Once SVD sampling cell runs, output will be: /tmp/tinyfox_1763639622_3c71ba/tinyfox_1763639622_3c71ba.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "RylNAMd2xiS6",
        "outputId": "64949e6c-d567-4455-bd7f-cfe49ba8e5ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0bce210-bd16-4784-86de-8ced9ff07b65\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0bce210-bd16-4784-86de-8ced9ff07b65\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Kling AI- Next-Gen AI Video & AI Image Generator.mp4 to Kling AI- Next-Gen AI Video & AI Image Generator.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1Alez_Ux_4s",
        "outputId": "0402b766-72a1-4bb4-df7c-61b383b9d9ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'Kling AI- Next-Gen AI Video & AI Image Generator.mp4',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE-TO-VIDEO MODE\n",
        "# Use your uploaded file to extract a conditioning frame (change timestamp if you want)\n",
        "import os\n",
        "frame_path = \"/content/frame_for_svd.png\"\n",
        "run_cmd(f\"ffmpeg -y -ss 00:00:01 -i '{UPLOADED_VIDEO}' -frames:v 1 '{frame_path}'\")\n",
        "print(\"Extracted frame:\", frame_path)\n",
        "\n",
        "# Now create SVD job that uses this image\n",
        "prompt_image = \"9:16 vertical, mechanical fox exploring, use this frame as a style reference. No text.\"\n",
        "out_mp4_img, jobdir_img = generate_svd_from_text(prompt_image, seed=999, num_frames=25, out_prefix=\"img2vid\")\n",
        "# attach the frame info to jobdir so the sampling cell can pick it\n",
        "open(f\"{jobdir_img}/cond_frame.txt\",\"w\").write(frame_path)\n",
        "print(\"Image->video job created at\", jobdir_img, \"expected out:\", out_mp4_img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y_8wn01Gtgy",
        "outputId": "6b7cfb68-7dd3-48b6-813d-b56bfb5b7321"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN: ffmpeg -y -ss 00:00:01 -i '/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4' -frames:v 1 '/content/frame_for_svd.png'\n",
            "\n",
            "ERR: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enab\n",
            "Extracted frame: /content/frame_for_svd.png\n",
            "SVD job written: /tmp/img2vid_1763639623_8339dd/cfg.json\n",
            "Image->video job created at /tmp/img2vid_1763639623_8339dd expected out: /tmp/img2vid_1763639623_8339dd/img2vid_1763639623_8339dd.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-dejavu-core\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksm7tOZFQouV",
        "outputId": "4ae08987-004a-4b5c-a320-59031f0ec771"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 1,041 kB of archives.\n",
            "After this operation, 3,025 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Fetched 1,041 kB in 0s (4,691 kB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVD sampling runner (paste into a cell and run after you confirm model & weights)\n",
        "# ONE-CELL: Robust fix for \"No SVD job config found in /tmp\"\n",
        "# - creates a /tmp/svd_* job with cfg.json if none exists\n",
        "# - tries to call sample() if available; otherwise produces simulated mp4\n",
        "# - safe, idempotent, prints everything you need\n",
        "import os, json, time, uuid, subprocess\n",
        "from pathlib import Path\n",
        "from shlex import quote\n",
        "\n",
        "# ---------- USER / ENV SETTINGS ----------\n",
        "# Use your uploaded file path (developer-provided)\n",
        "UPLOADED_FILE = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "# default prompt (edit inline if you want different)\n",
        "DEFAULT_PROMPT = (\n",
        "    \"9:16 vertical, ultra-detailed close-up of a tiny mechanical fox exploring a sunlit garden, \"\n",
        "    \"cinematic shallow depth-of-field, warm color grade, subtle camera push-in, photorealistic textures, no text or logos.\"\n",
        ")\n",
        "\n",
        "DEFAULT_SEED = 1234\n",
        "DEFAULT_NUM_FRAMES = 25\n",
        "\n",
        "# Where SVD checkpoints are expected (adjust if you use Drive)\n",
        "if \"CHECKPOINT_DIR\" not in globals():\n",
        "    CHECKPOINT_DIR = \"/content/checkpoints\"\n",
        "\n",
        "if \"SVD_VERSION\" not in globals():\n",
        "    # keep as 'svd' if you only have open weights; use 'svd-xt-1-1' only if you have access\n",
        "    SVD_VERSION = \"svd-xt-1-1\"\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run_cmd(cmd, fail_ok=False):\n",
        "    print(\"RUN:\", cmd)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if p.stdout:\n",
        "        print(p.stdout.strip())\n",
        "    if p.stderr:\n",
        "        # only show trimmed error to avoid spamming\n",
        "        print(\"ERR:\", p.stderr.strip()[:1000])\n",
        "    if p.returncode != 0 and not fail_ok:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\\nstderr: {p.stderr}\")\n",
        "    return p\n",
        "\n",
        "def find_latest_jobcfg(tmpdir=\"/tmp\"):\n",
        "    p = Path(tmpdir)\n",
        "    candidates = sorted(p.glob(\"svd_*\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "    for d in candidates:\n",
        "        cfg = d / \"cfg.json\"\n",
        "        if cfg.exists():\n",
        "            return str(cfg)\n",
        "    return None\n",
        "\n",
        "# ---------- main logic ----------\n",
        "print(\"Looking for existing SVD job cfg in /tmp ...\")\n",
        "job_cfg = find_latest_jobcfg(\"/tmp\")\n",
        "\n",
        "if job_cfg:\n",
        "    print(\"Found job config:\", job_cfg)\n",
        "else:\n",
        "    # create a new job folder and cfg\n",
        "    jobid = f\"svd_job_{int(time.time())}_{uuid.uuid4().hex[:6]}\"\n",
        "    jobdir = Path(\"/tmp\") / jobid\n",
        "    jobdir.mkdir(parents=True, exist_ok=True)\n",
        "    out_mp4 = str(jobdir / f\"{jobid}.mp4\")\n",
        "    cfg = {\n",
        "        \"prompt\": DEFAULT_PROMPT,\n",
        "        \"seed\": DEFAULT_SEED,\n",
        "        \"num_frames\": DEFAULT_NUM_FRAMES,\n",
        "        \"out\": out_mp4,\n",
        "        \"conditioning_image\": UPLOADED_FILE  # if you want image->video\n",
        "    }\n",
        "    cfg_path = jobdir / \"cfg.json\"\n",
        "    with open(cfg_path, \"w\", encoding=\"utf8\") as f:\n",
        "        json.dump(cfg, f, indent=2)\n",
        "    job_cfg = str(cfg_path)\n",
        "    print(\"WROTE new SVD job config to:\", job_cfg)\n",
        "    print(\"EXPECTED OUTPUT ->\", out_mp4)\n",
        "    # create a short simulated MP4 so downstream pipeline can run\n",
        "    print(\"Creating simulated sample MP4 (2s) — so RIFE/upscale/test can run immediately...\")\n",
        "    # safe ffmpeg drawtext value (escape single quotes)\n",
        "    txt = cfg[\"prompt\"][:80].replace(\"'\", \"\")\n",
        "    ffmpeg_cmd = (\n",
        "        f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 \"\n",
        "        f\"-t 2 -vf drawtext=text='{txt}':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "        f\"'{out_mp4}'\"\n",
        "    )\n",
        "    res = subprocess.run(ffmpeg_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    if res.returncode == 0:\n",
        "        print(\"✅ Simulated SVD output created at:\", out_mp4)\n",
        "    else:\n",
        "        print(\"⚠️ ffmpeg failed to create simulated output. stderr:\")\n",
        "        print(res.stderr[:2000])\n",
        "        raise RuntimeError(\"ffmpeg simulation failed; check ffmpeg availability.\")\n",
        "\n",
        "# ---------- try to run real sample() if available ----------\n",
        "# Many SVD notebooks expose a `sample()` function in session. We'll attempt to call it safely.\n",
        "# If sample() isn't available or call fails, we keep the simulated mp4 created above.\n",
        "sample_called = False\n",
        "if 'sample' in globals() and callable(globals()['sample']):\n",
        "    print(\"Detected sample() in session — attempting to call sample() with job config.\")\n",
        "    try:\n",
        "        # attempt a generic call signature. This may need adaptation depending on the notebook's sample() signature.\n",
        "        # We'll read the cfg and try common kwargs. Wrap in try/except to avoid killing the cell on mismatch.\n",
        "        cfg = json.load(open(job_cfg, 'r', encoding='utf8'))\n",
        "        # Common safe arguments — you might need to adapt these for your sample()\n",
        "        kwargs = dict(\n",
        "            input_path=cfg.get(\"conditioning_image\", \"\"),\n",
        "            resize_image=True,\n",
        "            num_frames=cfg.get(\"num_frames\", 14),\n",
        "            num_steps=30,\n",
        "            seed=cfg.get(\"seed\", \"random\"),\n",
        "            decoding_t=2,\n",
        "            fps_id=6,\n",
        "            motion_bucket_id=127,\n",
        "            cond_aug=0.02,\n",
        "            device='cuda' if (torch.cuda.is_available() if 'torch' in globals() else False) else 'cpu',\n",
        "            skip_filter=True\n",
        "        )\n",
        "        print(\"Calling sample(...) with kwargs (trimmed):\", {k: kwargs[k] for k in ['num_frames','seed','device']})\n",
        "        out_paths = globals()['sample'](**kwargs)\n",
        "        print(\"sample() returned:\", out_paths)\n",
        "        sample_called = True\n",
        "    except Exception as e:\n",
        "        print(\"sample() call failed (ok) — will use simulated output. Error:\", repr(e))\n",
        "\n",
        "else:\n",
        "    print(\"No sample() found in session — simulated output will be used for now.\")\n",
        "\n",
        "# ---------- final reporting ----------\n",
        "print(\"\\n--- SUMMARY ---\")\n",
        "print(\"job_cfg used:\", job_cfg)\n",
        "cfg_obj = json.load(open(job_cfg, 'r', encoding='utf8'))\n",
        "print(\"cfg['out'] ->\", cfg_obj.get(\"out\"))\n",
        "if sample_called:\n",
        "    print(\"Real sample() executed. Check returned outputs above.\")\n",
        "else:\n",
        "    print(\"No real sample() executed. Simulated mp4 exists at cfg['out'] and downstream steps can proceed.\")\n",
        "print(\"If you want me to replace the simulation with an exact sample() call for your generative-models fork, say: 'Plug real sample()' and paste the notebook sampling function cell or give me the exact repo/branch you used.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "1vNAwjlHGvKB",
        "outputId": "b8636906-c830-4e20-f9cf-8a76adf8417f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for existing SVD job cfg in /tmp ...\n",
            "WROTE new SVD job config to: /tmp/svd_job_1763656828_6aa160/cfg.json\n",
            "EXPECTED OUTPUT -> /tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4\n",
            "Creating simulated sample MP4 (2s) — so RIFE/upscale/test can run immediately...\n",
            "⚠️ ffmpeg failed to create simulated output. stderr:\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, lavfi, from 'color=size=720x1280:rate=6:color=0x101018':\n",
            "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
            "  Stream #0:0: Video: rawvideo (I420 / 0x30323449), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 6 tbr, 6 tbn, 6 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (rawvideo (native) -> h264 (l\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ffmpeg simulation failed; check ffmpeg availability.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3105775276.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"⚠️ ffmpeg failed to create simulated output. stderr:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ffmpeg simulation failed; check ffmpeg availability.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# ---------- try to run real sample() if available ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ffmpeg simulation failed; check ffmpeg availability."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced, robust MP4 repair + interpolation cell (Colab-ready)\n",
        "# Paste and run in a fresh Colab Python cell.\n",
        "\n",
        "import os, subprocess, sys, shutil, time, uuid\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- Config (edit only if you know what you're doing) ----------\n",
        "# fallback user-uploaded file (from your session)\n",
        "UPLOADED_SAMPLE = \"/mnt/data/Kling AI- Next-Gen AI Video & AI Image Generator.mp4\"\n",
        "\n",
        "# output folder for processed files\n",
        "OUT_DIR = Path(\"/tmp/processed_svd_outputs\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def run(cmd, capture=True):\n",
        "    \"\"\"Run shell command; return (rc, stdout, stderr).\"\"\"\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    return p.returncode, p.stdout or \"\", p.stderr or \"\"\n",
        "\n",
        "def safe_print_head(tag, txt, n=800):\n",
        "    print(f\"\\n[{tag}]\")\n",
        "    if not txt:\n",
        "        print(\" <empty>\")\n",
        "    else:\n",
        "        print(txt[:n] + (\"...\\n\" if len(txt) > n else \"\\n\"))\n",
        "\n",
        "# ensure fonts for drawtext exist (silently ignore errors)\n",
        "print(\"Ensuring fonts available for ffmpeg drawtext...\")\n",
        "rc, out, err = run(\"fc-list : file | grep -i dejavu || true\")\n",
        "if not out:\n",
        "    _ = run(\"apt-get update -qq && apt-get install -y -qq fonts-dejavu-core || true\")\n",
        "    rc, out, err = run(\"fc-list : file | grep -i dejavu || true\")\n",
        "print(\"Fonts check done.\")\n",
        "\n",
        "# ---------- find candidate input mp4 ----------\n",
        "print(\"\\nSearching for candidate SVD outputs in /tmp ...\")\n",
        "candidates = sorted(Path(\"/tmp\").glob(\"svd_*/*.mp4\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "input_path = None\n",
        "if candidates:\n",
        "    input_path = candidates[0]\n",
        "    print(\"Found candidate:\", str(input_path))\n",
        "else:\n",
        "    # fallback to the known uploaded sample file\n",
        "    if Path(UPLOADED_SAMPLE).exists():\n",
        "        print(\"No /tmp svd outputs found. Falling back to uploaded sample:\", UPLOADED_SAMPLE)\n",
        "        # copy it into a job-like location so downstream code expects /tmp/svd_*/file.mp4\n",
        "        jobdir = Path(\"/tmp/svd_fallback_\" + uuid.uuid4().hex[:6])\n",
        "        jobdir.mkdir(parents=True, exist_ok=True)\n",
        "        input_path = jobdir / \"fallback_input.mp4\"\n",
        "        shutil.copy2(UPLOADED_SAMPLE, input_path)\n",
        "        print(\"Copied uploaded sample to:\", str(input_path))\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No SVD outputs found in /tmp and uploaded sample missing at: \" + UPLOADED_SAMPLE)\n",
        "\n",
        "# convert to Path object\n",
        "input_path = Path(input_path)\n",
        "print(\"Using input:\", input_path)\n",
        "\n",
        "# ---------- validate file size ----------\n",
        "min_size_bytes = 1024  # tiny threshold\n",
        "if not input_path.exists() or input_path.stat().st_size < min_size_bytes:\n",
        "    print(\"Input missing or too small; creating a valid placeholder video at the input path.\")\n",
        "    # create placeholder valid mp4 with faststart\n",
        "    placeholder_cmd = (\n",
        "        f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 -t 2 \"\n",
        "        f\"-vf drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='SIMULATED SVD':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "        f\"-c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{input_path}'\"\n",
        "    )\n",
        "    rc, out, err = run(placeholder_cmd)\n",
        "    safe_print_head(\"ffmpeg-create-placeholder-stdout\", out)\n",
        "    safe_print_head(\"ffmpeg-create-placeholder-stderr\", err)\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(\"Failed to create placeholder mp4. See stderr above.\")\n",
        "\n",
        "# ---------- probe input with ffprobe ----------\n",
        "print(\"\\nProbing input with ffprobe...\")\n",
        "rc, out, err = run(f\"ffprobe -v error -show_format -show_streams '{input_path}'\")\n",
        "safe_print_head(\"ffprobe\", out + err, 1200)\n",
        "# detect 'moov' related errors heuristically\n",
        "if (\"moov\" in err.lower()) or (\"invalid data found\" in err.lower()) or rc != 0:\n",
        "    print(\"Detected container issues (moov/invalid). Attempting to remux/recreate clean mp4 with -movflags +faststart.\")\n",
        "    fixed = input_path.with_suffix(\".fixed.mp4\")\n",
        "    remux_cmd = f\"ffmpeg -y -i '{input_path}' -c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{fixed}'\"\n",
        "    rc, out, err = run(remux_cmd)\n",
        "    safe_print_head(\"ffmpeg-remux-stdout\", out)\n",
        "    safe_print_head(\"ffmpeg-remux-stderr\", err)\n",
        "    if rc == 0 and fixed.exists():\n",
        "        # replace original safely (keep backup)\n",
        "        backup = input_path.with_suffix(\".bak.mp4\")\n",
        "        shutil.move(str(input_path), str(backup))\n",
        "        shutil.move(str(fixed), str(input_path))\n",
        "        print(\"Remux successful. Replaced input with fixed file. Backup at\", str(backup))\n",
        "    else:\n",
        "        print(\"Remux failed. We'll attempt to recreate a clean placeholder input instead.\")\n",
        "        recreate_cmd = (\n",
        "            f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x101018 -t 2 \"\n",
        "            f\"-vf drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='SIM RECREATE':fontsize=28:fontcolor=white:x=20:y=40 \"\n",
        "            f\"-c:v libx264 -pix_fmt yuv420p -crf 18 -preset veryfast -movflags +faststart '{input_path}'\"\n",
        "        )\n",
        "        rc, out, err = run(recreate_cmd)\n",
        "        safe_print_head(\"ffmpeg-recreate-stderr\", err)\n",
        "        if rc != 0:\n",
        "            raise RuntimeError(\"Failed to remux or recreate a valid input mp4. Stderr above.\")\n",
        "\n",
        "# ---------- check ffmpeg supports minterpolate ----------\n",
        "print(\"\\nChecking ffmpeg filters for 'minterpolate' support...\")\n",
        "rc, out, err = run(\"ffmpeg -hide_banner -filters\")\n",
        "supports_minterp = \"minterpolate\" in out\n",
        "print(\"minterpolate supported?\" , supports_minterp)\n",
        "\n",
        "# ---------- attempt interpolation (minterpolate) with fallback to fps re-encode ----------\n",
        "base_name = input_path.stem\n",
        "rife_out = OUT_DIR / f\"{base_name}_rife.mp4\"\n",
        "fps_out = OUT_DIR / f\"{base_name}_fps30.mp4\"\n",
        "\n",
        "if supports_minterp:\n",
        "    print(\"Running minterpolate interpolation (this may be slow)...\")\n",
        "    # use quotes carefully\n",
        "    cmd_minterp = (\n",
        "        f\"ffmpeg -y -i '{input_path}' -filter:v \\\"minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\\\" \"\n",
        "        f\"-c:v libx264 -pix_fmt yuv420p -crf 18 '{rife_out}'\"\n",
        "    )\n",
        "    rc, out, err = run(cmd_minterp, )\n",
        "    safe_print_head(\"minterpolate-stdout\", out)\n",
        "    safe_print_head(\"minterpolate-stderr\", err, 4000)\n",
        "    if rc == 0 and rife_out.exists():\n",
        "        final_out = rife_out\n",
        "        print(\"minterpolate succeeded ->\", str(final_out))\n",
        "    else:\n",
        "        print(\"minterpolate failed — falling back to fps re-encode.\")\n",
        "        rc, out, err = run(f\"ffmpeg -y -i '{input_path}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{fps_out}'\")\n",
        "        safe_print_head(\"fps-stdout\", out)\n",
        "        safe_print_head(\"fps-stderr\", err)\n",
        "        if rc == 0 and fps_out.exists():\n",
        "            final_out = fps_out\n",
        "        else:\n",
        "            raise RuntimeError(\"Both minterpolate and fps fallback failed. See stderr above.\")\n",
        "else:\n",
        "    print(\"minterpolate not supported in this ffmpeg build — using fps re-encode fallback (safe).\")\n",
        "    rc, out, err = run(f\"ffmpeg -y -i '{input_path}' -vf fps=30 -c:v libx264 -pix_fmt yuv420p -crf 18 '{fps_out}'\")\n",
        "    safe_print_head(\"fps-stdout\", out)\n",
        "    safe_print_head(\"fps-stderr\", err)\n",
        "    if rc == 0 and fps_out.exists():\n",
        "        final_out = fps_out\n",
        "    else:\n",
        "        raise RuntimeError(\"fps re-encode fallback failed. See stderr above.\")\n",
        "\n",
        "# ---------- final report ----------\n",
        "print(\"\\n--- DONE ---\")\n",
        "print(\"Input used:\", str(input_path))\n",
        "print(\"Final interpolation output:\", str(final_out))\n",
        "print(\"Filesize (bytes):\", final_out.stat().st_size if final_out.exists() else \"MISSING\")\n",
        "print(\"You can now use this file for RIFE/upscale/stitch steps.\")\n",
        "\n",
        "# show quick ls of output dir\n",
        "print(\"\\nOUT_DIR listing:\")\n",
        "for p in sorted(OUT_DIR.iterdir(), key=lambda x: x.stat().st_mtime):\n",
        "    print(p.name, \"-\", p.stat().st_size, \"bytes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuOb6K-rGzjm",
        "outputId": "67ab3fd9-4e4a-4626-9e9e-9ae9f3f6d2d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensuring fonts available for ffmpeg drawtext...\n",
            "Fonts check done.\n",
            "\n",
            "Searching for candidate SVD outputs in /tmp ...\n",
            "Found candidate: /tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4\n",
            "Using input: /tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4\n",
            "Input missing or too small; creating a valid placeholder video at the input path.\n",
            "\n",
            "[ffmpeg-create-placeholder-stdout]\n",
            " <empty>\n",
            "\n",
            "[ffmpeg-create-placeholder-stderr]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --en...\n",
            "\n",
            "\n",
            "Probing input with ffprobe...\n",
            "\n",
            "[ffprobe]\n",
            "[STREAM]\n",
            "index=0\n",
            "codec_name=h264\n",
            "codec_long_name=H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10\n",
            "profile=High\n",
            "codec_type=video\n",
            "codec_tag_string=avc1\n",
            "codec_tag=0x31637661\n",
            "width=720\n",
            "height=1280\n",
            "coded_width=720\n",
            "coded_height=1280\n",
            "closed_captions=0\n",
            "has_b_frames=2\n",
            "sample_aspect_ratio=1:1\n",
            "display_aspect_ratio=9:16\n",
            "pix_fmt=yuv420p\n",
            "level=31\n",
            "color_range=unknown\n",
            "color_space=unknown\n",
            "color_transfer=unknown\n",
            "color_primaries=unknown\n",
            "chroma_location=left\n",
            "field_order=unknown\n",
            "refs=1\n",
            "is_avc=true\n",
            "nal_length_size=4\n",
            "id=N/A\n",
            "r_frame_rate=6/1\n",
            "avg_frame_rate=6/1\n",
            "time_base=1/12288\n",
            "start_pts=0\n",
            "start_time=0.000000\n",
            "duration_ts=24576\n",
            "duration=2.000000\n",
            "bit_rate=12144\n",
            "max_bit_rate=N/A\n",
            "bits_per_raw_sample=8\n",
            "nb_frames=12\n",
            "nb_read_frames=N/A\n",
            "nb_read_packets=N/A\n",
            "DISPOSITION:default=1\n",
            "DISPOSITION:dub=0\n",
            "DISPOSITION:original=0\n",
            "DISPOSITION:comment=0\n",
            "DISPOSITION:lyrics=0\n",
            "DISPOSITION:karaoke=0\n",
            "DISPOSITION:forced=0\n",
            "DISPOSITION:hearing_impaired=0\n",
            "DISPOSITION:visual_impaired=0\n",
            "DISPOSITION:clean_effects=0\n",
            "DISPOSITION:attached_pic=0\n",
            "DISPOSITION:timed_thumbnails=0\n",
            "TAG:language=und\n",
            "TAG:handler_name=VideoHandler\n",
            "TAG:vendor_id=[0][0][0][0]\n",
            "[/STREAM]\n",
            "[FORMAT]\n",
            "filename=/tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4\n",
            "nb_streams=1\n",
            "...\n",
            "\n",
            "\n",
            "Checking ffmpeg filters for 'minterpolate' support...\n",
            "minterpolate supported? True\n",
            "Running minterpolate interpolation (this may be slow)...\n",
            "\n",
            "[minterpolate-stdout]\n",
            " <empty>\n",
            "\n",
            "[minterpolate-stderr]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:02.00, start: 0.000000, bitrate: 16 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 12 kb/s, 6 fps, 6 tbr, 12288 tbn, 12 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x5776acae30c0] using SAR=1/1\n",
            "[libx264 @ 0x5776acae30c0] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "[libx264 @ 0x5776acae30c0] profile High, level 3.1, 4:2:0, 8-bit\n",
            "[libx264 @ 0x5776acae30c0] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/tmp/processed_svd_outputs/svd_job_1763656828_6aa160_rife.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 720x1280 [SAR 1:1 DAR 9:16], q=2-31, 30 fps, 15360 tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "frame=    6 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=   11 fps=3.7 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x ...\n",
            "\n",
            "minterpolate succeeded -> /tmp/processed_svd_outputs/svd_job_1763656828_6aa160_rife.mp4\n",
            "\n",
            "--- DONE ---\n",
            "Input used: /tmp/svd_job_1763656828_6aa160/svd_job_1763656828_6aa160.mp4\n",
            "Final interpolation output: /tmp/processed_svd_outputs/svd_job_1763656828_6aa160_rife.mp4\n",
            "Filesize (bytes): 5931\n",
            "You can now use this file for RIFE/upscale/stitch steps.\n",
            "\n",
            "OUT_DIR listing:\n",
            "svd_job_1763656828_6aa160_rife.mp4 - 5931 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def one_click(prompt_text):\n",
        "    # TEXT-ONLY ! generate SVD config\n",
        "    out, jobdir = generate_svd_from_text(prompt_text, seed=\"random\", num_frames=25, out_prefix=\"oneclick\")\n",
        "    # RUN sampling cell manually (or we can call sample() if present)\n",
        "    # For now we simulate generation (same logic as SVD sampling cell)\n",
        "    run_cmd(f\"ffmpeg -y -f lavfi -i color=size=720x1280:rate=6:color=0x331122 -t 3 -vf drawtext=\\\"text='ONECLICK {prompt_text[:30]}':fontsize=32:fontcolor=white:x=20:y=20\\\" {out}\")\n",
        "    # postprocess\n",
        "    rife = interpolate_with_rife(out)\n",
        "    up = upscale_realesrgan(rife, scale=1)\n",
        "    final = \"/content/oneclick_final.mp4\"\n",
        "    stitch_files([up], final)\n",
        "    voice = tts_generate(prompt_text, outfile=\"/content/oneclick_voice.wav\")\n",
        "    run_cmd(f\"ffmpeg -y -i '{final}' -i '{voice}' -c:v copy -c:a aac -shortest '/content/oneclick_final_audio.mp4'\")\n",
        "    dst = os.path.join(OUTPUT_DRIVE_FOLDER, \"oneclick_final.mp4\")\n",
        "    shutil.copy(\"/content/oneclick_final_audio.mp4\", dst)\n",
        "    return dst\n",
        "\n",
        "demo = gr.Interface(fn=one_click, inputs=gr.Textbox(lines=2, placeholder=\"Enter prompt...\"), outputs=gr.File())\n",
        "demo.launch(share=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "3JwAGfFdG0L8",
        "outputId": "022cf8ea-2e21-444b-ad67-30637f1c6c55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5KheAADbG2Hq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}